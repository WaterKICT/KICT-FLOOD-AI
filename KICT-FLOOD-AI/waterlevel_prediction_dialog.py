# -*- coding: utf-8 -*-
"""
/***************************************************************************
 WaterlevelPredictionDialog
                                 A QGIS plugin
 This plugin is water level prediction.
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                             -------------------
        email                : woonss@gmail.com
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""

import os, sys, csv, shutil
import time
import ast
import qgis
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import math
import threading
from datetime import datetime, timedelta
from random import *
from pickle import dump

import configparser

from matplotlib import gridspec        
import re

import matplotlib.dates as mdates

from mpl_toolkits.mplot3d import Axes3D
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.backends.backend_qt5agg import NavigationToolbar2QT as NavigationToolbar

import matplotlib.ticker as ticker

from qgis.PyQt import QtCore, QtGui, QtWidgets
from qgis.PyQt.QtGui import *
from qgis.PyQt import uic
from qgis.PyQt import *
from qgis.PyQt.QtWidgets import QDockWidget, QAction, QApplication, QWidget, QTableWidget, QTableWidgetItem, QFileDialog, QDialog, QPushButton, QDialogButtonBox, QLineEdit, QTreeWidgetItem
from PyQt5.QtWidgets import QDateEdit, QButtonGroup, QLabel, QFileDialog, QTableWidgetItem, QHeaderView, QMessageBox, QDialog, QCheckBox, QHBoxLayout, QComboBox
from PyQt5 import QtWidgets
from qgis.core import *
from qgis.utils import *
from qgis.core import QgsVectorLayer, QgsProject, QgsMarkerSymbol, QgsFillSymbol, QgsPalLayerSettings, QgsTextFormat, QgsVectorLayerSimpleLabeling, QgsTextBufferSettings
from PyQt5.QtCore import Qt
from PyQt5.QtCore import QTimer, QDate
from PyQt5.QtGui import QFont, QIcon
from PyQt5.QtGui import QPalette, QColor
from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QComboBox, QListView, QFrame
from PyQt5.QtCore import Qt, QPoint, QStringListModel, QSize
from PyQt5.QtCore import pyqtSignal

import pandas as pd
from PyQt5.QtCore import QObject, pyqtSlot, QUrl, QThread
from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QPushButton, QFileDialog, QMainWindow
)

import sys
import plotly.graph_objs as go
from PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget, QSizePolicy

import tempfile
from PyQt5.QtCore import QUrl
import plotly.graph_objects as go

import time
from io import BytesIO
import requests
import json
import socket
import win32com.client as win32


from PyQt5.QtWidgets import (
    QWidget, QPushButton, QListWidget, QListWidgetItem,
    QLineEdit, QHBoxLayout, QVBoxLayout, QLabel, QToolButton, QCompleter, QApplication
)
from PyQt5.QtCore import Qt, pyqtSignal, QStringListModel, QPoint, QObject, QEvent
import sys

# This loads your .ui file so that PyQt can populate your plugin with the elements from Qt Designer
FORM_CLASS, _ = uic.loadUiType(os.path.join(os.path.dirname(__file__), 'waterlevel_prediction_dialog_base.ui'))

class WaterlevelPredictionDialog(QtWidgets.QDialog, FORM_CLASS):
    
    def __init__(self, parent=None):
        """Constructor."""
        super(WaterlevelPredictionDialog, self).__init__(parent)
        # Set up the user interface from Designer through FORM_CLASS.
        # After self.setupUi() you can access any designer object by doing
        # self.<objectname>, and you can use autoconnect slots - see
        # http://qt-project.org/doc/qt-4.8/designer-using-a-ui-file.html
        # #widgets-and-dialogs-with-auto-connect

        # set_plugin_path
        self.program_path = os.path.dirname(__file__)  

        # 아이콘 설정
        self.setWindowIcon(QIcon(os.path.join(self.program_path,'icon.png')))
        self.setupUi(self)

        self.progressBar_file.hide()
        self.lbl_status.hide()

        # 최소화 버튼이 포함된 창 플래그 설정
        self.setWindowFlags(Qt.Window | 
                            Qt.WindowMinimizeButtonHint | 
                            Qt.WindowCloseButtonHint)
        
        # 기본 크기 저장
        self.base_width = 1410
        self.base_height = 1012

        self.isMakeModelDataNull = False    # 모델생성 : 데이터Null여부
        self.isPredictModelDataNull = False # 예측수행 : 데이터Null여부    

        self.dashBoard = None

        # check_ssl_sign
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

        # set_python_path
        self.path_python = '' 

        # set_env_sce_sfm
        self.sce_sfm_param1 = ''    #Model 폴더경로
        self.sce_sfm_param2 = ''    #ModelParam 상위폴더경로
        self.sce_sfm_param3 = ''    #권역명 
        self.sce_sfm_param4 = ''    #대형홍수시나리오모델 폴더경로
        self.sce_sfm_param5 = ''    #데이터셋 폴더경로
        self.sce_sfm_param6 = ''    #관측데이터 폴더경로

        # set configFile_parser
        self.config = configparser.ConfigParser()

        # set_dataimport_thread
        self.data_importer = None
        
        # set_config_file_path
        self.path_configFile = os.path.join(os.path.dirname(__file__), 'config.ini')

        # check_mariaDB_service
        # set_db_connect_info
        import mariadb

        self.db_user = None 
        self.db_password = None 
        self.db_host = None 
        self.db_port = None 
        self.db_tablespace = None 

        self.shp_waterlevel = None 
        self.shp_rainfall = None 
        self.shp_discharge = None 
        self.shp_daminlet = None 
        self.shp_damrelease = None 
        self.shp_tidelevel = None 
        self.shp_watershed = None 
        
        self.id_waterlevel = None 
        self.id_rainfall = None 
        self.id_discharge = None 
        self.id_daminlet = None 
        self.id_damrelease = None 
        self.id_tidelevel = None 
        self.id_watershed = None 

        self.dash_root = None
        self.dash_observe = None
        self.dash_models = None
        self.dash_years = None
        self.dash_riverRegions = None
        self.dash_modelNames = None
        
        # 설정 파일 읽기 등 초기화 작업 호출 가능        
        self.SetConfig()          

        self.db_config = {
            "user": self.db_user,
            "password": self.db_password,
            "host": self.db_host,
            "port": self.db_port,
            "database": self.db_tablespace
        }

        self.db_config_admin = {
            "user": self.db_user,
            "password": self.db_password,
            "host": self.db_host,
            "port": self.db_port,
            "database": "information_schema"
        }           
        
        tablespaces = []
        self.combo_tblspace = SearchableComboBox(
            tablespaces,
            max_visible_items=6,
            popup_width=200,
            popup_height=200,
            popup_offset=QPoint(0, 5) 
        )
        self.combo_tblspace.itemSelected.connect(lambda text: self.get_selected_tablespace(text))
        self.verticalLayout_tablespace.addWidget(self.combo_tblspace)  

        if self.is_mariadb_running():
            try:
                self.get_tablespace_name()                  
                self.visiable_db_control(True)
            except mariadb.Error as e:  
                self.visiable_db_control(False)   
        else:    
            if self.start_mariadb_service():
                self.get_tablespace_name()  

        # 데이터관리 - DB자료조회 (관측소번호 콤보박스); # [데이터조회] 관측소번호 Combobox Event
        self.selected_obsId = None  # 선택된 값을 저장할 변수
        items = []
        self.combo_obs_dblist = SearchableComboBox(
            items,
            max_visible_items=6,
            popup_width=200,
            popup_height=200,
            popup_offset=QPoint(0, 5)  # 버튼보다 5px 아래에 위치
        )
        self.combo_obs_dblist.itemSelected.connect(lambda text: self.get_selected_obsId(text))
        self.verticalLayout_obsList.addWidget(self.combo_obs_dblist)       

        # 데이터관리 - DB자료조회 - init_webView
        from PyQt5.QtWebEngineWidgets import QWebEngineView
        self.web_view = QWebEngineView()
        self.verticalLayout_dataGraph.addWidget(self.web_view)        

        # 데이터관리 - DB자료조회 - init_webView 그래프 초기화 (빈 Figure 생성)
        import plotly.graph_objs as go
        import tempfile
        from PyQt5 import QtCore

        myfig = go.Figure()
        myfig.update_layout(
            xaxis=dict(title='Time'),
            yaxis=dict(title='Value'),
            margin=dict(l=0, r=60, t=30, b=0)
        )

        # HTML로 임시 저장
        with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as f:
            temp_html_path = f.name
            myfig.write_html(temp_html_path)

        # QWebEngineView에 로드
        self.web_view.load(QtCore.QUrl.fromLocalFile(temp_html_path))
        
        # 데이터관리 - DB자료조회 (API관측소번호 콤보박스); # [openAPI 불러오기] 관측소코드 Combobox Event
        self.selected_api_obsId = None  # 선택된 값을 저장할 변수
        items = []
        self.combo_api_obsId = SearchableComboBox(
            items,
            max_visible_items=6,
            popup_width=200,
            popup_height=200,
            popup_offset=QPoint(0, 5)  # 버튼보다 5px 아래에 위치
        )
        self.combo_api_obsId.itemSelected.connect(lambda text: self.get_selected_api_obsId(text))
        self.verticalLayout_api_obsList.addWidget(self.combo_api_obsId)           

        # 대형홍수시나리오 - 시나리오명(폴더리스트)
        self.selected_mksce_sfmName = ''
        sceName = []
        self.combo_mksce_sfmName = SearchableComboBox(
            sceName,
            max_visible_items=6,
            popup_width=200,
            popup_height=200,
            popup_offset=QPoint(0, 5)  # 버튼보다 5px 아래에 위치
        )
        self.combo_mksce_sfmName.itemSelected.connect(lambda text: self.get_selected_mksce_SFM_name(text))
        self.verticalLayout_makeScenarioName.addWidget(self.combo_mksce_sfmName)  

        # 대형홍수시나리오 - 권역명
        river_item = ['Han', 'Nakdong', 'Yeongsan', 'Guem']
        self.cb_River_area.clear()
        self.cb_River_area.addItems(river_item)
        river_idx = self.cb_River_area.findText(self.sce_sfm_param3)   # 인덱스 찾기
        if river_idx >= 0:                   # 존재할 때만
            self.cb_River_area.setCurrentIndex(river_idx)

        # 분류별 콤보박스 관리
        self.combo_boxes = {}

        combo_layouts = {
            "waterlevel": self.vl_dsRef_waterLevel_id,
            "rainfall": self.vl_dsRef_rainfall_id,
            "discharge": self.vl_dsRef_discharge_id,
            "daminlet": self.vl_dsRef_daminlet_id,
            "damrelease": self.vl_dsRef_damrelease_id,
            "tidelevel": self.vl_dsRef_tidelevel_id,
            "watershed": self.vl_dsRef_watershed_id
        }

        for category, layout in combo_layouts.items():
            combo = ButtonComboBox([])       
            layout.addWidget(combo)
            combo.itemDeleted.connect(lambda text, cat=category: self.DatasetObsCodeDeleted(cat, text))
            combo.itemAdded.connect(lambda text, cat=category: self.DatasetObsCodeAdd(cat, text))  
            self.combo_boxes[category] = combo
        
        # basic control set ############################################################        

        # Plugin 화면종료
        self.btn_dialogClose.clicked.connect(self.close)        
        # PythonConsole 불러오기 Button
        self.btn_showPythonConsole.clicked.connect(self.load_pyConsole)        
        # Control 초기화
        self.InitializeUiControls()
        # Dashboard 이벤트
        self.btn_showDashboard.clicked.connect(self.showDashboardDialog)         

        # Plugin 초기화 #################################################################

        # init : PythonConsole 불러오기
        self.load_pyConsole()
        # init : Database 관측소 기간 가져오기
        self.init_databaseDate()
        # init : ShapeFILE 불러오기
        self.load_shapefiles()

        # [tab-대형홍수시나리오생성] ###############################################     

        #self.btn_sceModel_select_model_forder.clicked.connect(self.makeScenario_selectFolder_Model)
        self.btn_sceModel_select_modelParam_folder.clicked.connect(self.makeScenario_selectFolder_Param)
        self.btn_sceModel_select_scenario_model_folder.clicked.connect(self.makeScenario_selectFolder_Dataset)
        self.btn_sceModel_select_dataset_folder.clicked.connect(self.makeScenario_selectFolder_SaveModel)
        self.btn_sceModel_select_observ_folderpath.clicked.connect(self.makeScenario_selectFolder_ObservFolder)        
        self.rb_observ_folderpath_db.clicked.connect(self.makeScenario_setObservControl)
        self.rb_observ_folderpath_file.clicked.connect(self.makeScenario_setObservControl)        
        self.btn_makeScenario_SFM.clicked.connect(self.makeScenario_SFM)
        self.cb_River_area.currentIndexChanged.connect(self.makeScenario_setRiverArea)
        
        self.makeScenario_SFM_getSceName()
        self.makeScenario_setObservControl()
        self.makeScenario_setRiverArea()

        # [tab-환경설정] #################################################################

        # [환경설정] 버튼 그룹화
        self.env_btn_group = QButtonGroup(self)
        self.env_btn_group.setExclusive(True)
        self.btn_envSet_database.setCheckable(True)
        self.btn_envSet_layerinfo.setCheckable(True)
        self.btn_envSet_dashboard.setCheckable(True)
        self.btn_envSet_python.setCheckable(True)
        self.env_btn_group.addButton(self.btn_envSet_database)
        self.env_btn_group.addButton(self.btn_envSet_layerinfo)
        self.env_btn_group.addButton(self.btn_envSet_dashboard)
        self.env_btn_group.addButton(self.btn_envSet_python)

        # [환경설정] 버튼 이벤트 (클릭 및 색상변경)
        self.btn_envSet_database.clicked.connect(lambda: (self.stackedWidget_env.setCurrentIndex(0), self.set_env_button_color()))
        self.btn_envSet_layerinfo.clicked.connect(lambda: (self.stackedWidget_env.setCurrentIndex(1), self.set_env_button_color()))
        self.btn_envSet_dashboard.clicked.connect(lambda: (self.stackedWidget_env.setCurrentIndex(2), self.set_env_button_color()))
        self.btn_envSet_python.clicked.connect(lambda: (self.stackedWidget_env.setCurrentIndex(3), self.set_env_button_color()))

        # [환경설정] 버튼 초기화
        self.btn_envSet_database.setChecked(True)
        self.set_env_button_color()

        # [환경설정] 레이어 설정
        self.btn_env_lyr_waterlevel.clicked.connect(self.set_Shapefile_Path)
        self.btn_env_lyr_rainfall.clicked.connect(self.set_Shapefile_Path)
        self.btn_env_lyr_discharge.clicked.connect(self.set_Shapefile_Path)
        self.btn_env_lyr_daminlet.clicked.connect(self.set_Shapefile_Path)
        self.btn_env_lyr_damrelease.clicked.connect(self.set_Shapefile_Path)
        self.btn_env_lyr_tidelevel.clicked.connect(self.set_Shapefile_Path)
        self.btn_env_lyr_watershed.clicked.connect(self.set_Shapefile_Path)
        self.btn_env_lyr_default.clicked.connect(self.init_shapefiles)

        # [환경설정] 파이썬 경로설정
        self.btn_check_pythonPath.clicked.connect(self.check_pythonPath)
        self.btn_config_pythonPath.clicked.connect(self.set_pythonPath)

        # [환경설정] 데이터베이스 설정
        self.create_tablespace_window = None  # 데이터베이스 생성창 객체
        self.btn_create_tablespace.clicked.connect(self.create_tablespace)
        self.btn_connect_mariadb.clicked.connect(self.connect_database_info)

        # [tab-데이터관리] ###############################################################

        # [데이터파일 불러오기] 파일불러오기(...) Button Event
        self.btn_data_loadDataFile.clicked.connect(self.LoadDataFile)
        # [데이터파일 불러오기] 테이블선택 Combobox Event
        self.cb_dataTable.currentIndexChanged.connect(self.SetDataTableType)
        # [데이터파일 불러오기] 데이터파일저장 (File or DB Import) 
        self.btn_dataSave.clicked.connect(self.FileCSV_Save)        
        
        # [데이터조회] 조회테이블 Combobox Event
        self.cb_searchTable.currentIndexChanged.connect(self.SetDataSearchTableData)
        # [데이터조회] 조회 Button Event
        self.btn_dataSearch.clicked.connect(self.SearchData)
        # [데이터조회] GIS 포인트(관측지점) 선택 Button Event
        self.btn_datasearchGispoint.clicked.connect(self.SelectObs_GIS_DB)
        
        # [openAPI 불러오기] 자료종류 Combobox Event
        self.cb_apiObsType.currentIndexChanged.connect(self.SetOpenAPI_ObsType)
        # [openAPI 불러오기] 조회 Button Event
        self.btn_apiSearch.clicked.connect(self.Search_OpenAPIData)
        # [openAPI 불러오기] 파일저장 Button Event
        self.btn_apiSaveCSV.clicked.connect(self.Save_OpenAPIData)
        # [openAPI 불러오기] 조회기간 셋팅
        self.dt_apiStartDt.setDateTime(QtCore.QDateTime.currentDateTime())
        self.dt_apiEndDt.setDateTime(QtCore.QDateTime.currentDateTime())
        # [openAPI 불러오기] GIS 포인트(관측지점) 선택 Button Event
        self.btn_apisearchGispoint.clicked.connect(self.SelectObs_GIS_API)

        # tab [데이터셋생성] #############################################################

        # [데이터셋생성] 선택레이어 초기화
        self.btn_dataset_selLayer_init.clicked.connect(self.dataset_init_select_layer)
        
        # [데이터셋생성] 레이어활성화
        self.btn_dataset_activelayer_targetpoint.clicked.connect(lambda: self.dataset_on_select_layer("waterlevel"))
        self.btn_dataset_activelayer_waterlevel.clicked.connect(lambda: self.dataset_on_select_layer("waterlevel"))
        self.btn_dataset_activelayer_rainfall.clicked.connect(lambda: self.dataset_on_select_layer("rainfall"))
        self.btn_dataset_activelayer_discharge.clicked.connect(lambda: self.dataset_on_select_layer("discharge"))
        self.btn_dataset_activelayer_daminlet.clicked.connect(lambda: self.dataset_on_select_layer("daminlet"))
        self.btn_dataset_activelayer_damrelease.clicked.connect(lambda: self.dataset_on_select_layer("damrelease"))
        self.btn_dataset_activelayer_tidelevel.clicked.connect(lambda: self.dataset_on_select_layer("tidelevel"))
        self.btn_dataset_activelayer_watershed.clicked.connect(lambda: self.dataset_on_select_layer("watershed"))

        # [데이터셋생성] QGIS에서 선택된 Feature 가져오기(+) Button Event
        self.btn_getSelectedTargetpoint.clicked.connect(self.btn_getSelectedFeatureTarget)
        self.btn_getSelectedWaterlevel.clicked.connect(lambda: self.btn_getSelectedFeature("waterlevel"))
        self.btn_getSelectedRainfall.clicked.connect(lambda: self.btn_getSelectedFeature("rainfall"))
        self.btn_getSelectedDischarge.clicked.connect(lambda: self.btn_getSelectedFeature("discharge"))
        self.btn_getSelectedDaminlet.clicked.connect(lambda: self.btn_getSelectedFeature("daminlet"))
        self.btn_getSelectedDamrelease.clicked.connect(lambda: self.btn_getSelectedFeature("damrelease"))
        self.btn_getSelectedTidelevel.clicked.connect(lambda: self.btn_getSelectedFeature("tidelevel"))
        self.btn_getSelectedThiessen.clicked.connect(lambda: self.btn_getSelectedFeature("watershed"))

        # [데이터셋생성] Make Dataset Button Event
        self.threadpool = QThreadPool()
        self.btn_makeDataset.clicked.connect(self.start_makeDataset)
        # [데이터셋생성] Save Dataset File Button Event
        self.btn_saveDataset.clicked.connect(self.btn_saveDatasetFunc)
        # [데이터셋생성] 기간선택 RadioButton Event
        self.rb_dataset_periodYear.clicked.connect(self.SetDatasetPeriodRadioGroup)
        self.rb_dataset_periodDate.clicked.connect(self.SetDatasetPeriodRadioGroup)
        # [데이터셋생성] 리드타임설정 Event
        self.rb_ds_leadtimeBasic.clicked.connect(self.SetDatasetLeadtimeRadioGroup)
        self.rb_ds_leadtimeTimeseries.clicked.connect(self.SetDatasetLeadtimeRadioGroup)
        self.cb_ds_leadtimeUnit.currentIndexChanged.connect(self.SetDatasetOptionLeadtime)
        # [데이터셋생성] 데이터전처리 Checkbox/Radiobutton Event
        self.ckb_ds_preProcessing_noRain.clicked.connect(self.SetDatasetPreNoRain)
        self.sp_ds_preProcessing_noRainVal.clicked.connect(self.SetDatasetPreAccRain)
        self.ckb_ds_preProcessing_month.clicked.connect(self.SetDatasetPreMonth)
        self.rb_ds_preProcessing_month.clicked.connect(self.SetDatasetPreDateFiltering)
        self.rb_ds_preProcessing_date.clicked.connect(self.SetDatasetPreDateFiltering)
        self.ckb_ds_preProcessing_predictRainVal.clicked.connect(self.SetDatasetPrePredictRain)

        # [데이터셋생성] 그래프보기 button
        self.preHeader = []
        self.preDataset = []
        self.arrDsHeader = []   # 그래프생성을 위한 데이터셋 헤더정보
        self.arrDsData = []     # 그래프생성을 위한 데이터셋 자료정보
        self.btn_showDatasetGraph.clicked.connect(self.ShowDatasetGraph)

        ## tab [하천수위예측모형제작] #####################################################

        # [하천수위예측모형제작] dataset file load Button Event
        self.btn_param_datasetPath.clicked.connect(self.LoadMakeModelDataset)
        # [하천수위예측모형제작] 파라메터 불러오기 Button Event
        self.btn_dl_loadParameter.clicked.connect(self.LoadMakeModelParam)
        # [하천수위예측모형제작] Save path select Button Event
        self.btn_param_savePath.clicked.connect(self.SetMakeModelSavePath)
        # [하천수위예측모형제작] make model Button Event
        self.btn_makeModel.clicked.connect(self.MakeModel)
        # [하천수위예측모형제작] Select leadtime all
        self.ckb_dl_leadtime_all.clicked.connect(self.SetMakeModel_LeadtimeSelect)
        # [하천수위예측모형제작] Select ItemData all
        self.ckb_dl_itemdata_all.clicked.connect(self.SetMakeModel_ItemDataSelect)
        # [하천수위예측모형제작] Training_rate(sp_dl_trainingRate) == Test_start(sp_dl_testRate)
        self.sp_dl_trainingRate.editingFinished.connect(self.ChangedValue_TrainingTestValue) 

        # tab [예측수행및성능분석] #########################################################

        # [예측수행및성능분석] Select Dataset File Button Event
        self.btn_selectDataFile.clicked.connect(self.LoadPredictDataset)
        # [예측수행및성능분석] Select Model Directory Button Event
        self.btn_selectModelFile.clicked.connect(self.LoadModel)
        # [예측수행및성능분석] Save Model Path Button Event
        self.btn_saveModelPath.clicked.connect(self.SetPredictResultSavePath)
        # [예측수행및성능분석] Running Model Button Event
        self.btn_dl_reloadModel.clicked.connect(self.RunPredict)
        # [예측수행및성능분석] Select leadtime all
        self.ckb_predictDatasetLeadtime_all.clicked.connect(self.SetPredict_LeadtimeSelect)
        # [예측수행및성능분석] Select leadtime all
        self.ckb_predictDatasetItemData_all.clicked.connect(self.SetPredict_ItemDataSelect)

        # tab [실시간예측] #########################################################

        # [실시간예측] Realtime Run Model button
        self.btn_realtimeModel.clicked.connect(self.RunRealtimeModel)
        # [실시간예측] Select Model Directory button
        self.btn_selectRealtimeModelFile.clicked.connect(self.LoadRealtimeModel)
        # [실시간예측] Save Model Path button
        self.btn_saveRealtimeModelPath.clicked.connect(self.SaveRealtimeModelPath)
        # [실시간예측] 시간세팅
        self.dt_rt_datetime.setDateTime(QtCore.QDateTime.currentDateTime())

        # tab [대시보드] #########################################################

        self.btn_dash_select_rootFolder.clicked.connect(self.Dashboard_setRootPath)
        self.btn_dash_select_obsFolder.clicked.connect(self.Dashboard_setObservationPath)

        self.btn_dash_add_model.clicked.connect(self.Dashboard_addModel)
        self.btn_dash_delete_model.clicked.connect(self.Dashboard_deleteModel)
        self.listWidget_dash_model.itemClicked.connect(self.Dashboard_ClickedListModel)
        self.btn_dash_modify_model.clicked.connect(self.Dashboard_modifyModel)

        self.btn_dash_add_year.clicked.connect(self.Dashboard_addYear)
        self.btn_dash_delete_year.clicked.connect(self.Dashboard_deleteYear)
        self.listWidget_dash_year.itemClicked.connect(self.Dashboard_ClickedListYear)
        self.btn_dash_modify_year.clicked.connect(self.Dashboard_modifyYear)

        self.btn_dash_add_riverRegion.clicked.connect(self.Dashboard_addRiverRegion)
        self.btn_dash_delete_riverRegion.clicked.connect(self.Dashboard_deleteRiverRegion)
        self.listWidget_dash_riverRegion.itemClicked.connect(self.Dashboard_ClickedListRiverRegion)
        self.btn_dash_modify_riverRegion.clicked.connect(self.Dashboard_modifyRiverRegion)

        self.btn_dash_add_modelName.clicked.connect(self.Dashboard_addModelName)
        self.btn_dash_delete_modelName.clicked.connect(self.Dashboard_deleteModelName)
        self.listWidget_dash_modelName.itemClicked.connect(self.Dashboard_ClickedListModelName)
        self.btn_dash_modify_modelName.clicked.connect(self.Dashboard_modifyModelName)

        # [컨트롤 셋팅] #########################################################

        self.SetDatasetPeriodRadioGroup()
        self.SetDatasetLeadtimeRadioGroup()

        # [데이터셋 - 그래프보기] 생성
        self.dialogDataset = QDialog()
       
    # [프로그램] 종료 이벤트
    def closeEvent(self, event):        
        reply = QMessageBox.question(self, 'KICT FLOOD AI', 'Are you sure you want to exit?',
                                     QMessageBox.Yes | QMessageBox.No, QMessageBox.No)
        if reply == QMessageBox.Yes:

            # save_config
            self.close_plugin()

            # clear_import_thread
            try:
                self.data_importer = getattr(self, "data_importer", None)  
                if self.data_importer is not None and self.data_importer.isRunning():
                    self.data_importer.stop()
                    self.data_importer.wait()
            except Exception as e:
                print("Failed to terminate DB Import Thread : ", e)

            # clear_search_item_combo
            for combo in self.combo_boxes.values():
                combo.cleanupFilter() 

            # clear_dataset_thread
            self.threadpool.waitForDone()
            #self.iface.removePluginMenu("MyPlugin", self.btn_makeDataset)
            #self.iface.removeToolBarIcon(self.toolbar)
            
            event.accept()
        else:
            event.ignore()

    # [환경설정] 파이썬경로 설정 
    def set_pythonPath(self):
        pypath = self.txtBox_pythonPath.text().strip()
        self.path_python = pypath

    # [환경설정] 파이썬경로 확인창 열기
    def check_pythonPath(self):
        import os
        import subprocess
        file_path = os.path.normpath(os.path.join(self.program_path, "checkpythonpath.py"))        
        subprocess.run(["explorer", "/select,", file_path])
    
    # [대형홍수시나리오] 모델폴더경로 설정
    '''def makeScenario_selectFolder_Model(self):
        dirPath = QFileDialog.getExistingDirectory(self)
        if (os.path.exists(dirPath)==False):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "There is no information for the selected folder.", QMessageBox.Ok)
            return
        else:
            self.txt_model_forder_path.setText(dirPath)'''
    
    # [대형홍수시나리오] 모델파라메터폴더경로 설정
    def makeScenario_selectFolder_Param(self):
        dirPath = QFileDialog.getExistingDirectory(self)
        if (os.path.exists(dirPath)==False):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "There is no information for the selected folder.", QMessageBox.Ok)
            return
        else:
            self.txt_modelParam_path.setText(dirPath)
    
    # [대형홍수시나리오] 시나리오모델경로 설정
    def makeScenario_selectFolder_Dataset(self):
        dirPath = QFileDialog.getExistingDirectory(self)
        if (os.path.exists(dirPath)==False):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "There is no information for the selected folder.", QMessageBox.Ok)
            return
        else:
            self.txt_scenario_model_folder_path.setText(dirPath)
            self.makeScenario_SFM_getSceName()
    
    # [대형홍수시나리오] 저장경로(생성된 데이터셋) 설정
    def makeScenario_selectFolder_SaveModel(self):
        dirPath = QFileDialog.getExistingDirectory(self)
        if (os.path.exists(dirPath)==False):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "There is no information for the selected folder.", QMessageBox.Ok)
            return
        else:
            self.txt_dataset_path.setText(dirPath)
            
    # [대형홍수시나리오] 시나리오데이터셋 생성시, 기타관측소정보 획득 파일(상위)폴더 설정 (콤보박스User)
    def makeScenario_selectFolder_ObservFolder(self):
        dirPath = QFileDialog.getExistingDirectory(self)
        if (os.path.exists(dirPath)==False):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "There is no information for the selected folder.", QMessageBox.Ok)
            return
        else:
            self.txt_observ_folderpath.setText(dirPath)

    # [대형홍수시나리오] 시나리오데이터셋 생성시, 기타관측소정보 획득유형 (db, file)
    def makeScenario_setObservControl(self):
        if self.rb_observ_folderpath_db.isChecked():
            self.txt_observ_folderpath.setEnabled(False)
            self.btn_sceModel_select_observ_folderpath.setEnabled(False)
        elif self.rb_observ_folderpath_file.isChecked():
            self.txt_observ_folderpath.setEnabled(True)
            self.btn_sceModel_select_observ_folderpath.setEnabled(True)

    # [대형홍수시나리오] 권역폴더 설정
    def makeScenario_setRiverArea(self):
        self.txt_River_area.setText(self.cb_River_area.currentText())

    # [대형홍수시나리오] 시나리오데이터셋 생성시, 시나리오(관측소) 목록
    def makeScenario_SFM_getSceName(self):

        sce_folder = self.txt_scenario_model_folder_path.text().strip()
        if not os.path.exists(sce_folder):            
            return
                
        self.combo_mksce_sfmName.reset_items()        
        self.txt_scenario_name.clear()

        subfolders = [f for f in os.listdir(sce_folder) if os.path.isdir(os.path.join(sce_folder, f))]
        if subfolders:   
            self.combo_mksce_sfmName.reset_items(subfolders)
        else:
            return

    # [대형홍수시나리오] 수문학적모형(저류함수법) 생성
    def makeScenario_SFM(self):
        
        # (x)Model 폴더패스 
        #model_folder_path = self.txt_model_forder_path.text()
        # (o)ModelParam 상위폴더패스 ---> 모델파라메터가있는폴더 패스
        modelParam_path = self.txt_modelParam_path.text()   
        # (o)ModelParam 하위패스 (권역명-Han)
        River_area = self.txt_River_area.text()
        # (o)대형홍수시나리오모델 패스 ----> 시나리오모델이 있는패스 (out, in, scenario_file)
        scenario_model_folder_path = self.txt_scenario_model_folder_path.text()
        # (o)데이터셋 패스(x) ---> 저장경로패스 
        dataset_path = self.txt_dataset_path.text()
        # (x)모델(년도)
        #model_version = self.txt_model_version.text()
        # (o)대형홍수시나리오명 (obscode 수위관측소명) ---> 대형홍수시나리오모델패스 안에 존재하는 폴더
        scenario_name = self.txt_scenario_name.text()
        
        # check_data
        if (modelParam_path == ''):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "Please enter the parent folder path for ModelParam..", QMessageBox.Ok)
            self.btn_sceModel_select_modelParam_folder.setFocus()
            return
        
        if (scenario_model_folder_path == ''):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "Please enter the folder path for the Extreme Flood Scenario model.", QMessageBox.Ok)
            self.btn_sceModel_select_scenario_model_folder.setFocus()
            return
        
        if (dataset_path == ''):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "Please enter the save path for the scenario dataset.", QMessageBox.Ok)
            self.btn_sceModel_select_dataset_folder.setFocus()
            return
        
        if (self.rb_observ_folderpath_file.isChecked() and self.txt_observ_folderpath.text().strip()==''):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "Please enter the folder containing the observation data files.", QMessageBox.Ok)
            self.btn_sceModel_select_observ_folderpath.setFocus()
            return
        
        if (scenario_name == ''):
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "Please select a Extreme Flood Scenario name.", QMessageBox.Ok)
            return
        
        # 수위관측소코드 추출
        checkCode = re.match(r"^(\d{7})", scenario_name)
        if not checkCode:
            QMessageBox.warning(self, 'Extreme Flood Scenario Creation', "Cannot extract the water level observation station code from the scenario name.", QMessageBox.Ok)
            return

        # run scenario_dataset
        folder_name = checkCode.group(1)

        # 옵션 전달
        options = {
            'modelParam_path' : modelParam_path,
            'River_area': River_area,
            'scenario_model_folder_path': scenario_model_folder_path,
            'dataset_path': dataset_path,
            'scenario_name': scenario_name,
            'folder_name': folder_name,
            'bfromfile' : self.rb_observ_folderpath_file.isChecked(),
            'bfromdb' : self.rb_observ_folderpath_db.isChecked(),
            'obs_folder' : self.txt_observ_folderpath.text().strip(),
            'db_config' : self.db_config,
            'db_tablespace' : self.db_tablespace,
        }

        # call scenario.py
        try:
            from .make_scenario import MakeScenario
        except ImportError as e:
            MakeScenario = None
            import_error_msg = str(e)
        
        self.setCursor(QtGui.QCursor(QtCore.Qt.WaitCursor))

        if MakeScenario is None:
            self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
            QMessageBox.critical(self, "Extreme Flood Scenario Creation", 
                                f"Cannot load the scenario module (.make_scenario).\n{import_error_msg}", 
                                QMessageBox.Ok)
            return

        try:
            myScenario = MakeScenario(options)
            result, msg = myScenario.Storage_Function_Method()
        except Exception as e:
            result = False
            msg = str(e)

        self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))

        if result:
            #QMessageBox.information(self, 'Extreme Flood Scenario Creation', "Scenario Creation is complete. Do you want to check the file?", QMessageBox.Ok)
            msgQuit = QMessageBox.information(self, 'Extreme Flood Scenario Creation', "Scenario Creation is complete. Do you want to check the file?",
                                              QMessageBox.Yes | QMessageBox.No)
            if msgQuit == QMessageBox.Yes:
                # 저장된 파일경로 열기(결과확인)
                save_path = os.path.join(dataset_path,River_area,folder_name,'scenario')
                os.startfile(save_path)
            
        else:
            QMessageBox.critical(self, "Extreme Flood Scenario Creation", msg, QMessageBox.Ok)
           
    # [데이터조회] GIS 포인트(관측지점) 선택 Button Event
    def SelectObs_GIS_DB(self):

        cb_text = self.cb_searchTable.currentText()
        if (cb_text == 'Please select'): 
            QMessageBox.warning(self, 'Query Database', "Please select the type of table to query.", QMessageBox.Ok) 
            return
        
        layer_name = ''
        if cb_text == 'Water Level':            
            layer_name = 'waterlevel'
        elif cb_text == 'Rainfall':            
            layer_name = 'rainfall'
        elif cb_text == 'Flow Rate':            
            layer_name = 'discharge'
        elif cb_text == 'Dam Inflow':            
            layer_name = 'daminlet'
        elif cb_text == 'Dam Outflow':            
            layer_name = 'damrelease'
        elif cb_text == 'Tide Level':            
            layer_name = 'tidelevel'
        elif cb_text == 'Watershed Average Rainfall':            
            layer_name = 'watershed'
        else:
            layer_name=''
        
        layers = QgsProject.instance().mapLayersByName(layer_name)
        if not layers:
            war_msg = f"'{layer_name}' Cannot find the layer."
            QMessageBox.warning(self, 'Query Database', war_msg, QMessageBox.Ok) 
            return
        
        self.target_layer = layers[0]
        iface.setActiveLayer(self.target_layer)

        try:
            self.target_layer.selectionChanged.disconnect(self.SeletedFeature_GISDB)
        except TypeError:
            pass

        self.target_layer.selectionChanged.connect(self.SeletedFeature_GISDB)

        from qgis.gui import QgsMapToolIdentifyFeature

        layer = iface.activeLayer()  
        canvas = iface.mapCanvas()

        if layer is None:
            QMessageBox.warning(self, 'Query Database', "No layer selected.", QMessageBox.Ok) 
        else:
            select_tool = QgsMapToolIdentifyFeature(canvas, layer)
            canvas.setMapTool(select_tool)
            iface.actionSelect().trigger()
    
    # [openAPI 불러오기] GIS 포인트(관측지점) 선택 Button Event
    def SelectObs_GIS_API(self):

        lyr_name = self.cb_apiObsType.currentText()

        if lyr_name == 'Please select':       
            QMessageBox.warning(self, 'Query OpenAPI', "Please select the type of data to query.", QMessageBox.Ok) 
            return
        
        layer_name = ''
        if lyr_name == 'Water Level':            
            layer_name = 'waterlevel'
        elif lyr_name == 'Rainfall':            
            layer_name = 'rainfall'
        elif lyr_name == 'Flow Rate':            
            layer_name = 'discharge'
        elif lyr_name == 'Dam Inflow':            
            layer_name = 'daminlet'
        elif lyr_name == 'Dam Outflow':            
            layer_name = 'damrelease'
        elif lyr_name == 'Tide Level':            
            layer_name = 'tidelevel'
        else:
            layer_name = ''

        layers = QgsProject.instance().mapLayersByName(layer_name)

        if not layers:
            QMessageBox.warning(self, 'Query OpenAPI', "Layer not found.", QMessageBox.Ok) 
            return
        
        self.target_layer = layers[0]
        iface.setActiveLayer(self.target_layer)

        try:
            self.target_layer.selectionChanged.disconnect(self.SeletedFeature_GISAPI)
        except TypeError:
            pass

        self.target_layer.selectionChanged.connect(self.SeletedFeature_GISAPI)

        from qgis.gui import QgsMapToolIdentifyFeature

        layer = iface.activeLayer()  
        canvas = iface.mapCanvas()

        if layer is None:
            QMessageBox.warning(self, 'Query OpenAPI', "No layer selected.", QMessageBox.Ok) 
        else:
            select_tool = QgsMapToolIdentifyFeature(canvas, layer)
            canvas.setMapTool(select_tool)
            iface.actionSelect().trigger()
                
    # [DB조회/OpenAPI불러오기] GIS 포인트(관측지점) 선택 후 관측번호 가져오기 Event
    def SeletedFeature_GISDB(self, selected, deselected, clear_and_select):
        if not selected or self.target_layer is None:
            return

        cb_text = self.cb_searchTable.currentText()
        if (cb_text == 'Please select'):
            return
        
        obs_code = ''
        layer_name = ''
        if cb_text == 'Water Level':            
            layer_name = 'waterlevel'
            obs_code = self.txtBox_env_obscode_waterlevel.text()
        elif cb_text == 'Rainfall':            
            layer_name = 'rainfall'
            obs_code = self.txtBox_env_obscode_rainfall.text()
        elif cb_text == 'Flow Rate':            
            layer_name = 'discharge'
            obs_code = self.txtBox_env_obscode_discharge.text()
        elif cb_text == 'Dam Inflow':            
            layer_name = 'daminlet'
            obs_code = self.txtBox_env_obscode_daminlet.text()
        elif cb_text == 'Dam Outflow':            
            layer_name = 'damrelease'
            obs_code = self.txtBox_env_obscode_damrelease.text()
        elif cb_text == 'Tide Level':            
            layer_name = 'tidelevel'
            obs_code = self.txtBox_env_obscode_tidelevel.text()
        elif cb_text == 'Watershed Average Rainfall':            
            layer_name = 'watershed'
            obs_code = self.txtBox_env_obscode_watershed.text()
        else:
            layer_name = ''
            obs_code = ''

        selectLyr = self.getSeletedFeature(layer_name)
        obs_id = ''
        if len(selectLyr) == 1:
            for f in selectLyr:
                obs_id =str(f[obs_code])
         
            self.combo_obs_dblist.set_selected_obs_text(obs_id)

            if self.target_layer:
                self.target_layer.removeSelection()

        try:           
            self.target_layer.selectionChanged.disconnect(self.SeletedFeature_GISDB)
        except TypeError:
            print("[Query Database] The layer connection has already been disconnected.")        

    # [OpenAPI불러오기] GIS 포인트(관측지점) 선택 후 관측번호 가져오기 Event
    def SeletedFeature_GISAPI(self, selected, deselected, clear_and_select):
        if not selected or self.target_layer is None:
            return

        layer_name = self.cb_apiObsType.currentText()
        lyr_name = ''
        obs_code = ''
        if layer_name == 'Water Level':            
            lyr_name = 'waterlevel'
            obs_code = self.txtBox_env_obscode_waterlevel.text()
        elif layer_name == 'Rainfall':            
            lyr_name = 'rainfall'
            obs_code = self.txtBox_env_obscode_rainfall.text()
        elif layer_name == 'Flow Rate':            
            lyr_name = 'discharge'
            obs_code = self.txtBox_env_obscode_discharge.text()
        elif layer_name == 'Dam Inflow':            
            lyr_name = 'daminlet'
            obs_code = self.txtBox_env_obscode_daminlet.text()
        elif layer_name == 'Dam Outflow':            
            lyr_name = 'damrelease'
            obs_code = self.txtBox_env_obscode_damrelease.text()
        elif layer_name == 'Tide Level':            
            lyr_name = 'tidelevel'
            obs_code = self.txtBox_env_obscode_tidelevel.text()
        else:
            lyr_name = ''

        selectLyr = self.getSeletedFeature(lyr_name)
        obs_id = ''
        if len(selectLyr) == 1:
            for f in selectLyr:
                obs_id =str(f[obs_code])
         
            self.combo_api_obsId.set_selected_obs_text(obs_id)

            if self.target_layer:
                self.target_layer.removeSelection()

        try:            
            self.target_layer.selectionChanged.disconnect(self.SeletedFeature_GISAPI)
        except TypeError:
            print("[Query OpenAPI] Layer connection is already disconnected.")       
    
    # [환경설정] 버튼그룹 이벤트 설정
    def set_env_button_color(self):
                
        font = QFont()
        font.setFamily("돋움")   
        font.setPointSize(10)        
        self.btn_envSet_database.setFont(font)
        self.btn_envSet_layerinfo.setFont(font)
        self.btn_envSet_dashboard.setFont(font)
        self.btn_envSet_python.setFont(font)

        for btn in [self.btn_envSet_database, self.btn_envSet_layerinfo, self.btn_envSet_dashboard, self.btn_envSet_python]:
            if btn.isChecked():
                btn.setStyleSheet("""
                    QPushButton {
                        background-color: #555555;   /* 선택된 버튼 */
                        color: white;
                    }
                    QPushButton:pressed {
                        background-color: #555555;   /* 눌러도 동일 */
                        color: white;
                    }
                """)
            else:
                btn.setStyleSheet("""
                    QPushButton {
                        background-color: #f5f5f5;   /* 기본 버튼 */
                        color: black;
                    }
                    QPushButton:pressed {
                        background-color: #f5f5f5;   /* 눌러도 동일 */
                        color: black;
                    }
                """)

    # [환경설정] 레이어설정 - 레이어파일변경하기 Button Event
    def set_Shapefile_Path(self, link):

        dialog = FileSelectDialog()
        if dialog.exec_() == QDialog.Accepted:            
            file_path, combo_value = dialog.get_result()
            str_code_id = '{}(:{})'.format(file_path, combo_value)
            sender = self.sender()
            link = ''
            if sender == self.btn_env_lyr_waterlevel:
                self.txtBox_env_lyr_waterlevel.setText(file_path)
                self.txtBox_env_obscode_waterlevel.setText(combo_value)
                link = 'waterlevel'
            elif sender == self.btn_env_lyr_rainfall:
                self.txtBox_env_lyr_rainfall.setText(file_path)
                self.txtBox_env_obscode_rainfall.setText(combo_value)
                link = 'rainfall'
            elif sender == self.btn_env_lyr_discharge:
                self.txtBox_env_lyr_discharge.setText(file_path)
                self.txtBox_env_obscode_discharge.setText(combo_value)
                link = 'discharge'
            elif sender == self.btn_env_lyr_daminlet:
                self.txtBox_env_lyr_daminlet.setText(file_path)
                self.txtBox_env_obscode_daminlet.setText(combo_value)
                link = 'daminlet'
            elif sender == self.btn_env_lyr_damrelease:
                self.txtBox_env_lyr_damrelease.setText(file_path)
                self.txtBox_env_obscode_damrelease.setText(combo_value)
                link = 'damrelease'
            elif sender == self.btn_env_lyr_tidelevel:
                self.txtBox_env_lyr_tidelevel.setText(file_path)
                self.txtBox_env_obscode_tidelevel.setText(combo_value)
                link = 'tidelevel'
            elif sender == self.btn_env_lyr_watershed:
                self.txtBox_env_lyr_watershed.setText(file_path)
                self.txtBox_env_obscode_watershed.setText(combo_value)
                link = 'watershed'
            else:
                No_= 0
            self.load_user_shapefiles(link, file_path, combo_value)

    # [데이터베이스 설정] 테이블스페이스 생성 창
    def create_tablespace(self):
        if self.create_tablespace_window is None or not self.create_tablespace_window.isVisible():
            self.create_tablespace_window = CreateTablespace(self.db_config_admin)
            result = self.create_tablespace_window.exec_()  
            if result == QDialog.Accepted:
                input_text = self.create_tablespace_window.get_text()
                self.get_tablespace_name()                
                self.combo_tblspace.set_selected_text(input_text)
                self.init_databaseDate()
            else:
                Non=0

    # [데이터베이스 설정] 데이터베이스 연결정보 수정 창
    def connect_database_info(self):    

        import mariadb    

        dlg = MariaDBConfigDialog(self.db_user, self.db_password, self.db_host, self.db_port)
        if dlg.exec_():  # OK 눌렀을 때
            config = dlg.get_config()
            try:
                conn = mariadb.connect(**config)

                self.db_user = config["user"]
                self.db_password = config["password"]
                self.db_host = config["host"]
                self.db_port = config["port"]

                self.db_config = {
                    "user": self.db_user,
                    "password": self.db_password,
                    "host": self.db_host,
                    "port": self.db_port,
                    "database": self.db_tablespace
                }

                self.db_config_admin = {
                    "user": self.db_user,
                    "password": self.db_password,
                    "host": self.db_host,
                    "port": self.db_port,
                    "database": "information_schema"
                }      

                self.txtBox_dbUser.setText(self.db_user)
                self.txtBox_dbPassword.setText(self.db_password)
                self.txtBox_dbHost.setText(self.db_host)
                self.sp_dbPort.setValue(self.db_port)
                
                self.get_tablespace_name()        
                self.init_databaseDate()
                self.visiable_db_control(True)

            except mariadb.Error as e:
                print(f"[MariaDB Connection Error] {e}")         
                QMessageBox.warning(self, 'Database (MariaDB) Connection Error', "Please check the database connection information again.", QMessageBox.Ok)            
                return
            finally:
                try:
                    if conn:
                        conn.close()
                except:
                    pass
    
    def visiable_db_control(self, bVisiable):
        self.btn_makeDataset.setEnabled(bVisiable)
        self.btn_realtimeModel.setEnabled(bVisiable)
        self.btn_dataSearch.setEnabled(bVisiable)
        self.ckb_data_saveDbImport.setEnabled(bVisiable)
        self.btn_create_tablespace.setEnabled(bVisiable)
        self.rb_observ_folderpath_db.setEnabled(bVisiable)
        self.rb_observ_folderpath_file.setChecked(not bVisiable)
        self.makeScenario_setObservControl()
        return

    # [대형홍수시나리오] 시나리오명 목록 조회
    def get_selected_mksce_SFM_name(self, selected_text):
        self.selected_mksce_sfmName = selected_text
        self.txt_scenario_name.setText(self.selected_mksce_sfmName)
    
    # [데이터관리] DB조회 - DB 데이터 관측소목록 조회
    def get_selected_obsId(self, selected_text):
        self.selected_obsId = selected_text

    # [데이터관리] DB조회 - API 관측소목록 조회
    def get_selected_api_obsId(self, selected_text):
        self.selected_api_obsId = selected_text
        
    # [데이터셋] TABLESPACE 조회 
    def get_selected_tablespace(self, selected_text):
        self.db_tablespace = selected_text
        
        import mariadb
        if (self.db_tablespace!='Please select'):
            
            self.db_config["database"] = self.db_tablespace
            conn = mariadb.connect(**self.db_config)
            cur = conn.cursor()

            query = """
                SELECT TABLE_NAME
                FROM information_schema.TABLES
                WHERE ENGINE = 'InnoDB'
                AND TABLE_SCHEMA = '{}';
            """.format(self.db_tablespace)
            cur.execute(query)
            
            tablespaces = [row[0] for row in cur]

            table_list = tablespaces
      
            self.tbl_dataset_talespace.clearContents()        
            self.tbl_dataset_talespace.setRowCount(len(table_list))
            headers = [
                'Table Name',
                'Sample Data(OBS_ID)', 'Sample Data(DT_DATE)', 'Sample Data(DT_DATA)', 'Sample Data(MI_DATA)', 'Sample Data(OI_DATA)']
            self.tbl_dataset_talespace.setColumnCount(len(headers))
            self.tbl_dataset_talespace.setHorizontalHeaderLabels(headers)
            self.tbl_dataset_talespace.verticalHeader().setVisible(False)

            for row_idx, table in enumerate(table_list):
                
                item = QTableWidgetItem(table)
                item.setTextAlignment(Qt.AlignCenter)
                self.tbl_dataset_talespace.setItem(row_idx, 0, item)
                if table!='predict_rain':

                    sql_last = f"""
                        SELECT obs_id, dt_date, dt_data, mi_data, oi_data
                        FROM {table} LIMIT 1;
                    """
                    cur.execute(sql_last)
                    first = cur.fetchone()     

                    if first:
                        for col_idx, val in enumerate(first):
                            item = QTableWidgetItem(str(val))
                            item.setTextAlignment(Qt.AlignCenter)
                            self.tbl_dataset_talespace.setItem(row_idx, col_idx + 1, item)
                    else:
                        col_idx = 0
                        item = QTableWidgetItem('No Data')
                        item.setTextAlignment(Qt.AlignCenter)
                        self.tbl_dataset_talespace.setItem(row_idx, col_idx + 1, item)
                
                else:   #predict_rain

                    sql_last = f"""
                        SELECT obs_id, dt_date
                        FROM {table} LIMIT 1;
                    """
                    cur.execute(sql_last)
                    first = cur.fetchone()     

                    if first:
                        for col_idx, val in enumerate(first):
                            item = QTableWidgetItem(str(val))
                            item.setTextAlignment(Qt.AlignCenter)
                            self.tbl_dataset_talespace.setItem(row_idx, col_idx + 1, item)
                    else:
                        col_idx = 0
                        item = QTableWidgetItem('No Data')
                        item.setTextAlignment(Qt.AlignCenter)
                        self.tbl_dataset_talespace.setItem(row_idx, col_idx + 1, item)

            self.cb_dataset_startYear.clear()
            self.cb_dataset_endYear.clear()

            current_year = datetime.now().year

            sql_min = "SELECT YEAR(dt_date) AS year FROM waterlevel ORDER BY dt_date ASC LIMIT 1;"
            cur.execute(sql_min)
            result_min = cur.fetchone()
            min_year = result_min[0] if result_min else 2011 

            sql_max = "SELECT YEAR(dt_date) AS year FROM waterlevel ORDER BY dt_date DESC LIMIT 1;"
            cur.execute(sql_max)
            result_max = cur.fetchone()
            max_year = result_max[0] if result_max else current_year  
            
            for year in range(min_year, max_year + 1):
                self.cb_dataset_startYear.addItem(str(year))
                self.cb_dataset_endYear.addItem(str(year))

            cur.close()
            conn.close()

            header = self.tbl_dataset_talespace.horizontalHeader()
            header.setSectionResizeMode(QHeaderView.Stretch)            

        else:
            self.tbl_dataset_talespace.clearContents()            
            self.tbl_dataset_talespace.setRowCount(0)
            self.tbl_dataset_talespace.setColumnCount(0)

    # [환경설정] DB Tabelspace Name 목록 가져오기
    def get_tablespace_name(self):

        import mariadb

        conn = mariadb.connect(**self.db_config_admin)
        cur = conn.cursor()

        target_tables = ['waterlevel', 'rainfall', 'discharge', 'daminlet', 'damrelease', 'tidelevel', 'watershed']
            
        query = f"""
            SELECT TABLE_SCHEMA
            FROM information_schema.TABLES
            WHERE TABLE_NAME IN ({','.join(['?' for _ in target_tables])})
            AND TABLE_SCHEMA NOT IN ('mysql', 'information_schema', 'performance_schema', 'sys')
            GROUP BY TABLE_SCHEMA
            HAVING COUNT(DISTINCT TABLE_NAME) = {len(target_tables)};
        """

        cur.execute(query, target_tables)
        tablespaces = [row[0] for row in cur]
        cur.close()
        conn.close()

        from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QComboBox, QListView

        if not tablespaces:
            print("[Database Settings] No available tablespace.")          
            return
        else:
            self.combo_tblspace.reset_items(tablespaces)
            self.combo_tblspace.set_selected_text(self.db_tablespace)

    def dataset_init_select_layer(self):

        # targetText_init
        self.txtBox_dsRef_targetPoint_id.clear()

        # label_init
        self.lbl_refWaterlevelCount.setText("(0)")
        self.lbl_refRainfallCount.setText("(0)")
        self.lbl_refDischargeCount.setText("(0)")
        self.lbl_refDaminletCount.setText("(0)")
        self.lbl_refDamreleaseCount.setText("(0)")
        self.lbl_refTidelevelCount.setText("(0)")
        self.lbl_refThiessenCount.setText("(0)")

        # combobox_init
        for combo in self.combo_boxes.values():
            combo.clearItems()


    # [데이터셋] 레이어선택 Button Event 
    def dataset_on_select_layer(self, layer_name):
        layers = QgsProject.instance().mapLayersByName(layer_name)
        if layers:
            layer = layers[0]
            iface.setActiveLayer(layer)
            iface.mapCanvas().refresh()
            print(f"[Dataset Creation] Please select an object from {layer.name()}.")

            from qgis.gui import QgsMapToolIdentifyFeature

            layer = iface.activeLayer()  
            canvas = iface.mapCanvas()

            if layer is None:
                QMessageBox.warning(self, 'Dataset Creation', "No layer selected.", QMessageBox.Ok) 
            else:
                select_tool = QgsMapToolIdentifyFeature(canvas, layer)
                canvas.setMapTool(select_tool)
                iface.actionSelect().trigger()
    
    # [환경설정] MariaDB 서비스 상태 확인
    def is_mariadb_running(self):
        import subprocess

        service_name = "MariaDB"

        result = subprocess.run(
            ['sc', 'query', service_name],
            capture_output=True,
            text=True,
            encoding='cp949'
        )
        if 'RUNNING' in result.stdout:
            return True

        config_result = subprocess.run(
            ['sc', 'qc', service_name],
            capture_output=True,
            text=True,
            encoding='cp949'
        )

        if "DISABLED" in config_result.stdout:
            print(f"[Note] {service_name} Change the start type from 'Disabled' to 'Manual'")
            subprocess.run(
                ['sc', 'config', service_name, 'start=', 'demand'],
                shell=True
            )

        start_result = subprocess.run(
            ['net', 'start', service_name],
            capture_output=True,
            text=True,
            encoding='cp949',
            shell=True
        )

        if start_result.returncode == 0:
            return True
        else:
            print(f"[Error] {service_name} Service failed to start.")
            print(start_result.stdout)
            return False

    # [환경설정] MariaDB 서비스 실행
    def start_mariadb_service(self):

        import subprocess
        import sys
        from PyQt5.QtWidgets import QMessageBox

        try:
            result = subprocess.run(
                ['sc', 'start', 'MariaDB'],
                capture_output=True,
                text=True,
                encoding='cp949',
                creationflags=0x08000000  
            )

            if 'OpenService 실패 5' in result.stdout or 'Access is denied' in result.stderr:
                reply = QMessageBox.question(
                    self,
                    "Database (MariaDB) Connection Error",
                    "Administrator privileges are required to start the MariaDB service.\n\n"
                    "Continue without a database?",
                    QMessageBox.Yes | QMessageBox.No
                )

                if reply == QMessageBox.Yes:
                    QMessageBox.critical(self, 'Database (MariaDB) Connection Error', "Run the program without MariaDB.\nSome features may be limited.", QMessageBox.Ok)                                        
                    self.visiable_db_control(False)
                    return False  
                else:
                    QMessageBox.critical(self, 'Database (MariaDB) Connection Error', "QGIS will be closed. Please restart it in administrator mode.", QMessageBox.Ok)

                    # clear_import_thread
                    try:
                        self.data_importer = getattr(self, "data_importer", None)  
                        if self.data_importer is not None and self.data_importer.isRunning():
                            self.data_importer.stop()
                            self.data_importer.wait()
                    except Exception as e:
                        print("Failed to terminate DB Import Thread :", e)     
                    
                    sys.exit(0)

            if '시작되었습니다' in result.stdout or 'START_PENDING' in result.stdout:
                print("MariaDB service has started.")
                return True
            elif '이미 실행 중' in result.stdout:
                print("MariaDB service is already running.")
                return True
            else:
                print("MariaDB Start Result:\n", result.stdout)
                return False

        except Exception as e:
            QMessageBox.critical(self, "Database (MariaDB) Service Start Error", f"An exception occurred while starting the MariaDB service :\n{e}")
            return False

    # [환경설정] config 파일 정보 확인 및 환경변수 설정
    def SetConfig(self):

        # config.ini 경로
        path_configFile = self.path_configFile

        # config 객체는 이미 __init__에서 초기화되었으므로 새로 생성하지 않음
        self.config.clear()  

        if os.path.exists(path_configFile):
            self.config.read(path_configFile, encoding='cp949')

            # set_dashboard
            if 'dashboard' in self.config:
                conf = self.config['dashboard']     

                self.dash_root = conf.get('root', '') 
                self.dash_observe = conf.get('observation', '')  
                self.dash_models = conf.get('modeltype', '') 
                self.dash_years = conf.get('year', '') 
                self.dash_riverRegions = conf.get('riverregion', '') 
                self.dash_modelNames = conf.get('modelname', '')                           

            else:
                # 'dashboard' 섹션 없으면 기본값 세팅
                self.SetDefaultConfig(path_configFile, 'dashboard')            

            # set_shapefile
            if 'shapefile' in self.config:
                conf = self.config['shapefile']         

                def get_shapefile_values(text):
                    if text and ',' in text:
                        parts = text.split(',', 1)  
                        file = parts[0].strip().replace("\\", "/")
                        code = parts[1].strip() if len(parts) > 1 else ''
                        return file, code
                    return '', '' 

                self.shp_waterlevel, self.id_waterlevel = get_shapefile_values(conf.get('waterlevel', ','))
                self.shp_rainfall, self.id_rainfall = get_shapefile_values(conf.get('rainfall', ','))
                self.shp_discharge, self.id_discharge = get_shapefile_values(conf.get('discharge', ','))
                self.shp_daminlet, self.id_daminlet = get_shapefile_values(conf.get('daminlet', ','))
                self.shp_damrelease, self.id_damrelease = get_shapefile_values(conf.get('damrelease', ','))
                self.shp_tidelevel, self.id_tidelevel = get_shapefile_values(conf.get('tidelevel', ','))
                self.shp_watershed, self.id_watershed = get_shapefile_values(conf.get('watershed', ','))
                
            else:
                # 'dashboard' 섹션 없으면 기본값 세팅
                self.SetDefaultConfig(path_configFile, 'shapefile')

            # set_tablespace
            if 'tablespace' in self.config:
                conf = self.config['tablespace']               

                self.db_user = conf.get('user', '') 
                self.db_password = conf.get('password', '') 
                self.db_host = conf.get('host', '') 
                self.db_tablespace = conf.get('database', '') 

                port_str = conf.get('port', '3306')  
                port = 0
                try:
                    port = int(port_str)
                except (ValueError, TypeError):
                    port = 3306  
                
                self.db_port = port

            else:
                # 'dashboard' 섹션 없으면 기본값 세팅
                self.SetDefaultConfig(path_configFile, 'tablespace')            

            # set_pythonpath
            if 'envpath' in self.config:
                conf = self.config['envpath']               
                self.path_python = conf.get('python', '')             

            else:
                # 'dashboard' 섹션 없으면 기본값 세팅
                self.SetDefaultConfig(path_configFile, 'envpath')

            # set_env_sfm_param
            if 'sfmparam' in self.config: 
                conf = self.config['sfmparam']  

                # set_env_sce_sfm  
                self.sce_sfm_param1 = conf.get('sce_sfm_param1', '') 
                self.sce_sfm_param2 = conf.get('sce_sfm_param2', '') 
                self.sce_sfm_param3 = conf.get('sce_sfm_param3', '') 
                self.sce_sfm_param4 = conf.get('sce_sfm_param4', '') 
                self.sce_sfm_param5 = conf.get('sce_sfm_param5', '') 
                self.sce_sfm_param6 = conf.get('sce_sfm_param6', '') 
                #self.sce_sfm_param7 = conf.get('sce_sfm_param7', '') 
             
                self.makeScenario_SFM_getSceName()

            else:
                # 'dashboard' 섹션 없으면 기본값 세팅
                self.SetDefaultConfig(path_configFile, 'sfmparam')            

        else:
            # config.ini 파일 없으면 기본값 생성
            self.SetDefaultConfig(path_configFile, 'dashboard')
            self.SetDefaultConfig(path_configFile, 'shapefile')
            self.SetDefaultConfig(path_configFile, 'tablespace')
            self.SetDefaultConfig(path_configFile, 'envpath')
            self.SetDefaultConfig(path_configFile, 'sfmparam')

    # [환경설정] config 파일 정보 초기화
    def SetDefaultConfig(self, path_configFile, con_name):

        # init_dashboard_param
        if con_name=='dashboard':
            if not self.config.has_section('dashboard'):
                self.config.add_section('dashboard')

            self.config.set('dashboard', 'root', "")
            self.config.set('dashboard', 'observation', "")
            self.config.set('dashboard', 'modelType', "Basic, Predict_RF, Scenario")
            self.config.set('dashboard', 'year', "2022, 2023, 2024")
            self.config.set('dashboard', 'riverRegion', "Han, Nakdong, Yeongsan, Guem")
            self.config.set('dashboard', 'modelName', "WL_{}_timeseries, Predict_RF_WL_{}_timeseries, Scenario_WL_{}_timeseries")
        
            self.dash_root = ""
            self.dash_observe = ""
            self.dash_models = "Basic, Predict_RF, Scenario"
            self.dash_years = "2022, 2023, 2024"
            self.dash_riverRegions = "Han, Nakdong, Yeongsan, Guem"
            self.dash_modelNames = "WL_{}_timeseries, Predict_RF_WL_{}_timeseries, Scenario_WL_{}_timeseries"
            
        if con_name=='shapefile':
            if not self.config.has_section('shapefile'):
                self.config.add_section('shapefile')

            # init_shapefile_path
            pluginPath = os.path.dirname(__file__)
            urlThiessen = pluginPath + "/shp/Korea_watershed_EPSG5186.shp,sbsncd"          # 표준유역
            urlDischarge = pluginPath + "/shp/Korea_Discharge_EPSG5186.shp,obs_code"         # 유량
            urlDaminlet = pluginPath + "/shp/Korea_point_IF_mywater_EPSG5186.shp,obs_code"   # 댐유입량
            urlDamrelease = pluginPath + "/shp/Korea_point_OF_mywater_EPSG5186.shp,obs_code" # 댐방류량
            urlRainfall = pluginPath + "/shp/Korea_Rainfall_EPSG5186.shp,obs_code"           # 강우
            urlTidelevel = pluginPath + "/shp/Korea_point_Tide_level_EPSG5186.shp,obs_code"  # 조위
            urlWaterlevel = pluginPath + "/shp/Korea_Waterlevel_EPSG5186.shp,obs_code"       # 수위
            #urlRiverNetwork = pluginPath + "/shp/Korea_River_network_EPSG5186.shp"  # 하천

            self.config.set('shapefile', 'waterlevel', urlWaterlevel)
            self.config.set('shapefile', 'rainfall', urlRainfall)
            self.config.set('shapefile', 'discharge', urlDischarge)
            self.config.set('shapefile', 'daminlet', urlDaminlet)
            self.config.set('shapefile', 'damrelease', urlDamrelease)
            self.config.set('shapefile', 'tidelevel', urlTidelevel)
            self.config.set('shapefile', 'watershed', urlThiessen)

            # shapcefile 정보확인 (경로, obs_code)
            def get_shapefile_values(text):
                if text and ',' in text:
                    parts = text.split(',', 1)  
                    file = parts[0].strip().replace("\\", "/")
                    code = parts[1].strip() if len(parts) > 1 else ''
                    return file, code
                return '', '' 
        
            self.shp_waterlevel, self.id_waterlevel = get_shapefile_values(urlWaterlevel)
            self.shp_rainfall, self.id_rainfall = get_shapefile_values(urlRainfall)
            self.shp_discharge, self.id_discharge = get_shapefile_values(urlDischarge)
            self.shp_daminlet, self.id_daminlet = get_shapefile_values(urlDaminlet)
            self.shp_damrelease, self.id_damrelease = get_shapefile_values(urlDamrelease)
            self.shp_tidelevel, self.id_tidelevel = get_shapefile_values(urlTidelevel)
            self.shp_watershed, self.id_watershed = get_shapefile_values(urlThiessen)

        # init_database(tablespace)
        if con_name=='tablespace':             
            if not self.config.has_section('tablespace'):
                self.config.add_section('tablespace')

            self.config.set('tablespace', 'user', 'root')
            self.config.set('tablespace', 'password', 'admin')
            self.config.set('tablespace', 'host', 'localhost')
            self.config.set('tablespace', 'port', '3306')
            self.config.set('tablespace', 'database', 'wpdb')    

            self.db_user = 'root' 
            self.db_password = 'admin' 
            self.db_host = 'localhost' 
            self.db_port = 3306
            self.db_tablespace = 'wpdb' 

         # init_dashboard_param
        if con_name=='envpath':
            if not self.config.has_section('envpath'):
                self.config.add_section('envpath')

            self.config.set('envpath', 'python', "")
            self.path_python = ""

        # init_sfm_param
        if con_name=='sfmparam':
            if not self.config.has_section('sfmparam'):
                self.config.add_section('sfmparam')

            self.config.set('sfmparam', 'sce_sfm_param1', "")
            self.config.set('sfmparam', 'sce_sfm_param2', "")
            self.config.set('sfmparam', 'sce_sfm_param3', "")
            self.config.set('sfmparam', 'sce_sfm_param4', "")
            self.config.set('sfmparam', 'sce_sfm_param5', "")
            self.config.set('sfmparam', 'sce_sfm_param6', "")

            self.sce_sfm_param1 = ""
            self.sce_sfm_param2 = ""
            self.sce_sfm_param3 = ""
            self.sce_sfm_param4 = ""
            self.sce_sfm_param5 = ""
            self.sce_sfm_param6 = ""

            self.makeScenario_SFM_getSceName()

        with open(path_configFile, 'w', encoding='cp949') as configfile:
            self.config.write(configfile)
        
    # init : Controls 초기화
    def InitializeUiControls(self):

        # 컨트롤 상태 초기화
        self.cb_dataset_startYear.setEnabled(False)
        self.cb_dataset_endYear.setEnabled(False)
        self.sp_ds_preProcessing_startMonth.setEnabled(False)
        self.sp_ds_preProcessing_endMonth.setEnabled(False)
        self.dt_dataset_startTime.setEnabled(False)
        self.dt_dataset_endTime.setEnabled(False)
        self.ckb_ds_leadtimeHarf.setEnabled(False)
        self.ckb_ds_leadtime1h.setEnabled(False)
        self.ckb_ds_leadtime2h.setEnabled(False)
        self.ckb_ds_leadtime3h.setEnabled(False)
        self.ckb_ds_leadtime4h.setEnabled(False)
        self.ckb_ds_leadtime5h.setEnabled(False)
        self.ckb_ds_leadtime6h.setEnabled(False)
        self.cb_ds_leadtimeTarget.setEnabled(False)
        self.cb_ds_leadtimeTerm.setEnabled(False)
        self.cb_ds_leadtimeUnit.setEnabled(False)

        self.txtBox_ds_preProcessing_noRain.setEnabled(False)
        self.txtBox_ds_preProcessing_accRainHour.setEnabled(False)
        self.sp_ds_preProcessing_startMonth.setEnabled(False)
        self.sp_ds_preProcessing_endMonth.setEnabled(False)
        self.rb_ds_preProcessing_month.setChecked(True)
        self.txtBox_ds_preProcessing_predictRainHour.setEnabled(False)
        self.SetDatasetPreMonth()

        # 컨트롤 데이터초기화
        self.cb_ds_leadtimeTarget.clear()
        self.cb_ds_leadtimeTerm.clear()
        for i in range(1, 7, 1):
            self.cb_ds_leadtimeTarget.addItem(str(i))
            self.cb_ds_leadtimeTerm.addItem(str(i))

        self.cb_ds_leadtimeTarget.setCurrentIndex(self.cb_ds_leadtimeTarget.count()-1)
        self.cb_ds_leadtimeUnit.setCurrentIndex(1)
        self.SetDatasetOptionLeadtime(1)
        self.cb_ds_leadtimeTerm.setCurrentIndex(0)

        # 환경변수 셋팅
        self.listWidget_dash_model.clear()
        self.listWidget_dash_year.clear()
        self.listWidget_dash_riverRegion.clear()
        self.listWidget_dash_modelName.clear()

        self.txtBox_dash_rootPath.setText(self.dash_root)
        self.txtBox_dash_obsPath.setText(self.dash_observe)

        def add_items_from_str(listwidget, s):
            if s:
                for item in s.split(','):
                    listwidget.addItem(item.strip())

        add_items_from_str(self.listWidget_dash_model, self.dash_models)
        add_items_from_str(self.listWidget_dash_year, self.dash_years)
        add_items_from_str(self.listWidget_dash_riverRegion, self.dash_riverRegions)
        add_items_from_str(self.listWidget_dash_modelName, self.dash_modelNames)

        self.txtBox_dbUser.setText(self.db_user)
        self.txtBox_dbPassword.setText(self.db_password)
        self.txtBox_dbHost.setText(self.db_host)
        self.sp_dbPort.setValue(self.db_port)

        self.txtBox_pythonPath.setText(self.path_python)  

        #self.txt_model_forder_path.setText(self.sce_sfm_param1)    
        self.txt_modelParam_path.setText(self.sce_sfm_param2)   
        self.txt_River_area.setText(self.sce_sfm_param3)   
        self.txt_scenario_model_folder_path.setText(self.sce_sfm_param4)   
        self.txt_dataset_path.setText(self.sce_sfm_param5)   
        self.txt_observ_folderpath.setText(self.sce_sfm_param6)

    # [대시보드] Dashboard 창 화면팝업
    def showDashboardDialog(self):

        # model_root_path
        modelRoot_path = self.txtBox_dash_rootPath.text().strip()

        if (modelRoot_path == ''):
            QMessageBox.warning(self, 'Dashboard', "Please set the folder path for the data to display on the dashboard.", QMessageBox.Ok)
            return

        # observation data_path
        pluginPath = os.path.dirname(__file__)
        modelObservation_path = pluginPath + "/station_info"  

        # model_info
        lst_model = [] #['Basic', 'Predict_RF', 'Scenario']
        if (self.listWidget_dash_model.count()>0):
            lst_model = [self.listWidget_dash_model.item(x).text().strip() for x in range(self.listWidget_dash_model.count())]

        # year_info
        lst_year = [] #['2022', '2023', '2024']
        if (self.listWidget_dash_year.count()>0):
            lst_year = [self.listWidget_dash_year.item(x).text().strip() for x in range(self.listWidget_dash_year.count())]

        # river_region_info
        lst_riverRegion = [] #['Han', 'Nakdong', 'Yeongsan', 'Guem']
        if (self.listWidget_dash_riverRegion.count()>0):
            lst_riverRegion = [self.listWidget_dash_riverRegion.item(x).text().strip() for x in range(self.listWidget_dash_riverRegion.count())]

        # model_name_info
        lst_modelName = [] #['WL_{}_timeseries', 'Predict_RF_WL_{}_timeseries', 'Scenario_WL_{}_timeseries']
        if (self.listWidget_dash_modelName.count()>0):
            lst_modelName = [self.listWidget_dash_modelName.item(x).text().strip() for x in range(self.listWidget_dash_modelName.count())]

        # inference_name_info #[inference_모델명]
        lst_infName = []
        if (self.listWidget_dash_modelName.count()>0):
            for i in range(self.listWidget_dash_modelName.count()):
                modNm = self.listWidget_dash_modelName.item(i).text().strip()
                infNm = 'inference_' + modNm
                lst_infName.append(infNm)

        self.setCursor(QtGui.QCursor(QtCore.Qt.WaitCursor))
        self.dashBoard = DashBoard(modelRoot_path, modelObservation_path, lst_model, lst_year, lst_riverRegion, lst_modelName, lst_infName)
        self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
        self.dashBoard.exec_()

    # KICT-FLOOD-AI Plugin 화면 종료 전 CONFIG 설정
    def close_plugin(self):

        # 실시간예측 수행중일경우 종료하기
        if threading.active_count() > 1:
            myThread.cancel()

        # 대시보드창 종료
        if self.dashBoard and self.dashBoard.isVisible():
            self.dashBoard.close()

        # save_config_file
        # save_config_dashboard
        rootInfo = self.txtBox_dash_rootPath.text().strip()
        observationInfo = self.txtBox_dash_obsPath.text().strip()

        def listwidget_to_str(lw):
            return ','.join([lw.item(i).text().strip() for i in range(lw.count())])

        lst_model = listwidget_to_str(self.listWidget_dash_model)
        lst_year = listwidget_to_str(self.listWidget_dash_year)
        lst_riverRegion = listwidget_to_str(self.listWidget_dash_riverRegion)
        lst_modelName = listwidget_to_str(self.listWidget_dash_modelName)

        if not self.config.has_section('dashboard'):
            self.config.add_section('dashboard')

        self.config.set('dashboard', 'root', rootInfo)
        self.config.set('dashboard', 'observation', observationInfo)
        self.config.set('dashboard', 'modelType', lst_model)
        self.config.set('dashboard', 'year', lst_year)
        self.config.set('dashboard', 'riverRegion', lst_riverRegion)
        self.config.set('dashboard', 'modelName', lst_modelName)

        # set_shapefile
        lyrWatershed = self.txtBox_env_lyr_watershed.text()
        codeWatershed = self.txtBox_env_obscode_watershed.text()
        conf_watershed = f'{lyrWatershed},{codeWatershed}'

        lyrDaminlet = self.txtBox_env_lyr_daminlet.text()
        codeDaminlet = self.txtBox_env_obscode_daminlet.text()
        conf_daminlet = f'{lyrDaminlet},{codeDaminlet}'

        lyrDamrelease = self.txtBox_env_lyr_damrelease.text()
        codeDamrelease = self.txtBox_env_obscode_damrelease.text()
        conf_damrelease = f'{lyrDamrelease},{codeDamrelease}'

        lyrRainfall = self.txtBox_env_lyr_rainfall.text()
        codeRainfall = self.txtBox_env_obscode_rainfall.text()
        conf_rainfall = f'{lyrRainfall},{codeRainfall}'

        lyrTidelevel = self.txtBox_env_lyr_tidelevel.text()
        codeTidelevel = self.txtBox_env_obscode_tidelevel.text()
        conf_tidelevel = f'{lyrTidelevel},{codeTidelevel}'

        lyrTidelevel = self.txtBox_env_lyr_tidelevel.text()
        codeTidelevel = self.txtBox_env_obscode_tidelevel.text()
        conf_tidelevel = f'{lyrTidelevel},{codeTidelevel}'

        lyrDischarge = self.txtBox_env_lyr_discharge.text()
        codeDischarge = self.txtBox_env_obscode_discharge.text()
        conf_discharge = f'{lyrDischarge},{codeDischarge}'

        lyrWaterlevel = self.txtBox_env_lyr_waterlevel.text()
        codeWaterlevel = self.txtBox_env_obscode_waterlevel.text()
        conf_waterlevel = f'{lyrWaterlevel},{codeWaterlevel}'

        # set_shapefile
        if not self.config.has_section('shapefile'):
            self.config.add_section('shapefile')

        self.config.set('shapefile', 'watershed', conf_watershed)
        self.config.set('shapefile', 'daminlet', conf_daminlet)
        self.config.set('shapefile', 'damrelease', conf_damrelease)
        self.config.set('shapefile', 'rainfall', conf_rainfall)
        self.config.set('shapefile', 'tidelevel', conf_tidelevel)
        self.config.set('shapefile', 'discharge', conf_discharge)
        self.config.set('shapefile', 'waterlevel', conf_waterlevel)

        # set_tablespace
        if not self.config.has_section('tablespace'):
            self.config.add_section('tablespace')

        db_user = self.txtBox_dbUser.text()
        db_pw = self.txtBox_dbPassword.text()
        db_host = self.txtBox_dbHost.text()
        db_port = str(self.sp_dbPort.value())

        self.config.set('tablespace', 'user', db_user)
        self.config.set('tablespace', 'password', db_pw)
        self.config.set('tablespace', 'host', db_host)
        self.config.set('tablespace', 'port', db_port)
        self.config.set('tablespace', 'database', self.db_tablespace)

        # set_envpath
        if not self.config.has_section('envpath'):
            self.config.add_section('envpath')
        
        path_py = self.txtBox_pythonPath.text().strip()
        self.config.set('envpath', 'python', path_py)


        # set_sfmparam
        if not self.config.has_section('sfmparam'):
            self.config.add_section('sfmparam')
        
        sce_sfm_param1 = ''#self.txt_model_forder_path.text().strip()
        sce_sfm_param2 = self.txt_modelParam_path.text().strip()
        sce_sfm_param3 = self.txt_River_area.text().strip()
        sce_sfm_param4 = self.txt_scenario_model_folder_path.text().strip()
        sce_sfm_param5 = self.txt_dataset_path.text().strip()
        sce_sfm_param6 = self.txt_observ_folderpath.text().strip()

        self.config.set('sfmparam', 'sce_sfm_param1', sce_sfm_param1)
        self.config.set('sfmparam', 'sce_sfm_param2', sce_sfm_param2)
        self.config.set('sfmparam', 'sce_sfm_param3', sce_sfm_param3)
        self.config.set('sfmparam', 'sce_sfm_param4', sce_sfm_param4)
        self.config.set('sfmparam', 'sce_sfm_param5', sce_sfm_param5)
        self.config.set('sfmparam', 'sce_sfm_param6', sce_sfm_param6)

        # save_file
        with open(self.path_configFile, 'w', encoding='cp949') as configfile:
            self.config.write(configfile)

    # init : 데이터베이스 정보 가져오기
    def init_databaseDate(self):     

        import mariadb  
        
        conn = None

        try:
            # 기간설정정보 가져오기
            self.db_config["database"] = self.db_tablespace
            conn = mariadb.connect(**self.db_config)        
            cur = conn.cursor()

            # 데이터베이스 내 테이블 목록 가져오기
            select_query = "SHOW tables"
            cur.execute(select_query)
            resultset = cur.fetchall()
            self.cb_dataTable.clear()
            self.cb_searchTable.clear()
            self.cb_dataTable.addItem("Please select")
            self.cb_searchTable.addItem("Please select")
            for idx in range(len(resultset)):
                tbl_text = resultset[idx][0]
                self.cb_dataTable.addItem(tbl_text)
                if (str(tbl_text) != "predict_rain"):
                    layer_name = ''
                    if tbl_text == 'waterlevel':            
                        layer_name = 'Water Level'
                    elif tbl_text == 'rainfall':            
                        layer_name = 'Rainfall'
                    elif tbl_text == 'discharge':            
                        layer_name = 'Flow Rate'
                    elif tbl_text == 'daminlet':            
                        layer_name = 'Dam Inflow'
                    elif tbl_text == 'damrelease':            
                        layer_name = 'Dam Outflow'
                    elif tbl_text == 'tidelevel':            
                        layer_name = 'Tide Level'
                    elif tbl_text == 'watershed':            
                        layer_name = 'Watershed Average Rainfall'
                        
                    self.cb_searchTable.addItem(layer_name)

            # 컨트롤 날짜데이터 셋팅
            self.cb_dataset_startYear.clear()
            self.cb_dataset_endYear.clear()

            # 현재 연도
            current_year = datetime.now().year

            # 1. 최소 연도 조회
            sql_min = "SELECT YEAR(dt_date) AS year FROM waterlevel ORDER BY dt_date ASC LIMIT 1;"
            cur.execute(sql_min)
            result_min = cur.fetchone()
            min_year = result_min[0] if result_min else 2011  

            # 2. 최대 연도 조회
            sql_max = "SELECT YEAR(dt_date) AS year FROM waterlevel ORDER BY dt_date DESC LIMIT 1;"
            cur.execute(sql_max)
            result_max = cur.fetchone()
            max_year = result_max[0] if result_max else current_year  

            # 3. 콤보박스에 연도 채우기
            for year in range(min_year, max_year + 1):
                self.cb_dataset_startYear.addItem(str(year))
                self.cb_dataset_endYear.addItem(str(year))

            self.sp_ds_preProcessing_startMonth.clear()
            self.sp_ds_preProcessing_endMonth.clear()
            for idx in range(1,13,1):
                self.sp_ds_preProcessing_startMonth.addItem(str(idx))
                self.sp_ds_preProcessing_endMonth.addItem(str(idx))
            
        except mariadb.Error as e:
            print(f"init databaseDate Error Occurred : {e}")
        except Exception as e:
            print(f"[Unknown Error] {e}")
        finally:
            if conn:
                conn.close()

    # init : QGIS ShapeFILE 불러오기
    def load_shapefiles(self):

        pluginPath = os.path.dirname(__file__)
        
        urlThiessen = self.shp_watershed   # 표준유역
        urlDischarge = self.shp_discharge    # 유량
        urlDaminlet = self.shp_daminlet     # 댐유입량
        urlDamrelease = self.shp_damrelease # 댐방류량
        urlRainfall = self.shp_rainfall     # 강우
        urlTidelevel = self.shp_tidelevel   # 조위
        urlWaterlevel = self.shp_waterlevel  # 수위
        urlRiverNetwork = pluginPath + "/shp/Korea_River_network_EPSG5186.shp"  # 하천

        # layer property (lyr_name, T, fill_color, obs_code, shapes_name)
        self.add_mapLayer(urlThiessen, "watershed", "ogr", 'transparent', self.id_waterlevel, '')
        self.add_mapLayer(urlRiverNetwork, "rivernetwork", "ogr", '#276bff', 'obs_code', '')
        self.add_mapLayer(urlDischarge, "discharge", "ogr", 'yellow', self.id_discharge, 'star')
        self.add_mapLayer(urlDaminlet, "daminlet", "ogr", 'green', self.id_daminlet, 'square')
        self.add_mapLayer(urlDamrelease, "damrelease", "ogr", 'blue', self.id_damrelease, 'square')
        self.add_mapLayer(urlRainfall, "rainfall", "ogr", 'orange', self.id_rainfall, 'circle')
        self.add_mapLayer(urlTidelevel, "tidelevel", "ogr", 'purple', self.id_tidelevel, 'diamond')
        self.add_mapLayer(urlWaterlevel, "waterlevel", "ogr", 'red', self.id_watershed, 'triangle')

        # set_initialize
        if (os.path.exists(urlThiessen)):            
            str_code_id = '{}(:{})'.format(urlThiessen, self.id_watershed)
            self.txtBox_env_lyr_watershed.setText(urlThiessen)
            self.txtBox_env_obscode_watershed.setText(self.id_watershed)
        
        if (os.path.exists(urlDischarge)):            
            str_code_id = '{}(:{})'.format(urlDischarge, self.id_discharge)
            self.txtBox_env_lyr_discharge.setText(urlDischarge)
            self.txtBox_env_obscode_discharge.setText(self.id_discharge)
        
        if (os.path.exists(urlDaminlet)):            
            str_code_id = '{}(:{})'.format(urlDaminlet, self.id_daminlet)
            self.txtBox_env_lyr_daminlet.setText(urlDaminlet)
            self.txtBox_env_obscode_daminlet.setText(self.id_daminlet)

        if (os.path.exists(urlDamrelease)):            
            str_code_id = '{}(:{})'.format(urlDamrelease, self.id_damrelease)
            self.txtBox_env_lyr_damrelease.setText(urlDamrelease)
            self.txtBox_env_obscode_damrelease.setText(self.id_damrelease)

        if (os.path.exists(urlRainfall)):            
            str_code_id = '{}(:{})'.format(urlRainfall, self.id_rainfall)
            self.txtBox_env_lyr_rainfall.setText(urlRainfall)
            self.txtBox_env_obscode_rainfall.setText(self.id_rainfall)

        if (os.path.exists(urlTidelevel)):            
            str_code_id = '{}(:{})'.format(urlTidelevel, self.id_tidelevel)
            self.txtBox_env_lyr_tidelevel.setText(urlTidelevel)
            self.txtBox_env_obscode_tidelevel.setText(self.id_tidelevel)

        if (os.path.exists(urlWaterlevel)):            
            str_code_id = '{}(:{})'.format(urlWaterlevel, self.id_waterlevel)
            self.txtBox_env_lyr_waterlevel.setText(urlWaterlevel)
            self.txtBox_env_obscode_waterlevel.setText(self.id_waterlevel)

    def init_shapefiles(self):
        pluginPath = os.path.dirname(__file__)
        
        # initialize
        urlThiessen = pluginPath + "/shp/Korea_watershed_EPSG5186.shp,sbsncd"          # 표준유역
        urlDischarge = pluginPath + "/shp/Korea_Discharge_EPSG5186.shp,obs_code"         # 유량
        urlDaminlet = pluginPath + "/shp/Korea_point_IF_mywater_EPSG5186.shp,obs_code"   # 댐유입량
        urlDamrelease = pluginPath + "/shp/Korea_point_OF_mywater_EPSG5186.shp,obs_code" # 댐방류량
        urlRainfall = pluginPath + "/shp/Korea_Rainfall_EPSG5186.shp,obs_code"           # 강우
        urlTidelevel = pluginPath + "/shp/Korea_point_Tide_level_EPSG5186.shp,obs_code"  # 조위
        urlWaterlevel = pluginPath + "/shp/Korea_Waterlevel_EPSG5186.shp,obs_code"       # 수위

        # shapcefile 정보확인 (경로, obs_code)
        def get_shapefile_values(text):
            if text and ',' in text:
                parts = text.split(',', 1)  
                file = parts[0].strip().replace("\\", "/")
                code = parts[1].strip() if len(parts) > 1 else ''
                return file, code
            return '', '' 
    
        self.shp_waterlevel, self.id_waterlevel = get_shapefile_values(urlWaterlevel)
        self.shp_rainfall, self.id_rainfall = get_shapefile_values(urlRainfall)
        self.shp_discharge, self.id_discharge = get_shapefile_values(urlDischarge)
        self.shp_daminlet, self.id_daminlet = get_shapefile_values(urlDaminlet)
        self.shp_damrelease, self.id_damrelease = get_shapefile_values(urlDamrelease)
        self.shp_tidelevel, self.id_tidelevel = get_shapefile_values(urlTidelevel)
        self.shp_watershed, self.id_watershed = get_shapefile_values(urlThiessen)

        urlThiessen = self.shp_watershed   # 표준유역
        urlDischarge = self.shp_discharge    # 유량
        urlDaminlet = self.shp_daminlet     # 댐유입량
        urlDamrelease = self.shp_damrelease # 댐방류량
        urlRainfall = self.shp_rainfall     # 강우
        urlTidelevel = self.shp_tidelevel   # 조위
        urlWaterlevel = self.shp_waterlevel  # 수위
        urlRiverNetwork = pluginPath + "/shp/Korea_River_network_EPSG5186.shp"  # 하천     

        # layer property (lyr_name, T, fill_color, obs_code, shapes_name)
        self.add_mapLayer(urlThiessen, "watershed", "ogr", 'transparent', self.id_waterlevel, '')
        self.add_mapLayer(urlRiverNetwork, "rivernetwork", "ogr", '#276bff', 'obs_code', '')
        self.add_mapLayer(urlDischarge, "discharge", "ogr", 'yellow', self.id_discharge, 'star')
        self.add_mapLayer(urlDaminlet, "daminlet", "ogr", 'green', self.id_daminlet, 'square')
        self.add_mapLayer(urlDamrelease, "damrelease", "ogr", 'blue', self.id_damrelease, 'square')
        self.add_mapLayer(urlRainfall, "rainfall", "ogr", 'orange', self.id_rainfall, 'circle')
        self.add_mapLayer(urlTidelevel, "tidelevel", "ogr", 'purple', self.id_tidelevel, 'diamond')
        self.add_mapLayer(urlWaterlevel, "waterlevel", "ogr", 'red', self.id_watershed, 'triangle')

        # set_initialize
        if (os.path.exists(urlThiessen)):            
            str_code_id = '{}(:{})'.format(urlThiessen, self.id_watershed)
            self.txtBox_env_lyr_watershed.setText(urlThiessen)
            self.txtBox_env_obscode_watershed.setText(self.id_watershed)
        
        if (os.path.exists(urlDischarge)):            
            str_code_id = '{}(:{})'.format(urlDischarge, self.id_discharge)
            self.txtBox_env_lyr_discharge.setText(urlDischarge)
            self.txtBox_env_obscode_discharge.setText(self.id_discharge)
        
        if (os.path.exists(urlDaminlet)):            
            str_code_id = '{}(:{})'.format(urlDaminlet, self.id_daminlet)
            self.txtBox_env_lyr_daminlet.setText(urlDaminlet)
            self.txtBox_env_obscode_daminlet.setText(self.id_daminlet)

        if (os.path.exists(urlDamrelease)):            
            str_code_id = '{}(:{})'.format(urlDamrelease, self.id_damrelease)
            self.txtBox_env_lyr_damrelease.setText(urlDamrelease)
            self.txtBox_env_obscode_damrelease.setText(self.id_damrelease)

        if (os.path.exists(urlRainfall)):            
            str_code_id = '{}(:{})'.format(urlRainfall, self.id_rainfall)
            self.txtBox_env_lyr_rainfall.setText(urlRainfall)
            self.txtBox_env_obscode_rainfall.setText(self.id_rainfall)

        if (os.path.exists(urlTidelevel)):            
            str_code_id = '{}(:{})'.format(urlTidelevel, self.id_tidelevel)
            self.txtBox_env_lyr_tidelevel.setText(urlTidelevel)
            self.txtBox_env_obscode_tidelevel.setText(self.id_tidelevel)

        if (os.path.exists(urlWaterlevel)):            
            str_code_id = '{}(:{})'.format(urlWaterlevel, self.id_waterlevel)
            self.txtBox_env_lyr_waterlevel.setText(urlWaterlevel)
            self.txtBox_env_obscode_waterlevel.setText(self.id_waterlevel)

    # [환경설정] 레이어설정한 파일 gis에 load
    def load_user_shapefiles(self, obs_name, obs_path, obs_code):

        layers = QgsProject.instance().mapLayersByName(obs_name)

        # 레이어가 있을경우, path(source)만 변경
        if layers:
            layer = layers[0]
            new_source = obs_path
            provider_type = layer.providerType()
            layer.setDataSource(new_source, layer.name(), provider_type)
            layer.triggerRepaint()

        # 레이어가 없을경우, 새로추가
        else:
            if obs_name=='waterlevel':
                self.add_mapLayer(obs_path, obs_name, "ogr", 'red', obs_code, 'triangle')
            elif obs_name=='rainfall':
                self.add_mapLayer(obs_path, obs_name, "ogr", 'orange', obs_code, 'circle')
            elif obs_name=='discharge':
                self.add_mapLayer(obs_path, obs_name, "ogr", 'yellow', obs_code, 'star')
            elif obs_name=='daminlet':
                self.add_mapLayer(obs_path, obs_name, "ogr", 'green', obs_code, 'square')
            elif obs_name=='damrelease':
                self.add_mapLayer(obs_path, obs_name, "ogr", 'blue', obs_code, 'square')
            elif obs_name=='tidelevel':
                self.add_mapLayer(obs_path, obs_name, "ogr", 'purple', obs_code, 'diamond')
            elif obs_name=='watershed':
                self.add_mapLayer(obs_path, obs_name, "ogr", 'transparent', obs_code, '')
            else:
                No_ = 0

    # init : QGIS 레이어 추가
    def add_mapLayer(self, lyr, lyrName, etc, color, labelText, shapes):

        addLayer = QgsVectorLayer(lyr, lyrName, etc)
        if not addLayer.isValid():
            print ("Layer failed to load!")
        else:
            # 같은 레이어가 있다면 지우고 다시 추가한다.
            for layer in QgsProject.instance().mapLayers().values():
                if layer.name() == lyrName:
                    QgsProject.instance().removeMapLayers([layer.id()])

            # 레이어 타입(point, polygon)에 따라 렌더링
            layer_type = addLayer.geometryType()
            if layer_type  == QgsWkbTypes.PointGeometry:
                QgsProject.instance().addMapLayer(addLayer)
                # set labeling
                text_format = QgsTextFormat()
                buffer_settings = QgsTextBufferSettings()
                buffer_settings.setEnabled(True)
                buffer_settings.setSize(0.10)
                buffer_settings.setColor(QColor(color))
                text_format.setBuffer(buffer_settings)
                label = QgsPalLayerSettings()
                label.fieldName = labelText
                label.enabled = True
                label.setFormat(text_format)
                labeler = QgsVectorLayerSimpleLabeling(label)
                addLayer.setLabelsEnabled(True)
                addLayer.setLabeling(labeler)
                # set symbol
                addLayer.renderer().symbol().symbolLayer(0).setSize(2)
                props = addLayer.renderer().symbol().symbolLayer(0).properties()
                props['color'] = color
                props['name'] = shapes
                addLayer.renderer().setSymbol(QgsMarkerSymbol.createSimple(props))
                # qgis symbol refresh
                iface.layerTreeView().refreshLayerSymbology(addLayer.id())
                # repaint
                addLayer.triggerRepaint()
                print(lyrName + " Point Layer was loaded successfully!")
            elif layer_type  == QgsWkbTypes.PolygonGeometry:
                QgsProject.instance().addMapLayer(addLayer)
                # set labeling
                text_format = QgsTextFormat()
                buffer_settings = QgsTextBufferSettings()
                buffer_settings.setEnabled(True)
                buffer_settings.setSize(0.10)
                buffer_settings.setColor(QColor('black'))
                text_format.setBuffer(buffer_settings)
                label = QgsPalLayerSettings()
                label.fieldName = labelText
                label.enabled = True
                label.setFormat(text_format)
                labeler = QgsVectorLayerSimpleLabeling(label)
                # set symbol
                props = addLayer.renderer().symbol().symbolLayer(0).properties()
                props['color'] = color
                if (lyrName == 'rivernetwork'):
                    addLayer.setOpacity(0.8)
                    addLayer.setLabelsEnabled(False)
                if (lyrName == 'watershed'):
                    addLayer.setLabelsEnabled(True)
                    addLayer.setLabeling(labeler)
                addLayer.renderer().setSymbol(QgsFillSymbol.createSimple(props))
                # repaint
                iface.layerTreeView().refreshLayerSymbology(addLayer.id())
                addLayer.triggerRepaint()
                print(lyrName + " Polygon Layer was loaded successfully!")

            else:
                print(lyrName + " NoneType Layer was loaded successfully!")

    # init : PythonConsole 불러오기
    def load_pyConsole(self):
        pythonConsole = iface.mainWindow().findChild(QDockWidget, 'PythonConsole')
        if not pythonConsole or not pythonConsole.isVisible():
            iface.actionShowPythonDialog().trigger()

    # tab [대시보드] : 루트폴더 설정하기
    def Dashboard_setRootPath(self):

        dirPath = QFileDialog.getExistingDirectory(self)
        if (os.path.exists(dirPath)==False):
            QMessageBox.warning(self, 'Dashboard', "No folder selected.", QMessageBox.Ok)
            return
        else:
            self.txtBox_dash_rootPath.setText(dirPath)
    
    # tab [대시보드] : 강우자료폴더 설정하기
    def Dashboard_setObservationPath(self):
        dirPath = QFileDialog.getExistingDirectory(self)
        if (os.path.exists(dirPath)==False):
            QMessageBox.warning(self, 'Dashboard', "No folder selected.", QMessageBox.Ok)
            return
        else:
            self.txtBox_dash_obsPath.setText(dirPath)

    # tab [대시보드] : Level1 추가
    def Dashboard_addModel(self):
        addModelText = self.txtBox_dash_model.text().strip()
        if addModelText is not '':
            self.listWidget_dash_model.addItem(addModelText)
            self.txtBox_dash_model.setText('')

    # tab [대시보드] : Level1 삭제
    def Dashboard_deleteModel(self):     
        removeItemRow = self.listWidget_dash_model.currentRow()
        if (removeItemRow>=0):
            self.listWidget_dash_model.takeItem(removeItemRow)
            self.txtBox_dash_model.setText('')
            self.listWidget_dash_model.setCurrentRow(-1)

    # tab [대시보드] : Level1 선택
    def Dashboard_ClickedListModel(self):     
        self.txtBox_dash_model.setText('')
        ItemRow = self.listWidget_dash_model.currentRow()
        if (ItemRow>=0):
            self.txtBox_dash_model.setText(self.listWidget_dash_model.currentItem().text())
    
    # tab [대시보드] : Level1 수정
    def Dashboard_modifyModel(self):     
        mod_text = self.txtBox_dash_model.text().strip()
        if (mod_text == '') : return

        ItemRow = self.listWidget_dash_model.currentRow()
        if (ItemRow>=0):
            self.listWidget_dash_model.takeItem(ItemRow)
            self.listWidget_dash_model.insertItem(ItemRow, mod_text)
            self.txtBox_dash_model.setText('')
            self.listWidget_dash_model.setCurrentRow(-1)

    # tab [대시보드] : Level2 추가
    def Dashboard_addYear(self):
        addModelText = self.txtBox_dash_year.text().strip()
        if addModelText is not '':
            self.listWidget_dash_year.addItem(addModelText)
            self.txtBox_dash_year.setText('')

    # tab [대시보드] : Level2 삭제
    def Dashboard_deleteYear(self):
        self.removeItemRow = self.listWidget_dash_year.currentRow()
        if (self.removeItemRow>=0):
            self.listWidget_dash_year.takeItem(self.removeItemRow)       
            self.txtBox_dash_year.setText('')
            self.listWidget_dash_year.setCurrentRow(-1)

    # tab [대시보드] : Level2 선택
    def Dashboard_ClickedListYear(self):     
        self.txtBox_dash_year.setText('')
        ItemRow = self.listWidget_dash_year.currentRow()
        if (ItemRow>=0):
            self.txtBox_dash_year.setText(self.listWidget_dash_year.currentItem().text())
    
    # tab [대시보드] : Level2 수정
    def Dashboard_modifyYear(self):     
        mod_text = self.txtBox_dash_year.text().strip()
        if (mod_text == '') : return

        ItemRow = self.listWidget_dash_year.currentRow()
        if (ItemRow>=0):
            self.listWidget_dash_year.takeItem(ItemRow)
            self.listWidget_dash_year.insertItem(ItemRow, mod_text)            
            self.txtBox_dash_year.setText('')
            self.listWidget_dash_year.setCurrentRow(-1)

    # tab [대시보드] : Level3 추가
    def Dashboard_addRiverRegion(self):
        addModelText = self.txtBox_dash_riverRegion.text().strip()
        if addModelText is not '':
            self.listWidget_dash_riverRegion.addItem(addModelText)
            self.txtBox_dash_riverRegion.setText('')

    # tab [대시보드] : Level3 삭제
    def Dashboard_deleteRiverRegion(self):
        self.removeItemRow = self.listWidget_dash_riverRegion.currentRow()
        if (self.removeItemRow>=0):
            self.listWidget_dash_riverRegion.takeItem(self.removeItemRow)  
            self.txtBox_dash_riverRegion.setText('')
            self.listWidget_dash_riverRegion.setCurrentRow(-1)

    # tab [대시보드] : Level3 선택
    def Dashboard_ClickedListRiverRegion(self):     
        self.txtBox_dash_riverRegion.setText('')
        ItemRow = self.listWidget_dash_riverRegion.currentRow()
        if (ItemRow>=0):
            self.txtBox_dash_riverRegion.setText(self.listWidget_dash_riverRegion.currentItem().text())
    
    # tab [대시보드] : Level3 수정
    def Dashboard_modifyRiverRegion(self):     
        mod_text = self.txtBox_dash_riverRegion.text().strip()
        if (mod_text == '') : return

        ItemRow = self.listWidget_dash_riverRegion.currentRow()
        if (ItemRow>=0):
            self.listWidget_dash_riverRegion.takeItem(ItemRow)
            self.listWidget_dash_riverRegion.insertItem(ItemRow, mod_text)         
            self.txtBox_dash_riverRegion.setText('')
            self.listWidget_dash_riverRegion.setCurrentRow(-1)

    # tab [대시보드] : Level5 추가
    def Dashboard_addModelName(self):
        addModelText = self.txtBox_dash_modelName.text().strip()
        if addModelText is not '':
            self.listWidget_dash_modelName.addItem(addModelText)
            self.txtBox_dash_modelName.setText('')

    # tab [대시보드] : Level5 삭제
    def Dashboard_deleteModelName(self):
        self.removeItemRow = self.listWidget_dash_modelName.currentRow()
        if (self.removeItemRow>=0):
            self.listWidget_dash_modelName.takeItem(self.removeItemRow)       
            self.txtBox_dash_modelName.setText('')
            self.listWidget_dash_modelName.setCurrentRow(-1)

    # tab [대시보드] : Level5 선택
    def Dashboard_ClickedListModelName(self):     
        self.txtBox_dash_modelName.setText('')
        ItemRow = self.listWidget_dash_modelName.currentRow()
        if (ItemRow>=0):
            self.txtBox_dash_modelName.setText(self.listWidget_dash_modelName.currentItem().text())
    
    # tab [대시보드] : Level5 수정
    def Dashboard_modifyModelName(self):     
        mod_text = self.txtBox_dash_modelName.text().strip()
        if (mod_text == '') : return

        ItemRow = self.listWidget_dash_modelName.currentRow()
        if (ItemRow>=0):
            self.listWidget_dash_modelName.takeItem(ItemRow)
            self.listWidget_dash_modelName.insertItem(ItemRow, mod_text)       
            self.txtBox_dash_modelName.setText('')
            self.listWidget_dash_modelName.setCurrentRow(-1)

    # tab [데이터 관리] : [데이터파일 Import] 파일불러오기(...) Button Event
    def LoadDataFile(self):

        fileDatas, _ = QFileDialog.getOpenFileNames(self, 'Open file', '', 'csv file(*.csv)')
        
        # 선택된 파일이 없을 경우, 취소
        if len(fileDatas) == 0: return

        # set_tableWidget
        labels = ['File Name', 'File Path']
        self.tbl_showData.clearContents()
        nb_row = len(fileDatas)
        nb_col = len(labels)
        self.tbl_showData.setRowCount(nb_row)
        self.tbl_showData.setColumnCount(nb_col)
        self.tbl_showData.setHorizontalHeaderLabels(labels)
  
        fileNames = []
        for row in range(nb_row):
            dir, fileName = os.path.split(fileDatas[row])
            fileNames.append(fileName)
            item = QTableWidgetItem(fileName)
            item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
            self.tbl_showData.setItem(row, 0, item)
            item = QTableWidgetItem(dir)
            item.setTextAlignment(Qt.AlignLeft | Qt.AlignVCenter)
            self.tbl_showData.setItem(row, 1, item)

        self.txtBox_data_loadDataFile.setText(str(fileNames))
        self.tbl_showData.resizeColumnsToContents()
    
    # tab [데이터 관리] : [데이터파일 Import] 저장하기 (DB 또는 FILE)
    def FileCSV_Save(self):

        # 1. 입력테이블명
        strTableNm = self.cb_dataTable.currentText()

        # 2. 입력된 파일이 있는지 확인한다. (없으면취소, 있으면데이터재확인)
        if (self.tbl_showData.rowCount() == 0):
            QMessageBox.warning(self, 'Data File DB Import', "There is no data to import.", QMessageBox.Ok)
            return
        else:
            strDataName = ""
            if (strTableNm == "waterlevel"):
                strDataName = "Water Level"
            elif (strTableNm == "discharge"):
                strDataName = "Flow Rate"
            elif (strTableNm == "rainfall"):
                strDataName = "Rainfall"
            elif (strTableNm == "daminlet"):
                strDataName = "Dam Inflow"
            elif (strTableNm == "damrelease"):
                strDataName = "Dam Outflow"
            elif (strTableNm == "tidelevel"):
                strDataName = "Tide Level"
            elif (strTableNm == "watershed"):
                strDataName = "Watershed Average Rainfall"
            elif (strTableNm == "predict_rain"):
                strDataName = "Observed Rainfall in Watershed"
            else:
                strDataName = "None"

            msgImport = "Do you want to import the selected file into the {0} table?".format(strDataName)
            btnImportOK = QMessageBox.warning(self, 'Data File DB Import', msgImport,
                                              QMessageBox.Yes | QMessageBox.Cancel)
            if btnImportOK == QMessageBox.Cancel:
                QMessageBox.warning(self, 'Data File DB Import', "The operation has been canceled.", QMessageBox.Ok)
                return

        # 3. 중복데이터가 데이터베이스에 존재할 경우, 업데이트 여부를 선택한다.
        #    Yes-파일자료(또는품질관리자료)로 DB 데이터 수정, No-DB에 있는 데이터 그대로 사용, 취소-Import작업취소
        isUpdate = True
        buttonReply = QMessageBox.warning(self, 'Data File DB Import', "If duplicate data exists, do you want to update it?",
                                          QMessageBox.Yes | QMessageBox.No  | QMessageBox.Cancel)
        if buttonReply == QMessageBox.No:
            isUpdate = False
        elif buttonReply == QMessageBox.Yes:
            isUpdate = True
        else:
            return

        # 4. 품질관리여부
        bRemoveOutlier = self.ckb_data_option1.isChecked()      #이상치제거
        bRemoveMissingVAL = self.ckb_data_option2.isChecked()   #결측치보정     
        
        # 5. 저장분류
        bSaveFile = self.ckb_data_saveFile.isChecked()          #파일저장
        bSaveDbImport = self.ckb_data_saveDbImport.isChecked()  #DB_IMPORT

        # 5-1. 파일저장 폴더
        dirPath = ''
        if bSaveFile:
            dirPath = QFileDialog.getExistingDirectory(self)
            if not os.path.exists(dirPath):
                QMessageBox.warning(self, 'Data File DB Import', "No folder selected.")
                return
            
        # 6. 프로세스 실행
        
        # 실행 중 버튼 비활성화
        self.btn_dataSave.setEnabled(False)

        # 파일 리스트
        file_list = [
            {'path': os.path.join(self.tbl_showData.item(row, 1).text(),
                                self.tbl_showData.item(row, 0).text())}
            for row in range(self.tbl_showData.rowCount())
        ]

        # 옵션 전달
        options = {
            'table_nm' : strTableNm,
            'is_update': isUpdate,
            'remove_outlier': self.ckb_data_option1.isChecked(),
            'fill_missing': self.ckb_data_option2.isChecked(),            
            'save_db': self.ckb_data_saveDbImport.isChecked(),
            'save_file': self.ckb_data_saveFile.isChecked(),
            'save_dir': dirPath,
            'db_config' : self.db_config,
            'tablespace' : self.db_tablespace
        }

        self.progressBar_file.setValue(0)
        self.progressBar_allfile.setValue(0)
        self.progressBar_file.show()
        self.progressBar_allfile.show()        
        self.lbl_status.show()
        
        self.data_importer = DataImporter(file_list, options)
        self.data_importer.allProgressChanged.connect(self.progressBar_allfile.setValue)
        self.data_importer.fileProgressChanged.connect(self.progressBar_file.setValue)
        self.data_importer.fileChanged.connect(lambda fn: self.lbl_status.setText(f"{fn}"))
        self.data_importer.statusMessage.connect(lambda msg: print(msg))
        self.data_importer.errorOccured.connect(lambda e: QMessageBox.critical(self, "Data File DB Import", e))
        self.data_importer.finishedSignal.connect(self.on_finished)
        self.data_importer.start() 

    # tab [데이터 관리] : [데이터파일 Import] 저장하기 - 중간에 종료시 이벤트
    def stop_worker(self):
        if self.data_importer:
            self.data_importer.stop()
            self.lbl_status.setText("Stop Requested...")      

    # tab [데이터 관리] : [데이터파일 Import] 저장하기 - 작업종료 후 이벤트
    def on_finished(self):
        
        QMessageBox.information(self, "Data File DB Import", "All files have been saved.")

        # 처리 완료 후 progressBar_file, lbl_status 숨김        
        self.progressBar_file.hide()
        self.lbl_status.hide()        
        self.progressBar_file.setValue(0)
        self.progressBar_allfile.setValue(0)
        self.lbl_status.clear()
        self.data_importer = None

        # 처리 완료 후, 테이블스페이스정보 & 데이터셋 기간정보 재설정
        self.get_selected_tablespace(self.db_tablespace)

        # 버튼 다시 활성화
        self.btn_dataSave.setEnabled(True)     

    # tab [데이터 관리] : [데이터파일 Import] 테이블선택 Combobox Event
    def SetDataTableType(self, index):
        # 이상치제거(ckb_data_option1), 결측치보정(ckb_data_option2)
        # 테이블선택콤보박스(cb_dataTable)
        # 파일저장버튼(ckb_data_saveFile), DBIMPORT버튼(ckb_data_saveDbImport)
        strTableNm = self.cb_dataTable.currentText().strip()

        if (strTableNm == 'Please select'):
            return 
        
        if (strTableNm == "rainfall"):
            # 강우일 경우는 결측치를 보정해 파일로 내리거나 모두 임포트만 가능
            self.ckb_data_option1.setEnabled(False)
            self.ckb_data_option2.setEnabled(True)
            self.ckb_data_option1.setChecked(False)
            self.ckb_data_option2.setChecked(False)
            self.ckb_data_saveDbImport.setEnabled(True)
            self.ckb_data_saveFile.setEnabled(True)
        elif (strTableNm == "watershed" or strTableNm == "predict_rain"):
            # 유역평균강우는 모두 수기이므로 품질관리 비활성화, 유역실측강우도 원본그대로 - 임포트만 가능
            self.ckb_data_option1.setEnabled(False)
            self.ckb_data_option2.setEnabled(False)
            self.ckb_data_option1.setChecked(False)
            self.ckb_data_option2.setChecked(False)
            self.ckb_data_saveDbImport.setEnabled(True)
            self.ckb_data_saveFile.setEnabled(True)
            #self.ckb_data_saveFile.setEnabled(False)
        else:
            self.ckb_data_option1.setEnabled(True)
            self.ckb_data_option2.setEnabled(True)
            self.ckb_data_option1.setChecked(False)
            self.ckb_data_option2.setChecked(False)
            self.ckb_data_saveDbImport.setEnabled(True)
            self.ckb_data_saveFile.setEnabled(True)

    # tab [데이터 관리] : [openAPI 불러오기] 조회 Button Event
    def Search_OpenAPIData(self):

        # 조회전, 입력값 체크
        if (self.CheckOpenAPI_SearchDataInputValue() == False):
            return

        self.tbl_apiData.clearContents()

        # 인터넷연결확인
        ipaddress = socket.gethostbyname(socket.gethostname())
        if ipaddress == "127.0.0.1":
            QMessageBox.warning(self, 'Query OpenAPI', "Invalid internet connection.", QMessageBox.Ok)
            return

        # openAPI 데이터 정보(테이블, 컬럼) 설정
        idxDataType = self.cb_apiObsType.currentIndex()-1
        strDataType = ''
        colName = ''
        if (idxDataType == 0):      # 수위(한강홍수통제소)
            strDataType = 'waterlevel'
            colName = 'wl'
        elif (idxDataType == 1):    # 유량(한강홍수통제소)
            strDataType = 'waterlevel'
            colName = 'fw'
        elif (idxDataType == 2):    # 강우(한강홍수통제소)
            strDataType = 'rainfall'
            colName = 'rf'
        elif (idxDataType == 3):    # 댐유입량(한강홍수통제소)
            strDataType = 'dam'
            colName = 'inf'
        elif (idxDataType == 4):    # 댐방류량(한강홍수통제소)
            strDataType = 'dam'
            colName = 'tototf'
        elif (idxDataType == 5):    # 조위(해양조사원)
            strDataType = 'tidelevel'
            colName = 'tide_level'
        else:
            return

        # 관측소번호 설정
        strObsId = self.selected_api_obsId 

        # 조회기간 설정
        start = self.dt_apiStartDt.text()
        end = self.dt_apiEndDt.text()
        startDate = "{0}{1}{2}0000".format(start[0:4], start[5:7], start[8:10])
        endDate = "{0}{1}{2}2350".format(end[0:4], end[5:7], end[8:10])

        # openAPI 정보 설정

        # 환경부 한강홍수통제소 자료 (10분단위, 최대1개월까지 조회가능)
        # 낙동강, 금강, 영산강 권역의 자료는 한강 권역의 자료 보다 늦게 수집 됩니다.
        # 한강 권역 : 7~8분, 낙동강, 금강, 영산강 권역 : 11분 이상, 따라서 관측소별로 최종자료 시간이 다를 수 있습니다.
        # 수위/유량 데이터 url (wlobscd, ymdhm, wl, fw) - 관측소code, 년월일시분(yyyyMMddHHmm), 수위자료(m)(#), 유량자료(m3/s)(#)
        # url_waterlevel = 'https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/waterlevel/list/10M/1001607/202108010000/202108012350.json'
        # 강우 url (rfobscd, ymdhm, rf) - 관측소code, 년월일시분(yyyyMMddHHmm), 강수량자료(mm)(#)
        # url_rainfall = 'https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/rainfall/list/10M/10014010/202208090000/202208092350.json'
        # 댐유입/방류 데이터 url (dmobscd, ymdhm, swl, inf, sfw, ecpc, tototf) - 코드, 일시분, 현재수위, 유입량(#), 저수량, 공용량, 총방류량(#)
        # url_dam = 'https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/dam/list/10M/1001210/202308090000/202308101700.json'

        # 해양수산부 국립해양조사원 조위관측소 자료 (1분단위, 최대1일까지 조회가능)
        # 조위 url = https://www.khoa.go.kr/api/oceangrid/tideObs/search.do?ServiceKey=JuG/Up/1yV7/MD3MhQuduQ==&ObsCode=DT_0001&Date=20220809&ResultType=json

        url = ""        # openAPI service_url
        myKey = ""      # openAPI KEY (KEY정보 변경하기)
        url_data = ''
        if (idxDataType == 5):
            url = "https://www.khoa.go.kr/api/oceangrid/tideObs/search.do?ServiceKey={0}&ObsCode={1}&Date={2}&ResultType=json"
            myKey = "JuG/Up/1yV7/MD3MhQuduQ=="
            url_data = url.format(myKey, strObsId, startDate[0:8])
        else:
            url = "https://api.hrfco.go.kr/{0}/{1}/list/10M/{2}/{3}/{4}.json"
            myKey = "52832662-D130-4239-9C5F-730AD3BE6BC6"
            url_data = url.format(myKey, strDataType, strObsId, startDate, endDate)

        # openAPI 자료 가져오기
        response = requests.get(url_data, verify=False)
        if response.status_code == 200:
            data = json.loads(response.text)
            if (idxDataType == 5):
                for errData in data['result'].keys():
                    if errData == "error":
                        self.tbl_apiData.setRowCount(0)
                        self.tbl_apiData.setColumnCount(0)
                        QMessageBox.warning(self, 'Query OpenAPI', data['result'][errData], QMessageBox.Ok)
                        return False
                                    
                df = pd.json_normalize(data['result']['data'])
                labels = ['Date', 'Data']
                nb_row = len(df)
                nb_col = len(labels)
                self.tbl_apiData.setRowCount(nb_row)
                self.tbl_apiData.setColumnCount(nb_col)
                self.tbl_apiData.setHorizontalHeaderLabels(labels)
                idxTable = 0
                for row in range(len(df)):
                    Datetext = str(str(df.loc[row]['record_time']))
                    datetime_format = "%Y-%m-%d %H:%M:%S"
                    datetimeText = pd.to_datetime(Datetext)
                    # 1분단위 데이터이므로 10분단위 측정자료만 가져옴
                    if datetimeText.minute % 10 == 0:
                        item = QTableWidgetItem(str(df.loc[row]['record_time']))
                        item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                        self.tbl_apiData.setItem(idxTable, 0, item)
                        item = QTableWidgetItem(str(df.loc[row][colName]))
                        item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                        self.tbl_apiData.setItem(idxTable, 1, item)
                        idxTable += 1
                self.tbl_apiData.resizeColumnsToContents()
                self.tbl_apiData.setRowCount(idxTable)                

            else:
                for errData in data.keys():
                    if errData == "message":
                        self.tbl_apiData.setRowCount(0)
                        self.tbl_apiData.setColumnCount(0)
                        QMessageBox.warning(self, 'Query OpenAPI', data[errData], QMessageBox.Ok)
                        return False

                df = pd.json_normalize(data['content'])                                
                df['ymdhm'] = pd.to_datetime(df['ymdhm'], errors='coerce')
                df['ymdhm'] = df['ymdhm'].dt.strftime("%Y-%m-%d %H:%M")
                labels = ['Date', 'Data']
                nb_row = len(df)
                nb_col = len(labels)
                self.tbl_apiData.setRowCount(nb_row)
                self.tbl_apiData.setColumnCount(nb_col)
                self.tbl_apiData.setHorizontalHeaderLabels(labels)
                for row in range(len(df)):
                    item = QTableWidgetItem(str(df.loc[nb_row - row - 1]['ymdhm']))
                    item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                    self.tbl_apiData.setItem(row, 0, item)
                    item = QTableWidgetItem(str(df.loc[nb_row - row - 1][colName]))
                    item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                    self.tbl_apiData.setItem(row, 1, item)

                self.tbl_apiData.resizeColumnsToContents()

            return True
        else:
            errMsg = str(response.status_code)
            QMessageBox.warning(self, 'Query OpenAPI', errMsg, QMessageBox.Ok)
            return False

    # tab [데이터 관리] : [openAPI 불러오기] 조회전, 입력값 체크
    def CheckOpenAPI_SearchDataInputValue(self):

        # 0. 자료종류를 선택했는지,
        typeIdx = self.cb_apiObsType.currentIndex()-1
        if (typeIdx<0):
            QMessageBox.warning(self, 'Query OpenAPI', "Please select the type of data to query.", QMessageBox.Ok)
            return
        
        # 1.관측소번호를 입력했는지,
        strObsId = self.selected_api_obsId #""
        if (strObsId == None):
            QMessageBox.warning(self, 'Query OpenAPI', "Please enter the observation station number to query.", QMessageBox.Ok)
            return False

        # 2. 조회기간이 올바른지(시작일이 종료일보다 크거나 같은지)
        if (self.dt_apiStartDt.date() > self.dt_apiEndDt.date()):
            QMessageBox.warning(self, 'Query OpenAPI', "The start date cannot be later than the end date.", QMessageBox.Ok)
            return False

        # 3. 조회기간이 한달 또는 하루(조위)를 넘어가지는 않는지,
        from dateutil.relativedelta import relativedelta
        idxDataType = self.cb_apiObsType.currentIndex()-1
        start = self.dt_apiStartDt.text()
        end = self.dt_apiEndDt.text()
        dateMonth = datetime(int(start[0:4]), int(start[5:7]), int(start[8:10])) + relativedelta(months=1)
        dateEnd = datetime(int(end[0:4]), int(end[5:7]), int(end[8:10]))

        if (idxDataType == 5):
            if (start != end):
                QMessageBox.warning(self, 'Query OpenAPI', "Query period is limited to one day.", QMessageBox.Ok)
                return False
        else:
            if (dateEnd.date() > dateMonth.date()):
                QMessageBox.warning(self, 'Query OpenAPI', "Query period is limited to one month.", QMessageBox.Ok)
                return False

        return True

    # tab [데이터 관리] : [openAPI 불러오기] 관측소목록 변경
    def SetOpenAPI_ObsType(self, index):

        # 수위/유량관측소 제원정보
        # https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/waterlevel/info.json
        # 강우관측소 제원정보
        # https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/rainfall/info.json
        # 댐 제원정보
        # https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/dam/info.json
        # 조위관측소 제원정보
        # http://www.khoa.go.kr/api/oceangrid/ObsServiceObj/search.do?ServiceKey=wldhxng34hkddbsgm81lwldhxng34hkddbsgm81l==&ResultType=json

        self.selected_api_obsId = None

        # 인터넷연결확인
        ipaddress = socket.gethostbyname(socket.gethostname())
        if ipaddress == "127.0.0.1":
            return

        # 관측소 종류에 따라 조회자료, 기관, 컬럼명 변경
        url = "https://api.hrfco.go.kr/{0}/{1}/info.json"
        myKey = "52832662-D130-4239-9C5F-730AD3BE6BC6"
        strDataType = ''
        colName = ''
        url_obs = ''

        idxDataType = self.cb_apiObsType.currentIndex()-1
        if (idxDataType == 0):
            strDataType = 'waterlevel'
            colName = 'wlobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 1):
            strDataType = 'waterlevel'
            colName = 'wlobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 2):
            strDataType = 'rainfall'
            colName = 'rfobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 3):
            strDataType = 'dam'
            colName = 'dmobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 4):
            strDataType = 'dam'
            colName = 'dmobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 5):
            url = "http://www.khoa.go.kr/api/oceangrid/ObsServiceObj/search.do?ServiceKey={0}&ResultType=json"
            myKey = "JuG/Up/1yV7/MD3MhQuduQ=="
            colName = 'obs_post_id'
            url_obs = url.format(myKey)
        else:
            return

        # openAPI 관측소 제원정보(관측소코드) 가져오기
        response = requests.get(url_obs, verify=False)
        if response.status_code == 200:
            data = json.loads(response.text)
            if (idxDataType == 5): #조위일경우

                items = []
                for datas in data['result']['data']:
                    if datas is not None:
                        codeNo = datas[colName]
                        if codeNo != None:
                            items.append(codeNo)
                
                self.combo_api_obsId.reset_items(items)
                                
            else:                
                items = []
                for datas in data['content']:
                    if datas is not None:
                        codeNo = datas[colName]
                        if codeNo != None:
                            items.append(codeNo)           

                self.combo_api_obsId.reset_items(items)                

            return True
        else:
            errMsg = str(response.status_code)
            self.combo_api_obsId.reset_items([])  
            QMessageBox.warning(self, 'Query OpenAPI', errMsg, QMessageBox.Ok)
            return False

    # tab [데이터 관리] : [openAPI 불러오기] 파일저장
    def Save_OpenAPIData(self):

        # 저장할 내용이 없을경우, 취소
        if self.tbl_apiData.rowCount() == 0:
            QMessageBox.warning(self, 'Query OpenAPI', "There is no data to save.", QMessageBox.Ok)
            return

        idxDataType = self.cb_apiObsType.currentIndex()-1

        if (idxDataType<0):
            return

        # obsNo
        strObsId = self.selected_api_obsId 

        # 조위일경우 날짜형식을 변경하여 저장
        bChangeDateType = False
        if idxDataType == 5:
            bChangeDateType = True

        # 파일 정보 설정
        file = QFileDialog.getSaveFileName(self, "Save file", strObsId, "*.csv")
        # 저장경로가 없을때 리턴
        if file[0] == '':
            return
        # 저장경로 정보 설정
        saveFilePath = file[0]

        # 파일저장
        saveFile = open(saveFilePath, 'w', newline='')
        wr = csv.writer(saveFile)
        for row in range(self.tbl_apiData.rowCount()):
            rowdata = []
            for col in range(self.tbl_apiData.columnCount()):
                itemText = str(self.tbl_apiData.item(row, col).text())
                if ((col == 0) and (bChangeDateType == True)):
                    itemText = "{0}{1}{2}{3}{4}".format(itemText[0:4],itemText[5:7],itemText[8:10], itemText[11:13],itemText[14:16])
                rowdata.append(itemText)
            wr.writerow(rowdata)
        saveFile.close()

        QMessageBox.information(self, 'Query OpenAPI', "The data has been saved successfully", QMessageBox.Ok)

    # tab [데이터 관리] : [데이터조회] 관측소종류에 따른 목록변경
    def SetDataSearchTableData(self, index):
        self.SearchTableObsIdList()

    # tab [데이터 관리] : [데이터조회] 관측소목록 Combobox 설정
    def SearchTableObsIdList(self):
        import mariadb

        conn = None

        try:
            self.selected_obsId = None

            # 데이터조회
            conn = mariadb.connect(**self.db_config)
            cur = conn.cursor()

            # 데이터관리 - 데이터베이스 내 관측소별 관측소코드 목록 가져오기
            strTblNm = ''
            cb_text = self.cb_searchTable.currentText()
            if (cb_text == 'Please select'):
                # 관측소번호 콤보박스 초기화
                items = ['Please select']
                self.combo_obs_dblist.reset_items(items)                
                return
        
            else:
                if cb_text == 'Water Level':            
                    strTblNm = 'waterlevel'
                elif cb_text == 'Rainfall':            
                    strTblNm = 'rainfall'
                elif cb_text == 'Flow Rate':            
                    strTblNm = 'discharge'
                elif cb_text == 'Dam Inflow':            
                    strTblNm = 'daminlet'
                elif cb_text == 'Dam Outflow':            
                    strTblNm = 'damrelease'
                elif cb_text == 'Tide Level':            
                    strTblNm = 'tidelevel'
                elif cb_text == 'Watershed Average Rainfall':            
                    strTblNm = 'watershed'
                else:
                    return
            
            select_query = "SELECT OBS_ID FROM {0} GROUP BY OBS_ID".format(strTblNm)

            cur.execute(select_query)
            resultset = cur.fetchall()

            items = []
            for idx in range(len(resultset)):
                items.append(resultset[idx][0])

            self.combo_obs_dblist.reset_items(items)

        except mariadb.Error as e:
            print("[Query Database] Error occurred : {e}")
        except Exception as e:
            print("[Query Database] {e}")
        finally:
            if conn:
                conn.close()

    # tab [데이터 관리] : [데이터조회] 조회전, 입력값 체크
    def CheckSearchDataInputValue(self):
        
        # 1.관측소종류를 입력했는지,
        strTbl = self.cb_searchTable.currentText()
        if (strTbl == 'Please select'):
            QMessageBox.warning(self, 'Query Database', "Please select a table to query.", QMessageBox.Ok)
            return False

        # 2.관측소번호를 입력했는지,
        strObsId = self.selected_obsId 
        if (strObsId == None):
            QMessageBox.warning(self, 'Query Database', "Please enter the observation station id to query.", QMessageBox.Ok)
            return False

        # 3. 조회기간이 올바른지(시작일이 종료일보다 크거나 같은지)
        if (self.dt_data_startTime.date() > self.dt_data_endTime.date()):
            QMessageBox.warning(self, 'Query Database', "The start date cannot be later than the end date.", QMessageBox.Ok)
            return False

        return True

    # tab [데이터 관리] : [데이터조회] 조회 Button Event
    def SearchData(self):

        import mariadb

        # 조회전, 입력값 체크하기
        if (self.CheckSearchDataInputValue() == False):
            return

        # 관측소종류
        strTblNm = ''
        cb_text = self.cb_searchTable.currentText()
        if (cb_text == 'Please select'):
            return
        
        if cb_text == 'Water Level':            
            strTblNm = 'waterlevel'
        elif cb_text == 'Rainfall':            
            strTblNm = 'rainfall'
        elif cb_text == 'Flow Rate':            
            strTblNm = 'discharge'
        elif cb_text == 'Dam Inflow':            
            strTblNm = 'daminlet'
        elif cb_text == 'Dam Outflow':            
            strTblNm = 'damrelease'
        elif cb_text == 'Tide Level':            
            strTblNm = 'tidelevel'
        elif cb_text == 'Watershed Average Rainfall':            
            strTblNm = 'watershed'

        # 관측소코드
        strObsId = self.selected_obsId 

        # 자료종류 (0-표준화자료, 1-결측치보정자료, 2-이상치제거자료) - 모두 표출함

        # 조회기간 설정
        start = self.dt_data_startTime.text()
        end = self.dt_data_endTime.text()
        sql_date = "date_format(DT_DATE, '%Y-%m-%d') between '{0}' and '{1}'".format(start, end)

        # 데이터 조회
        conn = None

        #self.setCursor(QtGui.QCursor(QtCore.Qt.WaitCursor))
        try:

            conn = mariadb.connect(**self.db_config)
            cur = conn.cursor()
            select_all_query = "select OBS_ID, DT_DATE, DT_DATA, MI_DATA, OI_DATA from {} where OBS_ID = '{}' and ({}) ORDER BY DT_DATE".format(strTblNm, strObsId, sql_date)
            cur.execute(select_all_query)
            resultset = cur.fetchall()
        except mariadb.Error as e:
            print("오류 발생: {e}")
        except Exception as e:
            print("[기타 오류] {e}")
        finally:
            #self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
            if conn:
                conn.close()

        # 그래프 초기화 (빈 Figure 생성)
        import plotly.graph_objs as go
        import tempfile
        from PyQt5 import QtCore

        # 그래프 그리기
        if len(resultset) == 0:    

            myfig = go.Figure()
            myfig.update_layout(
                xaxis=dict(title='Time'),
                yaxis=dict(title='Value'),
                margin=dict(l=0, r=60, t=30, b=0)
            )

            # HTML로 임시 저장
            with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as f:
                temp_html_path = f.name
                myfig.write_html(temp_html_path)

            # QWebEngineView에 로드
            self.web_view.load(QtCore.QUrl.fromLocalFile(temp_html_path))
            
            QMessageBox.warning(self, 'Query Database', "No data found.", QMessageBox.Ok)      

        else:
            x_temp = [i[1] for i in resultset]
            y_temp = [self.convert_data_nullToNan(i[2]) for i in resultset]
            strTitle = "{0}({1}) {2}~{3}".format(strTblNm, strObsId, str(x_temp[0])[0:16], str(x_temp[len(x_temp)-1])[0:16])
  
            y_temp1 = [self.convert_data_nullToNan(i[2]) for i in resultset]                  
            y_temp2 = [self.convert_data_nullToNan(i[3]) for i in resultset]
            y_temp3 = [self.convert_data_nullToNan(i[4]) for i in resultset]

            # 그래프 초기화
            import plotly.graph_objs as go
            import plotly.io as pio
            import random

            # x축 데이터, y축 데이터
            layout = go.Layout(
                font=dict(family="Malgun Gothic, sans-serif"),  
                xaxis=dict(
                    title="time",
                    tickformat="%Y-%m-%d %H:%M",    
                ),
                yaxis=dict(title="data"),
                legend=dict(
                    x=1.05,             
                    y=1,                
                    xanchor='left',    
                    yanchor='top',      
                    bgcolor='rgba(255,255,255,0.5)',  
                ),
            )

            myfig = go.Figure(layout=layout)            
            
            myfig.add_trace(go.Scatter(x=x_temp, y=y_temp1, mode='lines', name='DT_DATA'))
            myfig.add_trace(go.Scatter(x=x_temp, y=y_temp2, mode='lines', name='MI_DATA'))
            myfig.add_trace(go.Scatter(x=x_temp, y=y_temp3, mode='lines', name='OI_DATA'))
            
            # 레이아웃 및 인터랙션 설정
            myfig.update_layout(
                xaxis=dict(title='Time', rangeslider_visible=True),
                yaxis=dict(title='Value'),
                margin=dict(l=0, r=60, t=30, b=0),
                legend=dict(x=1.02, y=1, xanchor='left', yanchor='top')
            )
            
            # HTML로 임시 저장
            with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as f:
                temp_html_path = f.name
                myfig.write_html(temp_html_path)

            # QWebEngineView에 HTML 로드
            self.web_view.load(QtCore.QUrl.fromLocalFile(temp_html_path))

    # tab [데이터 관리] : [데이터조회] 조회자료가 NULL값일 경우 처리
    def convert_data_nullToNan(self, data):
        if str(data) == 'None':
            return np.NAN
        else:
            return float(data)
        
    # tab [데이터셋 생성]: 관측소 정보 삭제 이벤트
    def DatasetObsCodeDeleted(self, category, text):

        combo = self.combo_boxes.get(category)
        if category == 'waterlevel':      
            self.lbl_refWaterlevelCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'rainfall':            
            self.lbl_refRainfallCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'discharge':            
            self.lbl_refDischargeCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'daminlet':            
            self.lbl_refDaminletCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'damrelease':            
            self.lbl_refDamreleaseCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'tidelevel':            
            self.lbl_refTidelevelCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'watershed':            
            self.lbl_refThiessenCount.setText("("+str(len(combo.getAllItems()))+")")
        else:
            No_=0        

    # tab [데이터셋 생성]: 관측소 정보 추가 이벤트
    def DatasetObsCodeAdd(self, category, text):
                
        combo = self.combo_boxes.get(category)
        if category == 'waterlevel':      
            self.lbl_refWaterlevelCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'rainfall':            
            self.lbl_refRainfallCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'discharge':            
            self.lbl_refDischargeCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'daminlet':            
            self.lbl_refDaminletCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'damrelease':            
            self.lbl_refDamreleaseCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'tidelevel':            
            self.lbl_refTidelevelCount.setText("("+str(len(combo.getAllItems()))+")")
        elif category == 'watershed':            
            self.lbl_refThiessenCount.setText("("+str(len(combo.getAllItems()))+")")
        else:
            No_=0   

    # tab [데이터셋 생성]: [1단계-지점정보] TargetPoint (+) Button
    def btn_getSelectedFeatureTarget(self):
        self.txtBox_dsRef_targetPoint_id.clear()
        lyrName = "waterlevel"
        obs_code = self.txtBox_env_obscode_waterlevel.text()
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) == 1:
            for f in selectLyr:             
                self.txtBox_dsRef_targetPoint_id.setText(str(f[obs_code]))
           
            layers = QgsProject.instance().mapLayersByName(lyrName)
            if layers:
                layer = layers[0] 
                layer.removeSelection()

        if (len(selectLyr) > 1):
            QMessageBox.warning(self, 'Dataset Creation', "Select only one Target Point.", QMessageBox.Ok)

    # tab [데이터셋 생성]: [1단계-지점정보] ReferencePoint (+) Button - getObsCode
    def set_dataset_getSelectedFeature(self, combo: QComboBox, label : QLabel, lyr_name : str, obs_code : str):
        sel_items = []
        
        fCount = 0
        selectLyr = self.getSeletedFeature(lyr_name)
        if len(selectLyr) > 0:
            for f in selectLyr:
                sel_items.append(str(f[obs_code]))
                fCount = fCount + 1
            
            combo.addItems(sel_items)

            layers = QgsProject.instance().mapLayersByName(lyr_name)
            if layers:
                layer = layers[0]  
                layer.removeSelection()
        
        label.setText("("+ str(len(combo.getAllItems())) +")")


    # tab [데이터셋 생성]: [1단계-지점정보] ReferencePoint (+) Button
    def btn_getSelectedFeature(self, lyr_name):

        combo = self.combo_boxes.get(lyr_name)
        if lyr_name == 'waterlevel':            
            obs_code = self.txtBox_env_obscode_waterlevel.text()
            self.set_dataset_getSelectedFeature(combo, self.lbl_refWaterlevelCount, lyr_name, obs_code)
        elif lyr_name == 'rainfall':            
            obs_code = self.txtBox_env_obscode_rainfall.text()
            self.set_dataset_getSelectedFeature(combo, self.lbl_refRainfallCount, lyr_name, obs_code)
        elif lyr_name == 'discharge':            
            obs_code = self.txtBox_env_obscode_discharge.text()
            self.set_dataset_getSelectedFeature(combo, self.lbl_refDischargeCount, lyr_name, obs_code)
        elif lyr_name == 'daminlet':            
            obs_code = self.txtBox_env_obscode_daminlet.text()
            self.set_dataset_getSelectedFeature(combo, self.lbl_refDaminletCount, lyr_name, obs_code)
        elif lyr_name == 'damrelease':            
            obs_code = self.txtBox_env_obscode_damrelease.text()
            self.set_dataset_getSelectedFeature(combo, self.lbl_refDamreleaseCount, lyr_name, obs_code)
        elif lyr_name == 'tidelevel':            
            obs_code = self.txtBox_env_obscode_tidelevel.text()
            self.set_dataset_getSelectedFeature(combo, self.lbl_refTidelevelCount, lyr_name, obs_code)
        elif lyr_name == 'watershed':            
            obs_code = self.txtBox_env_obscode_watershed.text()
            self.set_dataset_getSelectedFeature(combo, self.lbl_refThiessenCount, lyr_name, obs_code)
        else:
            No_=0

    # tab [데이터셋 생성]: [2단계:기간선택] 선택 Event
    def SetDatasetPeriodRadioGroup(self):
        # control initialize
        self.cb_dataset_startYear.setEnabled(False)
        self.cb_dataset_endYear.setEnabled(False)
        self.dt_dataset_startTime.setEnabled(False)
        self.dt_dataset_endTime.setEnabled(False)
        self.cb_dataset_startYear.setEnabled(self.rb_dataset_periodYear.isChecked())
        self.cb_dataset_endYear.setEnabled(self.rb_dataset_periodYear.isChecked())
        self.dt_dataset_startTime.setEnabled(self.rb_dataset_periodDate.isChecked())
        self.dt_dataset_endTime.setEnabled(self.rb_dataset_periodDate.isChecked())

    # tab [데이터셋 생성]: [2단계:리드타임설정] 선택 Event
    def SetDatasetLeadtimeRadioGroup(self):
        # control initialize
        self.ckb_ds_leadtimeHarf.setEnabled(False)
        self.ckb_ds_leadtime1h.setEnabled(False)
        self.ckb_ds_leadtime2h.setEnabled(False)
        self.ckb_ds_leadtime3h.setEnabled(False)
        self.ckb_ds_leadtime4h.setEnabled(False)
        self.ckb_ds_leadtime5h.setEnabled(False)
        self.ckb_ds_leadtime6h.setEnabled(False)
        self.cb_ds_leadtimeTarget.setEnabled(False)
        self.cb_ds_leadtimeTerm.setEnabled(False)
        self.cb_ds_leadtimeUnit.setEnabled(False)
        self.ckb_ds_leadtimeHarf.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime1h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime2h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime3h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime4h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime5h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime6h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.cb_ds_leadtimeTarget.setEnabled(self.rb_ds_leadtimeTimeseries.isChecked())
        self.cb_ds_leadtimeTerm.setEnabled(self.rb_ds_leadtimeTimeseries.isChecked())
        self.cb_ds_leadtimeUnit.setEnabled(self.rb_ds_leadtimeTimeseries.isChecked())

    # tab [데이터셋 생성]: [2단계:리드타임설정] 시간단위선택 Combobox Event
    def SetDatasetOptionLeadtime(self, index):
        self.cb_ds_leadtimeTerm.clear()
        if (index == 0):
            for i in range(1, 7, 1):
                self.cb_ds_leadtimeTerm.addItem(str(i))
            self.lbl_ds_leadtimeTerm.setText("hour interval")
        elif (index == 1):
            for i in range(1, 7, 1):
                self.cb_ds_leadtimeTerm.addItem(str(i * 10))
            self.lbl_ds_leadtimeTerm.setText("minute interval")
        else:
            self.cb_ds_leadtimeTerm.clear()
            self.lbl_ds_leadtimeTerm.setText("")

    # tab [데이터셋 생성]: [전처리옵션:기간필터링] 기간필터링 Checkbox Event
    def SetDatasetPreMonth(self):
        self.rb_ds_preProcessing_month.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.rb_ds_preProcessing_date.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_startMonth.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_endMonth.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_startDate.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_endDate.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        if (self.ckb_ds_preProcessing_month.isChecked()):
            self.SetDatasetPreDateFiltering()

    # tab [데이터셋 생성]: [전처리옵션:무강우사상삭제] 무강우사상삭제 Checkbox Event
    def SetDatasetPreNoRain(self):
        self.txtBox_ds_preProcessing_noRain.setEnabled(self.ckb_ds_preProcessing_noRain.isChecked())

    # tab [데이터셋 생성]: [전처리옵션:누적강우생성] 누적강우생성 Checkbox Event
    def SetDatasetPreAccRain(self):
        self.txtBox_ds_preProcessing_accRainHour.setEnabled(self.sp_ds_preProcessing_noRainVal.isChecked())

    # tab [데이터셋 생성]: [전처리옵션:기간필터링] 기간필터링 Radiobutton Event
    def SetDatasetPreDateFiltering(self):
        # control initialize
        self.sp_ds_preProcessing_startMonth.setEnabled(False)
        self.sp_ds_preProcessing_endMonth.setEnabled(False)
        self.sp_ds_preProcessing_startDate.setEnabled(False)
        self.sp_ds_preProcessing_endDate.setEnabled(False)
        self.sp_ds_preProcessing_startMonth.setEnabled(self.rb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_endMonth.setEnabled(self.rb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_startDate.setEnabled(self.rb_ds_preProcessing_date.isChecked())
        self.sp_ds_preProcessing_endDate.setEnabled(self.rb_ds_preProcessing_date.isChecked())

    # tab [데이터셋 생성] : [전처리옵션:예측강우생성] 예측강우생성 Checkbox Event
    def SetDatasetPrePredictRain(self):
        self.txtBox_ds_preProcessing_predictRainHour.setEnabled(self.ckb_ds_preProcessing_predictRainVal.isChecked())

    # tab [데이터셋 생성]:[1단계-지점정보] 레이어정보
    def getSeletedFeature(self, lyrName):
        selectFeatures = []
        for lyr in QgsProject.instance().mapLayers().values():
            gislyrName = lyr.name()
            if (lyrName in gislyrName.lower()) == True:
                selectFeatures = lyr.selectedFeatures()

        if len(selectFeatures) == 0:
            QMessageBox.warning(self, 'Dataset Creation', "No feature selected", QMessageBox.Ok)

        return selectFeatures

    # tab [데이터셋 생성]: 데이터셋생성전, 입력정보 체크
    def CheckDatasetInfo(self):

        # 1.Target 지점선택 되었는지
        isSelectPoint = False
        # target
        if self.txtBox_dsRef_targetPoint_id.text().strip() != '':
            isSelectPoint = True
        if isSelectPoint == False:
            QMessageBox.warning(self, 'Dataset Creation', "Please enter or select the Target Point information to query.", QMessageBox.Ok)
            return False

        # 2. Reference 지점선택 되었는지
        nRefCount = 0
        nRefCount += len(self.combo_boxes.get("waterlevel").getAllItems())
        nRefCount += len(self.combo_boxes.get("rainfall").getAllItems())
        nRefCount += len(self.combo_boxes.get("discharge").getAllItems())
        nRefCount += len(self.combo_boxes.get("daminlet").getAllItems())
        nRefCount += len(self.combo_boxes.get("damrelease").getAllItems())
        nRefCount += len(self.combo_boxes.get("tidelevel").getAllItems())
        nRefCount += len(self.combo_boxes.get("watershed").getAllItems())
        if nRefCount == 0:
            QMessageBox.warning(self, 'Dataset Creation', "Please enter or select the Reference Point information to query.", QMessageBox.Ok)
            return False

        # 3.기간선택 되었는지
        isPeriod = False
        if self.rb_dataset_periodYear.isChecked():
            startYear = int(self.cb_dataset_startYear.currentText())
            endYear = int(self.cb_dataset_endYear.currentText())
            startMonth = 1
            endMonth = 12
            if ((startYear == endYear) and startMonth <= endMonth) or (
                    ((startYear < endYear) and ((startMonth <= endMonth))) or (
                    (startYear < endYear) and ((startMonth > endMonth)))):
                isPeriod = True
        if self.rb_dataset_periodDate.isChecked():
            start = self.dt_dataset_startTime.dateTime()
            end = self.dt_dataset_endTime.dateTime()
            if start <= end:
                isPeriod = True
        if isPeriod == False:
            QMessageBox.warning(self, 'Dataset Creation', "Please set the period for the query.", QMessageBox.Ok)
            return False

        # 4. 전처리옵션 설정체크
        if (self.ckb_ds_preProcessing_noRain.isChecked()):
            
            if (len(self.combo_boxes.get("rainfall").getAllItems())==0):
                QMessageBox.warning(self, 'Dataset Creation', "No rainfall point information is selected, so the dry weather event data cannot be checked.", QMessageBox.Ok)
                return False
            
            if (self.txtBox_ds_preProcessing_noRain.text().strip()==''):
                QMessageBox.warning(self, 'Dataset Creation', "Please check the time information for the preprocessing option: Remove Dry Weather Events.", QMessageBox.Ok)
                return False
            else:
                tmpNoRainRange = self.txtBox_ds_preProcessing_noRain.text().strip()
                try:
                    intValues = int(tmpNoRainRange)
                except ValueError:
                    QMessageBox.warning(self, 'Dataset Creation', "Please recheck the time information for the preprocessing option: Remove Dry Weather Events.\n(Example - enter 8 if the period is 8 hours before and after)", QMessageBox.Ok)
                    return False

        if (self.sp_ds_preProcessing_noRainVal.isChecked()):
            
            if (len(self.combo_boxes.get("rainfall").getAllItems())==0):
                QMessageBox.warning(self, 'Dataset Creation', "No rainfall point information is selected, so cumulative rainfall cannot be generated.", QMessageBox.Ok)
                return False
            
            if (self.txtBox_ds_preProcessing_accRainHour.text().strip()==''):
                QMessageBox.warning(self, 'Dataset Creation', "Please recheck the information for the preprocessing option: Generate Cumulative Rainfall.", QMessageBox.Ok)
                return False
            else:
                tmpAccRainTerm = self.txtBox_ds_preProcessing_accRainHour.text().split(',')
                for tmpNumber in tmpAccRainTerm:
                    try:
                        intValues = int(tmpNumber.strip())
                    except ValueError:
                        QMessageBox.warning(self, 'Dataset Creation', "Please recheck the input information for the preprocessing option: Generate Cumulative Rainfall.\n(Example - enter 6,8 for 6-hour and 8-hour periods)", QMessageBox.Ok)
                        return False

        if (self.ckb_ds_preProcessing_month.isChecked()):
            if (self.rb_ds_preProcessing_month.isChecked()):
                stdMonth = self.sp_ds_preProcessing_startMonth.currentText()
                endMonth = self.sp_ds_preProcessing_endMonth.currentText()
                if int(stdMonth) > int(endMonth):
                    QMessageBox.warning(self, 'Dataset Creation', "Please recheck the information for the preprocessing option: Period Filtering.", QMessageBox.Ok)
                    return False
            if (self.rb_ds_preProcessing_date.isChecked()):
                stdDate = self.sp_ds_preProcessing_startDate.text()
                endDate = self.sp_ds_preProcessing_endDate.text()
                stdDay = stdDate[0:2] + stdDate[3:5]
                endDay = endDate[0:2] + endDate[3:5]
                if int(stdDay) > int(endDay):
                    QMessageBox.warning(self, 'Dataset Creation', "Please recheck the information for the preprocessing option: Period Filtering.", QMessageBox.Ok)
                    return False
                
        if (self.ckb_ds_preProcessing_predictRainVal.isChecked()):
            if (len(self.combo_boxes.get("watershed").getAllItems())==0):
                QMessageBox.warning(self, 'Dataset Creation', "No watershed information is selected, so predictive rainfall data cannot be generated.", QMessageBox.Ok)
                return False
            
            if (self.txtBox_ds_preProcessing_predictRainHour.text().strip()==''):
                QMessageBox.warning(self, 'Dataset Creation', "Please recheck the information for the preprocessing option: Generate Predictive Rainfall.", QMessageBox.Ok)
                return False
            else:
                tmpPredictRainTerm = self.txtBox_ds_preProcessing_predictRainHour.text().split(',')
                for tmpNumber in tmpPredictRainTerm:
                    try:
                        intValues = int(tmpNumber.strip())
                    except ValueError:
                        QMessageBox.warning(self, 'Dataset Creation', "Please recheck the input information for the preprocessing option: Generate Predictive Rainfall.\n(Example - enter 3,6 for 3-hour and 6-hour periods)", QMessageBox.Ok)
                        return False

        # 5.리드타임설정 되었는지
        isLeadtime = False
        if self.rb_ds_leadtimeBasic.isChecked():
            if self.ckb_ds_leadtimeHarf.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime1h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime2h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime3h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime4h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime5h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime6h.isChecked():
                isLeadtime = True
        if self.rb_ds_leadtimeTimeseries.isChecked():
            isLeadtime = True
        if isLeadtime == False:
            QMessageBox.warning(self, 'Dataset Creation', "Please set the lead time information to query.", QMessageBox.Ok)
            return False

        return True
        
    def start_makeDataset(self):

        if (self.CheckDatasetInfo() == False):
            return
        
        # 데이터셋조회결과 표출시 오류체크
        self.update_failed = False

        # get_ui_data
        # 1. 지점정보
        targetText = self.txtBox_dsRef_targetPoint_id.text().strip()
        dataWaterlevel = self.combo_boxes.get("waterlevel").getAllItems()
        dataRainfall = self.combo_boxes.get("rainfall").getAllItems()
        dataDaminlet = self.combo_boxes.get("daminlet").getAllItems()
        dataDamrelease = self.combo_boxes.get("damrelease").getAllItems()
        dataDischarge = self.combo_boxes.get("discharge").getAllItems()
        dataTidelevel = self.combo_boxes.get("tidelevel").getAllItems()
        dataWatershed = self.combo_boxes.get("watershed").getAllItems()

        ui_data = {
            "targetText": targetText,
            "dataWaterlevel": dataWaterlevel,
            "dataRainfall": dataRainfall,
            "dataDaminlet": dataDaminlet,
            "dataDamrelease": dataDamrelease,
            "dataDischarge": dataDischarge,
            "dataTidelevel": dataTidelevel,
            "dataWatershed": dataWatershed,
            "cb_dsCol_target": self.cb_dsCol_target.currentIndex(),
            "cb_dsCol_waterlevel": self.cb_dsCol_waterlevel.currentIndex(),
            "cb_dsCol_rainfall": self.cb_dsCol_rainfall.currentIndex(),
            "cb_dsCol_discharge": self.cb_dsCol_discharge.currentIndex(),
            "cb_dsCol_daminlet": self.cb_dsCol_daminlet.currentIndex(),
            "cb_dsCol_damrelease": self.cb_dsCol_damrelease.currentIndex(),
            "cb_dsCol_tidelevel": self.cb_dsCol_tidelevel.currentIndex(),
            "cb_dsCol_watershed": self.cb_dsCol_watershed.currentIndex(),
            
            "cb_dataset_startYear": self.cb_dataset_startYear.currentText(),
            "cb_dataset_endYear": self.cb_dataset_endYear.currentText(),
            "dt_dataset_startTime": self.dt_dataset_startTime.text(),
            "dt_dataset_endTime": self.dt_dataset_endTime.text(),

            "ckb_ds_preProcessing_predictRainVal" : self.ckb_ds_preProcessing_predictRainVal.isChecked(),            
            "txtBox_ds_preProcessing_predictRainHour" : self.txtBox_ds_preProcessing_predictRainHour.text().split(','),            
            "rb_dataset_periodDate" : self.rb_dataset_periodDate.isChecked(),
            "rb_dataset_periodYear" : self.rb_dataset_periodYear.isChecked(),

            "ckb_ds_preProcessing_noRain" : self.ckb_ds_preProcessing_noRain.isChecked(),
            "txtBox_ds_preProcessing_noRain" : self.txtBox_ds_preProcessing_noRain.text().strip(),
            "sp_ds_preProcessing_noRainVal" : self.sp_ds_preProcessing_noRainVal.isChecked(),
            "txtBox_ds_preProcessing_accRainHour": self.txtBox_ds_preProcessing_accRainHour.text().strip(),
            "ckb_ds_preProcessing_month" : self.ckb_ds_preProcessing_month.isChecked(),
            "rb_ds_preProcessing_month" : self.rb_ds_preProcessing_month.isChecked(),
            "rb_ds_preProcessing_date" : self.rb_ds_preProcessing_date.isChecked(),
            "sp_ds_preProcessing_startMonth" : self.sp_ds_preProcessing_startMonth.currentText(),
            "sp_ds_preProcessing_endMonth" : self.sp_ds_preProcessing_endMonth.currentText(),
            "sp_ds_preProcessing_startDate" : self.sp_ds_preProcessing_startDate.text(),
            "sp_ds_preProcessing_endDate" : self.sp_ds_preProcessing_endDate.text(),

            "rb_ds_leadtimeBasic" : self.rb_ds_leadtimeBasic.isChecked(),
            "ckb_ds_leadtimeHarf" : self.ckb_ds_leadtimeHarf.isChecked(),
            "ckb_ds_leadtime1h" : self.ckb_ds_leadtime1h.isChecked(),
            "ckb_ds_leadtime2h" : self.ckb_ds_leadtime2h.isChecked(),
            "ckb_ds_leadtime3h" : self.ckb_ds_leadtime3h.isChecked(),
            "ckb_ds_leadtime4h" : self.ckb_ds_leadtime4h.isChecked(),
            "ckb_ds_leadtime5h" : self.ckb_ds_leadtime5h.isChecked(),
            "ckb_ds_leadtime6h" : self.ckb_ds_leadtime6h.isChecked(),
            "rb_ds_leadtimeTimeseries" : self.rb_ds_leadtimeTimeseries.isChecked(),
            "cb_ds_leadtimeTarget" : self.cb_ds_leadtimeTarget.currentText(),
            "cb_ds_leadtimeTerm" : self.cb_ds_leadtimeTerm.currentText(),
            "cb_ds_leadtimeUnit" : self.cb_ds_leadtimeUnit.currentIndex() 
        }

        # set_summury
        
        ###############################

        # set_date
        search_date = ''
        # 월별조회하기
        if ui_data["rb_dataset_periodYear"]:
            startYear = int(ui_data["cb_dataset_startYear"])
            endYear = int(ui_data["cb_dataset_endYear"])
            search_date = f"{startYear}-01-01 ~ {endYear}-12-31"
        # 상세기간별조회하기
        if ui_data["rb_dataset_periodDate"]:
            start = ui_data["dt_dataset_startTime"]
            end = ui_data["dt_dataset_endTime"]
            search_date = f"{start} ~ {end}"

        # set_leadtime
        lead_time = ''
        termUnitText = "h"
        if ui_data["rb_ds_leadtimeBasic"]:
            lead_times = []
            if ui_data["ckb_ds_leadtimeHarf"]:
                lead_times.append("0.5h")
            if ui_data["ckb_ds_leadtime1h"]:
                lead_times.append("1h")
            if ui_data["ckb_ds_leadtime2h"]:
                lead_times.append("2h")
            if ui_data["ckb_ds_leadtime3h"]:
                lead_times.append("3h")
            if ui_data["ckb_ds_leadtime4h"]:
                lead_times.append("4h")
            if ui_data["ckb_ds_leadtime5h"]:
                lead_times.append("5h")
            if ui_data["ckb_ds_leadtime6h"]:
                lead_times.append("6h")
            lead_time = ",".join(lead_times)
        else:
            targetTime = int(ui_data["cb_ds_leadtimeTarget"])
            termTime = int(ui_data["cb_ds_leadtimeTerm"])
            termUnit = 0
            termUnitText = "h"
            if (ui_data["cb_ds_leadtimeUnit"]== 0):     #시간
                termUnit = 60
                termUnitText = "h"
            elif (ui_data["cb_ds_leadtimeUnit"]== 1):   #분
                termUnit = termTime
                termUnitText = "min"
            else:
                termUnit = 0
                termUnitText = "h"
            lead_time=f"Total {targetTime} hours, at {termTime} {termUnitText} intervals"

        # preset_option
        ck_no_rain = ui_data["ckb_ds_preProcessing_noRain"]
        info_no_rain = ''
        if ck_no_rain:
            info_no_rain = f"({ui_data["txtBox_ds_preProcessing_noRain"]}h)"

        ck_culcum_rain = ui_data["sp_ds_preProcessing_noRainVal"]
        info_culcum_rain = ''
        if ck_culcum_rain:
            info_culcum_rain = f"({ui_data["txtBox_ds_preProcessing_accRainHour"]}h)"

        ck_preset_period = ui_data["ckb_ds_preProcessing_month"]
        info_preset_period = ''
        if ck_preset_period:
            if ui_data["rb_ds_preProcessing_month"]:
                stdMonth = ui_data["sp_ds_preProcessing_startMonth"]
                endMonth = ui_data["sp_ds_preProcessing_endMonth"]
                info_preset_period = f"({stdMonth} - {endMonth})"
            else:
                stdDate = ui_data["sp_ds_preProcessing_startDate"]
                endDate = ui_data["sp_ds_preProcessing_endMonth"]
                stdDay = stdDate[0:2] + stdDate[3:5]
                endDay = endDate[0:2] + endDate[3:5]
                info_preset_period = f"({stdDay} - {endMonth})"

        ck_predicted_rainfall = ui_data["ckb_ds_preProcessing_predictRainVal"]
        info_predicted_rainfall = ''
        if ck_predicted_rainfall:
            hours = self.txtBox_ds_preProcessing_predictRainHour.text()
            info_predicted_rainfall = f"({hours}h)"

        # 문자열 생성
        summary = f"""
        [Target Point]: 
        - {ui_data['targetText']}

        [Reference Point]
        - Waterlevel  : {ui_data['dataWaterlevel'] if ui_data['dataWaterlevel'] else 'X'}
        - Rainfall    : {ui_data['dataRainfall'] if ui_data['dataRainfall'] else 'X'}
        - Dam Inlet   : {ui_data['dataDaminlet'] if ui_data['dataDaminlet'] else 'X'}
        - Dam Release : {ui_data['dataDamrelease'] if ui_data['dataDamrelease'] else 'X'}
        - Discharge   : {ui_data['dataDischarge'] if ui_data['dataDischarge'] else 'X'}
        - Tide Level  : {ui_data['dataTidelevel'] if ui_data['dataTidelevel'] else 'X'}
        - Watershed   : {ui_data['dataWatershed'] if ui_data['dataWatershed'] else 'X'}

        [Period]:
        - {search_date}

        [Lead Time]:
        - {lead_time}

        [Preprocessing Options]
        - No-Rainfall Event : {ck_no_rain}{info_no_rain}
        - Cumulative Rainfall Creation : {ck_culcum_rain}{info_culcum_rain}
        - Period Setting : {ck_preset_period}{info_preset_period}
        - Predicted Rainfall : {ck_predicted_rainfall}{info_predicted_rainfall}
        """

        # 메시지 박스 띄우기
        buttonReply = QMessageBox.information(self, 'Dataset Creation',
                                              f"Create dataset with the configured information??\n{summary}",
                                              QMessageBox.Yes | QMessageBox.Cancel)        
        if buttonReply == QMessageBox.Cancel:
            return

        # 버튼 비활성화
        self.btn_makeDataset.setEnabled(False)

        # 마우스 커서 대기 상태로 변경 (UI 스레드)
        self.setCursor(QtGui.QCursor(QtCore.Qt.WaitCursor))
        
        self.tbl_makeDataset.clear()
        self.tbl_makeDataset.setRowCount(0)
        self.tbl_makeDataset.setColumnCount(0)
        self.tbl_preProcessing_makeDataset.clear()
        self.tbl_preProcessing_makeDataset.setRowCount(0)
        self.tbl_preProcessing_makeDataset.setColumnCount(0)

        runnable = RunnableTask(lambda: self.MakeDataset(ui_data))

        # 오류 발생 시
        runnable.signals.error.connect(
            lambda msg: (
                QMessageBox.warning(self, "Dataset Creation", msg),
                setattr(self, "update_failed", True),  # 오류 플래그 세팅
                self.btn_makeDataset.setEnabled(True),
                self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))  
            )
        )

        # 진행 데이터 수신 (안전하게 감싸기)
        runnable.signals.progress.connect(
            lambda data: self.safeUpdateTables(ui_data, data)
        )

        # 완료 시
        runnable.signals.finished.connect(self.onDatasetFinished)

        self.threadpool.start(runnable)
            
    def safeUpdateTables(self, ui_data, data):
        try:
            self.updateTables(ui_data, data)
        except Exception as e:
            QMessageBox.warning(self, "Dataset Creation", f"{e}")
            self.update_failed = True
            
    def onDatasetFinished(self):
        self.btn_makeDataset.setEnabled(True)
        self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
        
        if not self.update_failed:
            QMessageBox.information(self, "Dataset Creation", "Dataset Creation has been completed.")
            
    # tab [데이터셋생성] Make Dataset button
    def MakeDataset(self, ui_data):

        import mariadb
        
        # column header setting
        columnHeader = []
        columnHeader.append("Date")

        resultset_now = []
        resultset_after = []
        resultset_predWS = []
        leadTexts = []
        leadControlText = []

        # 1. 지점정보
        targetText = ui_data["targetText"]
        dataWaterlevel = ui_data["dataWaterlevel"]
        dataRainfall = ui_data["dataRainfall"]
        dataDaminlet = ui_data["dataDaminlet"]
        dataDamrelease = ui_data["dataDamrelease"]
        dataDischarge = ui_data["dataDischarge"]
        dataTidelevel = ui_data["dataTidelevel"]
        dataWatershed = ui_data["dataWatershed"]

        # 2. 자료정보(컬럼, 표준화자료/결측치보정자료/이상치보정자료)
        arrDataCol = ['DT_DATA', 'MI_DATA', 'OI_DATA']
        target_col = arrDataCol[ui_data["cb_dsCol_target"]]
        waterlevel_col = arrDataCol[ui_data["cb_dsCol_waterlevel"]]
        rainfall_col = arrDataCol[ui_data["cb_dsCol_rainfall"]]
        discharge_col = arrDataCol[ui_data["cb_dsCol_discharge"]]
        daminlet_col = arrDataCol[ui_data["cb_dsCol_daminlet"]]
        damrelease_col = arrDataCol[ui_data["cb_dsCol_damrelease"]]
        tidelevel_col = arrDataCol[ui_data["cb_dsCol_tidelevel"]]
        watershed_col = arrDataCol[ui_data["cb_dsCol_watershed"]]

        # 3. 기간정보
        star = ''
        end = ''
        sql_date = "date_format(DT_DATE, '%Y-%m-%d %H:%i') between '{0}' and '{1}'"
        # 월별조회하기
        if ui_data["rb_dataset_periodYear"]:
            startYear = int(ui_data["cb_dataset_startYear"])
            endYear = int(ui_data["cb_dataset_endYear"])
            startMonth = 1
            endMonth = 12

            sql_date = "(YEAR(DT_DATE) BETWEEN '{0}' AND '{1}') AND (MONTH(DT_DATE) BETWEEN '{2}' AND '{3}')"
            sql_date = sql_date.format(startYear, endYear, startMonth, endMonth)
        # 상세기간별조회하기
        if ui_data["rb_dataset_periodDate"]:
            start = ui_data["dt_dataset_startTime"]
            end = ui_data["dt_dataset_endTime"]
            sql_date = "date_format(DT_DATE, '%Y-%m-%d %H:%i') between '{0}' and '{1}'".format(start, end)

        # 3-1. 기간정보인데, 유역예상강우 사용할 경우 -- 유역조회시에만 적용할 것
        bPredictRain = ui_data["ckb_ds_preProcessing_predictRainVal"]
        sql_predictRainWS = ''
        sql_predictDate = ''
        if (bPredictRain):            
            lstPredRainTerm = [] # 예측강우시간
            tmpPredRainTerm = ui_data["txtBox_ds_preProcessing_predictRainHour"]
            for tmpNumber in tmpPredRainTerm:
                try:
                    lstPredRainTerm.append(int(str(tmpNumber).strip()))
                except ValueError:                    
                    pass

            # 예측강우 최대시간만큼 데이터 가져오기 (시간)
            if (len(lstPredRainTerm)>0):
                predTimeMaxVal = max(lstPredRainTerm)

                pred_startDt = ''
                pred_endDt = ''

                # 월별조회하기
                if ui_data["rb_dataset_periodYear"]:
                    startYear = int(ui_data["cb_dataset_startYear"])
                    endYear = int(ui_data["cb_dataset_endYear"])

                    stTime = '{0}-01-01 00:00'.format(startYear)
                    edTime = '{0}-12-31 23:50'.format(endYear)                    
                    tmpEndTime = pd.to_datetime(edTime) + timedelta(minutes=60*predTimeMaxVal) 

                    pred_startDt = stTime
                    pred_endDt = str(tmpEndTime.strftime("%Y-%m-%d %H:%M"))

                # 상세기간별조회하기
                if ui_data["rb_dataset_periodDate"]:
                    stTime = ui_data["dt_dataset_startTime"]
                    edTime = ui_data["dt_dataset_endTime"]
                    tmpEndTime = pd.to_datetime(edTime) + timedelta(minutes=60*predTimeMaxVal) 

                    pred_startDt = stTime
                    pred_endDt = str(tmpEndTime.strftime("%Y-%m-%d %H:%M"))

                sql_predictDate = "date_format(DT_DATE, '%Y-%m-%d %H:%i') between '{0}' and '{1}'".format(pred_startDt, pred_endDt)
     
        # 데이터조회 #########################################################################################

        conn = None

        try:

            self.db_config["database"] = self.db_tablespace
            conn = mariadb.connect(**self.db_config)
            cur = conn.cursor()

            # 데이터조회 - 지점데이터조회

            # 1. get Target Data
            if targetText != "":
                columnHeader.append('Target_' + targetText)
                select_all_query = "select OBS_ID, DT_DATE, {0} from waterlevel where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                    target_col, targetText, sql_date)
                cur.execute(select_all_query)
                resultset = cur.fetchall()
                resultset_now.append(resultset)

            # 2. get Waterlevel Data
            for obs_row in range(len(dataWaterlevel)):
                if (dataWaterlevel[obs_row].strip() == ''): break
                columnHeader.append('WL_' + dataWaterlevel[obs_row].strip())
                select_all_query = "select OBS_ID, DT_DATE, {0} from waterlevel where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                    waterlevel_col, dataWaterlevel[obs_row].strip(), sql_date)
                cur.execute(select_all_query)
                resultset = cur.fetchall()
                resultset_now.append(resultset)

            # 3. get Rainfall Data
            for obs_row in range(len(dataRainfall)):
                if (dataRainfall[obs_row].strip() == ''): break
                columnHeader.append('RF_' + dataRainfall[obs_row].strip())
                select_all_query = "select OBS_ID, DT_DATE, {0} from rainfall where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                    rainfall_col, dataRainfall[obs_row].strip(), sql_date)
                cur.execute(select_all_query)
                resultset = cur.fetchall()
                resultset_now.append(resultset)

            # 4. get DamInlet Data
            for obs_row in range(len(dataDaminlet)):
                if (dataDaminlet[obs_row].strip() == ''): break
                columnHeader.append('DI_' + dataDaminlet[obs_row].strip())
                select_all_query = "select OBS_ID, DT_DATE, {0} from daminlet where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                    daminlet_col, dataDaminlet[obs_row].strip(), sql_date)
                cur.execute(select_all_query)
                resultset = cur.fetchall()
                resultset_now.append(resultset)

            # 5. get DamRelease Data
            for obs_row in range(len(dataDamrelease)):
                if (dataDamrelease[obs_row].strip() == ''): break
                columnHeader.append('DR_' + dataDamrelease[obs_row].strip())
                select_all_query = "select OBS_ID, DT_DATE, {0} from damrelease where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                    damrelease_col, dataDamrelease[obs_row].strip(), sql_date)
                cur.execute(select_all_query)
                resultset = cur.fetchall()
                resultset_now.append(resultset)

            # 6. get Flowarate Data
            for obs_row in range(len(dataDischarge)):
                if (dataDischarge[obs_row].strip() == ''): break
                columnHeader.append('DC_' + dataDischarge[obs_row].strip())
                select_all_query = "select OBS_ID, DT_DATE, {0} from discharge where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                    discharge_col, dataDischarge[obs_row].strip(), sql_date)
                cur.execute(select_all_query)
                resultset = cur.fetchall()
                resultset_now.append(resultset)

            # 7. get Elevation Data
            for obs_row in range(len(dataTidelevel)):
                if (dataTidelevel[obs_row].strip() == ''): break
                columnHeader.append('TE_' + dataTidelevel[obs_row].strip())
                select_all_query = "select OBS_ID, DT_DATE, {0} from tidelevel where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                    tidelevel_col, dataTidelevel[obs_row].strip(), sql_date)
                cur.execute(select_all_query)
                resultset = cur.fetchall()
                resultset_now.append(resultset)

            # 8. get Thiessen Data
            for obs_row in range(len(dataWatershed)):
                if (dataWatershed[obs_row].strip() == ''): break

                # 유역기본값
                columnHeader.append('WS_' + dataWatershed[obs_row].strip())
                select_all_query = "select OBS_ID, DT_DATE, {0} from watershed where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                    watershed_col, dataWatershed[obs_row].strip(), sql_date)
                cur.execute(select_all_query)
                resultset = cur.fetchall()
                resultset_now.append(resultset)

                # 유역예측강우 정보 사용할 경우의 값
                bPredictRain = ui_data["ckb_ds_preProcessing_predictRainVal"]
                if (bPredictRain):            
                    select_all_query = "select OBS_ID, DT_DATE, {0} from watershed where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                        watershed_col, dataWatershed[obs_row].strip(), sql_predictDate)
                    cur.execute(select_all_query)
                    resultset = cur.fetchall()
                    resultset_predWS.append(resultset)


            # 3. 리드타임 자료조회
            termUnitText = "H"
            if ui_data["rb_ds_leadtimeBasic"]:
                if ui_data["ckb_ds_leadtimeHarf"]:
                    columnHeader.append('Leadtime_0.5H')
                    leadTexts.append(30)
                    leadControlText.append(0.5)
                if ui_data["ckb_ds_leadtime1h"]:
                    columnHeader.append('Leadtime_1H')
                    leadTexts.append(60)
                    leadControlText.append(1)
                if ui_data["ckb_ds_leadtime2h"]:
                    columnHeader.append('Leadtime_2H')
                    leadTexts.append(120)
                    leadControlText.append(2)
                if ui_data["ckb_ds_leadtime3h"]:
                    columnHeader.append('Leadtime_3H')
                    leadTexts.append(180)
                    leadControlText.append(3)
                if ui_data["ckb_ds_leadtime4h"]:
                    columnHeader.append('Leadtime_4H')
                    leadTexts.append(240)
                    leadControlText.append(4)
                if ui_data["ckb_ds_leadtime5h"]:
                    columnHeader.append('Leadtime_5H')
                    leadTexts.append(300)
                    leadControlText.append(5)
                if ui_data["ckb_ds_leadtime6h"]:
                    columnHeader.append('Leadtime_6H')
                    leadTexts.append(360)
                    leadControlText.append(6)
            if ui_data["rb_ds_leadtimeTimeseries"]:
                targetTime = int(ui_data["cb_ds_leadtimeTarget"])
                termTime = int(ui_data["cb_ds_leadtimeTerm"])
                termUnit = 0
                termUnitText = "H"

                if (ui_data["cb_ds_leadtimeUnit"]== 0):
                    termUnit = 60
                    termUnitText = "H"
                elif (ui_data["cb_ds_leadtimeUnit"]== 1):
                    termUnit = termTime
                    termUnitText = "min"
                else:
                    termUnit = 0
                    termUnitText = "H"

                for dataTime in range(int((60 * targetTime) / termUnit)):
                    leadtimeData = 0
                    if (ui_data["cb_ds_leadtimeUnit"] == 0):  # 시간
                        leadtimeData = int(60 * (dataTime + 1) / 60)
                        columnHeader.append('Leadtime_' + str(leadtimeData) + termUnitText)
                        leadControlText.append((dataTime + 1))
                    elif (ui_data["cb_ds_leadtimeUnit"] == 1):  # 분
                        leadtimeData = termUnit * (dataTime + 1)
                        columnHeader.append('Leadtime_' + str(leadtimeData) + termUnitText)
                        leadControlText.append(termUnit * (dataTime + 1))
                    else:
                        leadtimeData = 0
                        termUnitText = "H"

                    leadTexts.append(termUnit * (dataTime + 1))

            # 리드타임 조회
            for leads in range(len(leadTexts)):
                lead_text = str(leadTexts[leads])
                if ui_data["rb_dataset_periodYear"]:
                    startYear = int(ui_data["cb_dataset_startYear"])
                    endYear = int(ui_data["cb_dataset_endYear"])
                    startMonth = 1
                    endMonth = 12
                    sql_query = "SELECT obs_id, dt_date, {0}  FROM (SELECT obs_id AS oid, dt_date AS odate, {1} AS odata FROM waterlevel WHERE obs_id='{2}' and {3}) AS sel_data, waterlevel WHERE OBS_ID='{4}' and DATE_ADD(sel_data.odate, INTERVAL {5} MINUTE) = dt_date ORDER BY DT_DATE"
                    select_all_query_after = sql_query.format(target_col, target_col, targetText, sql_date, targetText, leadTexts[leads])
                    cur.execute(select_all_query_after)
                elif ui_data["rb_dataset_periodDate"]:
                    sql_date = "date_format(DT_DATE, '%Y-%m-%d %H:%i') between DATE_FORMAT(DATE_ADD('{0}', INTERVAL {1} MINUTE), '%Y-%m-%d %H:%i') and DATE_FORMAT(DATE_ADD('{2}', INTERVAL {3} MINUTE), '%Y-%m-%d %H:%i')"
                    select_all_query_after = "select OBS_ID, DT_DATE, {0} from waterlevel where OBS_ID = '{1}' and {2} ORDER BY DT_DATE"
                    sql_date = sql_date.format(start, leadTexts[leads], end, leadTexts[leads])
                    select_all_query_after = select_all_query_after.format(target_col, targetText, sql_date)
                    cur.execute(select_all_query_after)
                else:
                    print("no data")

                resultset = cur.fetchall()
                resultset_after.append(resultset)

        except mariadb.Error as e:
            #print(f"[데이터셋 생성] MariaDB 오류 발생: {e}")
            raise RuntimeError(f"[Dataset Creation] MariaDB Error Occurred: {e}")
        except Exception as e:
            #print(f"[데이터셋 생성] 기타 오류 {e}")
            raise RuntimeError(f"[Dataset Creation] Unknown Error {e}")
        finally:
            if conn:
                conn.close()

        columnPreHeader = columnHeader.copy()
        preDataset= []

        return {
            "columnHeader": columnHeader,
            "preColumnHeader": columnPreHeader,
            "resultset_now": resultset_now,
            "resultset_predWS": resultset_predWS,
            "resultset_after": resultset_after,
            "preDataset": preDataset,
            "leadTexts" :  leadTexts
        }

    def updateTables(self, ui_data, data):

        try:
            # MakeDataset 테이블
            columnHeader = data["columnHeader"]
            columnPreHeader = data["preColumnHeader"]
            resultset_now = data["resultset_now"]
            resultset_after = data["resultset_after"]
            resultset_predWS = data["resultset_predWS"]
            preDataset = data["preDataset"]
            leadTexts = data["leadTexts"]

            # 결과확인 - 1. 조회결과가 없으면 리턴
            if all(len(inner) == 0 for inner in resultset_now):
                #self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
                #QMessageBox.warning(self, '데이터셋 생성', "조회된 데이터가 없습니다.", QMessageBox.Ok)            
                #return
                raise ValueError("No data found.")

            # 결과확인 - 2. 관측소별 조회데이터 갯수가 다를 경우 관측소별 데이터정보 출력 후, 리턴
            isDataSame = True
            isFirstValue = 0
            isDataResultOK = True
            isDataResultText = []
            for idxs in range(len(resultset_now)):
                if idxs == 0:
                    isFirstValue = len(resultset_now[idxs])
                else:
                    isValue = len(resultset_now[idxs])
                    if isFirstValue != isValue:
                        self.tbl_makeDataset.clear()
                        self.tbl_makeDataset.setRowCount(0)
                        self.tbl_makeDataset.setColumnCount(0)
                        self.tbl_preProcessing_makeDataset.clear()
                        self.tbl_preProcessing_makeDataset.setRowCount(0)
                        self.tbl_preProcessing_makeDataset.setColumnCount(0)
                        isDataResultOK = False
                        break
            if (isDataResultOK == False):
                txtDataInfo = ""
                for i in range(0, len(resultset_now), 1):
                    txtDataType = columnHeader[i+1]
                    txtEachData = ""
                    if (len(resultset_now[i])>0):
                        txtEachData = "{0} ~ {1}".format(str(resultset_now[i][0][1]), str(resultset_now[i][len(resultset_now[i])-1][1]))
                    else:
                        txtEachData = "None"
                    txtDataInfo += txtDataType + " : " + txtEachData + "\n"

                #self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
                #QMessageBox.warning(self, '데이터셋 생성', "데이터의 갯수가 관측소별로 다릅니다.\n\n" + txtDataInfo, QMessageBox.Ok)
                #return    
                msg = "The number of data points varies by observation station.\n\n" + txtDataInfo
                raise ValueError(msg)    


            # 결과확인 - 3. 타겟관측소의 자료와 lead_time의 갯수가 다를 경우 관측소별 데이터정보 출력 후, 리턴
            isLeadResultOK = True
            isLeadResultText = []
            for idxs in range(len(resultset_after)):
                if isFirstValue != len(resultset_after[idxs]):
                    self.tbl_makeDataset.clear()
                    self.tbl_makeDataset.setRowCount(0)
                    self.tbl_makeDataset.setColumnCount(0)
                    self.tbl_preProcessing_makeDataset.clear()
                    self.tbl_preProcessing_makeDataset.setRowCount(0)
                    self.tbl_preProcessing_makeDataset.setColumnCount(0)
                    isLeadResultOK = False
                    break
            if (isLeadResultOK == False):
                txtDataInfo = ""            
                # Target관측소의 자료정보
                txtDataType = columnHeader[1]
                txtEachData = "{0} ~ {1}".format(str(resultset_now[0][0][1]), str(resultset_now[0][len(resultset_now[0]) - 1][1]))
                txtDataInfo += txtDataType + " : " + txtEachData + "\n"
                # 리드타임 자료정보
                nLeadColumnIdx = len(columnHeader) - len(leadTexts)
                nTargetCount = len(resultset_now[0])
                txtErrLeadData = ""
                for i in range(0, len(resultset_after), 1):
                    txtLeadType = columnHeader[nLeadColumnIdx+i]
                    nLeadCount = len(resultset_after[i])
                    if nTargetCount !=  nLeadCount:
                        txtErrLeadData += txtLeadType + " "

                txtDataInfo += "Failed to get " + txtErrLeadData + ".\n"
                #self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
                #QMessageBox.warning(self, '데이터셋 생성', "Target 관측소의 자료 갯수와 Leadtime 갯수가 다릅니다.\n\n" + txtDataInfo, QMessageBox.Ok)
                #return
                msg = "The number of data points for the Target station does not match the number of lead times.\n\n" + txtDataInfo
                raise ValueError(msg)    
               

            # 데이터셋 생성 결과 표시
            nb_row = len(resultset_now[0])
            nb_col = len(columnHeader)
            self.tbl_makeDataset.setRowCount(nb_row)
            self.tbl_makeDataset.setColumnCount(nb_col)
            self.tbl_makeDataset.setHorizontalHeaderLabels(columnHeader)

            # [전처리옵션] ##########################################################################################

            #columnPreHeader = columnHeader.copy()

            # 강우컬럼찾기
            find_rain = 'RF_'
            # 강우관측소번호리스트
            rainList = [i - 1 for i in range(len(columnPreHeader)) if find_rain in columnPreHeader[i]]

            # 유역컬럼찾기
            find_watershed = 'WS_'
            watershedList = [i - 1 for i in range(len(columnPreHeader)) if find_watershed in columnPreHeader[i]]

            # 누적강우생성시 정보 설정
            bAccRainDelete = ui_data["sp_ds_preProcessing_noRainVal"] #self.sp_ds_preProcessing_noRainVal.isChecked()
            lstAccRainTerm = [] # 누적강우시간
            lstAccRange = []    # 누적강우범위(시간*한시간6개data)
            if (bAccRainDelete):
                tmpAccRainTerm = ui_data["txtBox_ds_preProcessing_accRainHour"]#self.txtBox_ds_preProcessing_accRainHour.text().split(',')
                for tmpNumber in tmpAccRainTerm:
                    try:
                        lstAccRange.append(int(tmpNumber.strip())*6)
                        lstAccRainTerm.append(str(tmpNumber).strip())
                    except ValueError:
                        pass
            arrAccRain = []
            if len(rainList) > 0:
                for i in range(len(rainList)):
                    newList = [j[2] for j in resultset_now[rainList[i]]]
                    arrAccRain.append(newList)

            # 예측강우생성시 정보 설정 
            bPredictRain = ui_data["ckb_ds_preProcessing_predictRainVal"]#self.ckb_ds_preProcessing_predictRainVal.isChecked()
            lstPredRainTerm = [] # 예측강우시간
            if (bPredictRain):
                tmpPredRainTerm = ui_data["txtBox_ds_preProcessing_predictRainHour"]#self.txtBox_ds_preProcessing_predictRainHour.text().split(',')
                for tmpNumber in tmpPredRainTerm:
                    try:
                        lstPredRainTerm.append(str(tmpNumber).strip())
                    except ValueError:
                        pass

            # 무강우사상삭제시 정보 설정
            arrNoRainIdx = []
            rainSum = 0.0
            bNoRainDelete = ui_data["ckb_ds_preProcessing_noRain"]#self.ckb_ds_preProcessing_noRain.isChecked()
            nNoRainRange = 0
            nDayRange = 0
            nRainIndex = 0
            if (bNoRainDelete):
                nNoRainRange = int(ui_data["txtBox_ds_preProcessing_noRain"])#self.txtBox_ds_preProcessing_noRain.text().strip())
                nDayRange = 6 * nNoRainRange  # 한시간6개 데이터 * 전후n시간 (n시간 무강우사상 데이터범위)        

            # 무강우사상삭제시, 전처리시트도 컬럼에 변화없음
            if (bNoRainDelete == True):
                self.tbl_preProcessing_makeDataset.setRowCount(nb_row)
                self.tbl_preProcessing_makeDataset.setColumnCount(nb_col)
                self.tbl_preProcessing_makeDataset.setHorizontalHeaderLabels(columnHeader)

            # 누적강우표시시, 누적강우컬럼이 (강우관측소지점*누적강우갯수) 만큼 추가됨
            if (bAccRainDelete == True):
                nb_col_acc = len(columnPreHeader) + (len(rainList)*len(lstAccRainTerm))
                startraincol = len(columnPreHeader) - len(leadTexts)  # 리드타임컬럼시작인덱스
                for i in range(len(rainList) - 1, -1, -1):
                    idxRF = rainList[i] + 1
                    for j in range(len(lstAccRainTerm) - 1, -1, -1):
                        strRfName = "RF_cum" + str(lstAccRainTerm[j]) + "_" + columnPreHeader[idxRF].strip("RF_")
                        columnPreHeader.insert(startraincol, strRfName)

                # 전후8시간 무강우사상 삭제할 경우는 데이터만 삭제
                self.tbl_preProcessing_makeDataset.setRowCount(nb_row)
                self.tbl_preProcessing_makeDataset.setColumnCount(nb_col_acc)
                self.tbl_preProcessing_makeDataset.setHorizontalHeaderLabels(columnPreHeader)


            # 예측강우표시시, 예측강우컬럼이 (유역지점*예측강우갯수) 만큼 추가됨
            if (bPredictRain == True):
                nb_col_pred = len(columnPreHeader) + (len(watershedList)*len(lstPredRainTerm))
                startraincol = len(columnPreHeader) - len(leadTexts)  # 리드타임컬럼시작인덱스
                for i in range(len(watershedList) - 1, -1, -1):
                    idxRF = watershedList[i] + 1
                    for j in range(len(lstPredRainTerm) - 1, -1, -1):
                        # .strip(".jpeg")
                        strRfName = "Predict_WS" + str(lstPredRainTerm[j]) + "_" + columnPreHeader[idxRF].strip("WS_")
                        columnPreHeader.insert(startraincol, strRfName)

                # 전후8시간 무강우사상 삭제할 경우는 데이터만 삭제
                self.tbl_preProcessing_makeDataset.setRowCount(nb_row)
                self.tbl_preProcessing_makeDataset.setColumnCount(nb_col_pred)
                self.tbl_preProcessing_makeDataset.setHorizontalHeaderLabels(columnPreHeader)


            # 기간필터링하기, 컬럼에 변화없음
            bShowMonth = ui_data["ckb_ds_preProcessing_month"]#self.ckb_ds_preProcessing_month.isChecked()  
            if (bNoRainDelete == False) and (bAccRainDelete == False) and bShowMonth:
                self.tbl_preProcessing_makeDataset.setRowCount(nb_row)
                self.tbl_preProcessing_makeDataset.setColumnCount(nb_col)
                self.tbl_preProcessing_makeDataset.setHorizontalHeaderLabels(columnHeader)
            
            # 테이블에 데이터 표출
            row_preset = 0

            rain_len = len(resultset_now[0])  # 미리 계산
            obs_index_map = {obs: idx for idx, obs in enumerate(rainList)}  # index 캐싱

            for row in range(nb_row):
                # now data
                for obs in range(len(resultset_now)):

                    # 전후8시간 무강우사상 삭제할 경우,
                    if ((bNoRainDelete==True) and (obs in rainList)):
                        
                        # 무강우사상 체크하기(계산)
                        rainSum = 0.0
                        obs_index = obs_index_map[obs]

                        start_idx = max(0, row - nDayRange)
                        end_idx = min(rain_len, row + nDayRange + 1)

                        lstSum = arrAccRain[obs_index][start_idx:end_idx]
                        rainSum = sum(filter(None, lstSum))

                        if rainSum > 0.0 and row not in arrNoRainIdx:
                            arrNoRainIdx.append(row)

                    # 누적강우를 선택했을경우, 이전부터 현재까지 누적시키기.
                    lstRainAcc = []
                    if ((bAccRainDelete==True) and (obs in rainList)):
                        arrAccIdx = rainList.index(obs)
                        # 누적강우 체크하기(계산) - 누적강우시간리스트만큼(6,9,12 등)                    
                        obs_index = rainList.index(obs)
                        for nAccRange in lstAccRange:
                            start_idx = max(0, row - nAccRange + 1)  # 현재 시각 포함해서 정확히 nAccRange 시간 누적
                            lstSum = arrAccRain[obs_index][start_idx : row + 1]
                            rainAcc = sum(filter(None, lstSum))
                            lstRainAcc.append(rainAcc)


                    # 원래데이터 출력
                    if obs == 0:  # 날짜,데이터
                        item = QTableWidgetItem(str(resultset_now[obs][row][1]))
                        item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                        self.tbl_makeDataset.setItem(row, obs, item)
                        item = QTableWidgetItem(str(resultset_now[obs][row][1]))
                        item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                        self.tbl_preProcessing_makeDataset.setItem(row_preset, obs, item)

                        itemText = str(resultset_now[obs][row][2])
                        if (itemText == 'None'):
                            itemText = ''

                        item = QTableWidgetItem(itemText)
                        item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                        self.tbl_makeDataset.setItem(row, obs + 1, item)
                        item = QTableWidgetItem(itemText)
                        item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                        self.tbl_preProcessing_makeDataset.setItem(row_preset, obs + 1, item)                    

                    else:  # 데이터
                        itemText = str(resultset_now[obs][row][2])
                        if (itemText == 'None'):
                            itemText = ''

                        item = QTableWidgetItem(itemText)
                        item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                        self.tbl_makeDataset.setItem(row, obs + 1, item)
                        item = QTableWidgetItem(itemText)
                        item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                        self.tbl_preProcessing_makeDataset.setItem(row_preset, obs + 1, item)

                        # (전처리옵션)누적강우가 선택되었다면,
                        if (bAccRainDelete==True) and (obs in rainList):
                            startAccCol = 0
                            # 예측강우도 선택되었다면,
                            if (bPredictRain==True):
                                startAccCol = len(columnPreHeader) - len(leadTexts) - (len(watershedList) * len(lstPredRainTerm)) - (len(arrAccRain) * len(lstAccRainTerm))
                            # 예측강우제외하고 누적강우만 선택되었다면,
                            else:
                                startAccCol = len(columnPreHeader) - len(leadTexts) - (len(arrAccRain) * len(lstAccRainTerm))

                            for idxAcc in range(len(lstRainAcc)):
                                itemData = str(lstRainAcc[idxAcc])
                                if (itemData == 'None'):
                                    itemData = ''
                                item = QTableWidgetItem(itemData)
                                item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                                self.tbl_preProcessing_makeDataset.setItem(row_preset,startAccCol + ((rainList.index(obs)*len(lstAccRainTerm)) + idxAcc),item)

                        # (전처리옵션)예측강우가 선택되었다면, 
                        if ((bPredictRain==True) and (obs in watershedList)):

                            startPredCol = 0
                            startPredCol = len(columnPreHeader) - len(leadTexts) - (len(watershedList) * len(lstPredRainTerm))

                            for idxPred in range(len(lstPredRainTerm)):                                
                                predData = resultset_predWS[watershedList.index(obs)][row+(int(lstPredRainTerm[idxPred])*6)][2]
                                itemData = str(predData)
                                if (itemData == 'None'):
                                    itemData = ''
                                item = QTableWidgetItem(itemData)
                                item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                                self.tbl_preProcessing_makeDataset.setItem(row_preset,startPredCol + ((watershedList.index(obs)*len(lstPredRainTerm)) + idxPred),item)             

                # leadtime data
                startleadcol = len(columnHeader) - len(leadTexts)            
                startPreleadCol = len(columnPreHeader) - len(leadTexts)
                for leads in range(len(leadTexts)):
                    itemText = str(resultset_after[leads][row][2])
                    if (itemText == 'None'):
                        itemText = ''

                    item = QTableWidgetItem(itemText)
                    item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                    self.tbl_makeDataset.setItem(row, startleadcol + leads, item)
                    item = QTableWidgetItem(itemText)
                    item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                    self.tbl_preProcessing_makeDataset.setItem(row_preset, startPreleadCol + leads, item)

                # 무강우나 월별데이터일경우 전처리시트에서 삭제하기
                # (전처리옵션)8시간무강우사상이 선택되었다면, 무강우일경우는 삭제, 아니면 출력
                if ((bNoRainDelete == True) and (rainSum <= 0)) :
                    self.tbl_preProcessing_makeDataset.removeRow(row_preset)
                # (전처리옵션)월별데이터 조회일경우, 해당 월이 아니면 삭제, index 다시 원래대로!
                elif ((bShowMonth == True) and (self.tbl_preProcessing_makeDataset.rowCount() > 0)):
                    Datetext = str(self.tbl_preProcessing_makeDataset.item(row_preset, 0).text())
                    datetime_format = "%Y-%m-%d %H:%M:%S"
                    datetimeText = pd.to_datetime(Datetext)
                    dayText = Datetext[5:7] + Datetext[8:10]
                    stdMonth = "01"
                    endMonth = "12"
                    stdDay = "01"
                    endDay = "31"
                    if ui_data["rb_ds_preProcessing_month"]:#(self.rb_ds_preProcessing_month.isChecked()):
                        stdMonth = ui_data["sp_ds_preProcessing_startMonth"]#self.sp_ds_preProcessing_startMonth.currentText()
                        endMonth = ui_data["sp_ds_preProcessing_endMonth"]#self.sp_ds_preProcessing_endMonth.currentText()
                    if ui_data["rb_ds_preProcessing_date"]:#(self.rb_ds_preProcessing_date.isChecked()):
                        stdDate = ui_data["sp_ds_preProcessing_startDate"]#self.sp_ds_preProcessing_startDate.text()
                        endDate = ui_data["sp_ds_preProcessing_endDate"]#elf.sp_ds_preProcessing_endDate.text()
                        stdDay = stdDate[0:2] + stdDate[3:5]
                        endDay = endDate[0:2] + endDate[3:5]

                    if ui_data["rb_ds_preProcessing_month"]:#(self.rb_ds_preProcessing_month.isChecked()):
                        if (int(stdMonth) > datetimeText.month) or (int(endMonth) < datetimeText.month):
                            self.tbl_preProcessing_makeDataset.removeRow(row_preset)
                        else:
                            row_preset = row_preset + 1
                    if ui_data["rb_ds_preProcessing_date"]: #(self.rb_ds_preProcessing_date.isChecked()):
                        if (int(stdDay) > int(dayText)) or (int(endDay) < int(dayText)):
                            self.tbl_preProcessing_makeDataset.removeRow(row_preset)
                        else:
                            row_preset = row_preset + 1
                # 전처리옵션으로 삭제된 경우가 아니라면, 행 증가시키기!
                else:
                    row_preset = row_preset + 1

            self.tbl_makeDataset.resizeColumnsToContents()
            self.tbl_preProcessing_makeDataset.resizeColumnsToContents()

            # 전처리데이터처리
            self.preHeader = columnPreHeader
            row_count = self.tbl_preProcessing_makeDataset.rowCount()
            col_count = self.tbl_preProcessing_makeDataset.columnCount()

            result_preset = [[] for _ in range(self.tbl_preProcessing_makeDataset.columnCount() - 1)]  # 날짜 제외한 열 수

            for row in range(self.tbl_preProcessing_makeDataset.rowCount()):
                dt_str = self.tbl_preProcessing_makeDataset.item(row, 0).text()
                dt_obj = pd.to_datetime(dt_str)

                for col in range(1, self.tbl_preProcessing_makeDataset.columnCount()):
                    obs_col = self.tbl_preProcessing_makeDataset.horizontalHeaderItem(col).text().split('_')
                    obs_id = obs_col[len(obs_col)-1]

                    val_item = self.tbl_preProcessing_makeDataset.item(row, col)
                    try:
                        value = float(val_item.text()) if val_item else None
                    except ValueError:
                        value = None

                    result_preset[col - 1].append((obs_id, dt_obj, value))

            self.preDataset  = result_preset

            # 데이터셋 그래프생성을 위한 정보 설정
            self.arrDsHeader = columnHeader
            self.arrDsData = resultset_now
        
        except Exception as e:
            # 오류 플래그 기록
            self.update_failed = True
            # 바로 오류 메시지 띄우기
            QMessageBox.warning(self, "Dataset Creation", f"{e}")
            # 버튼/커서 원복은 finished에서만 처리
            #QMessageBox.warning(self, "업데이트 오류", f"테이블 업데이트 중 오류 발생:\n{e}")
            # 버튼/커서 원복
            #self.btn_makeDataset.setEnabled(True)
            #self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
        #self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))        
        #QMessageBox.information(self, '데이터셋 생성', "데이터셋 생성을 완료했습니다.", QMessageBox.Ok)

    # tab [데이터셋생성] Save Dataset File Button
    def btn_saveDatasetFunc(self):
        
        # 데이터셋원본/전처리본 선택해서 저장하기 (tab_ds_result)
        if self.tab_ds_result.currentIndex() == 0:  # 데이터셋원본

            # 저장할 내용이 없을때 리턴
            if self.tbl_makeDataset.rowCount() == 0:
                QMessageBox.warning(self, 'Dataset Creation', "There is no data to save.", QMessageBox.Ok)
                return

            # Null값을 빼고 저장할지 확인 후 저장
            savefileName = ''
            buttonReply = QMessageBox.warning(self, 'Dataset Creation',
                                              "Save without NULL values?\n(Yes-Save excluding NULL values, No-Save all data)",
                                              QMessageBox.Yes | QMessageBox.No | QMessageBox.Cancel)
            isNullOK = False
            if buttonReply == QMessageBox.No:
                savefileName = 'Dataset_Target_{}_filtered_keep_null'.format(self.txtBox_dsRef_targetPoint_id.text().strip())
                isNullOK = True
            elif buttonReply == QMessageBox.Yes:                
                savefileName = 'Dataset_Target_{}_filtered_delete_null'.format(self.txtBox_dsRef_targetPoint_id.text().strip())
                isNullOK = False
            else:
                return

            file = QFileDialog.getSaveFileName(self, "Save file", savefileName, "*.csv")
            # 저장경로가 없을때 리턴
            if file[0] == '':
                return
            # 저장경로 정보 설정
            saveFilePath = file[0]

            saveFile = open(saveFilePath, 'w', newline='')
            wr = csv.writer(saveFile)

            # 데이터셋 컬럼정보 저장
            columnHeaders = []
            for j in range(self.tbl_makeDataset.columnCount()):
                columnHeaders.append(self.tbl_makeDataset.horizontalHeaderItem(j).text())
            wr.writerow(columnHeaders)

            if (isNullOK == True):
                # 데이터셋 자료정보 저장
                for row in range(self.tbl_makeDataset.rowCount()):
                    rowdata = []
                    for col in range(self.tbl_makeDataset.columnCount()):
                        text = str(self.tbl_makeDataset.item(row, col).text())
                        rowdata.append(text)
                    wr.writerow(rowdata)
            else:
                # 데이터셋 자료정보 저장 (Null값 제외하고 저장)
                for row in range(self.tbl_makeDataset.rowCount()):
                    rowdata = []
                    for col in range(self.tbl_makeDataset.columnCount()):
                        text = str(self.tbl_makeDataset.item(row, col).text())
                        rowdata.append(text)

                    if '' not in rowdata:
                        wr.writerow(rowdata)

            # 파일 저장
            saveFile.close()

            msgQuit = QMessageBox.information(self, 'Dataset Creation', "Dataset file has been saved. Do you want to check the file?",
                                              QMessageBox.Yes | QMessageBox.No)
            if msgQuit == QMessageBox.Yes:
                # 저장된 파일경로 열기(결과확인)
                saveFolderPath = os.path.dirname(saveFilePath)
                os.startfile(saveFolderPath)

        else:  # 데이터셋전처리본

            # 저장할 내용이 없을때 리턴
            if self.tbl_preProcessing_makeDataset.rowCount() == 0:
                QMessageBox.warning(self, 'Dataset Creation', "There is no data to save.", QMessageBox.Ok)
                return

            # Null값을 빼고 저장할지 확인 후 저장
            savefileName = ''
            buttonReply = QMessageBox.warning(self, 'Dataset Creation',
                                              "Save without NULL values?\n(Yes-Save excluding NULL values, No-Save all data)",
                                              QMessageBox.Yes | QMessageBox.No | QMessageBox.Cancel)
            isNullOK = False
            if buttonReply == QMessageBox.No:
                savefileName = 'Dataset_Target_{}_filtered_keep_null'.format(self.txtBox_dsRef_targetPoint_id.text())
                isNullOK = True
            elif buttonReply == QMessageBox.Yes:
                savefileName = 'Dataset_Target_{}_filtered_delete_null'.format(self.txtBox_dsRef_targetPoint_id.text())
                isNullOK = False
            else:
                return                        

            file = QFileDialog.getSaveFileName(self, "Save file", savefileName, "*.csv")
            # 저장경로가 없을때 리턴
            if file[0] == '':
                return
            # 저장경로 정보 설정
            saveFilePath = file[0]

            saveFile = open(saveFilePath, 'w', newline='')
            wr = csv.writer(saveFile)

            # 데이터셋 컬럼정보 저장
            columnHeaders = []
            for j in range(self.tbl_preProcessing_makeDataset.columnCount()):
                columnHeaders.append(self.tbl_preProcessing_makeDataset.horizontalHeaderItem(j).text())
            wr.writerow(columnHeaders)

            # 데이터셋 자료정보 저장
            if (isNullOK == True):
                # 데이터셋 자료정보 저장
                for row in range(self.tbl_preProcessing_makeDataset.rowCount()):
                    rowdata = []
                    for col in range(self.tbl_preProcessing_makeDataset.columnCount()):
                        text = str(self.tbl_preProcessing_makeDataset.item(row, col).text())
                        rowdata.append(text)
                    wr.writerow(rowdata)
            else:
                # 데이터셋 자료정보 저장 (Null값 제외하고 저장)
                for row in range(self.tbl_preProcessing_makeDataset.rowCount()):
                    rowdata = []
                    for col in range(self.tbl_preProcessing_makeDataset.columnCount()):
                        text = str(self.tbl_preProcessing_makeDataset.item(row, col).text())
                        rowdata.append(text)

                    if '' not in rowdata:
                        wr.writerow(rowdata)

            # 파일 저장
            saveFile.close()

            msgQuit = QMessageBox.information(self, 'Dataset Creation', "Dataset file has been saved. Do you want to check the file?",
                                              QMessageBox.Yes | QMessageBox.No)
            if msgQuit == QMessageBox.Yes:
                # 저장된 파일경로 열기(결과확인)
                saveFolderPath = os.path.dirname(saveFilePath)
                os.startfile(saveFolderPath)

    # tab [데이터셋생성] 그래프보기 버튼
    def ShowDatasetGraph(self):

        # 조회할 내용이 없을때 리턴
        if (self.tab_ds_result.currentIndex()==0):
            if self.tbl_makeDataset.rowCount() == 0:
                QMessageBox.warning(self, 'Dataset Creation', "No data to query", QMessageBox.Ok)
                return
            dlg_dashBoard = PyWPdsGraph(self.arrDsHeader, self.arrDsData)
            dlg_dashBoard.setWindowFlags(Qt.Window)
            dlg_dashBoard.exec_()

        else:
            if self.tbl_preProcessing_makeDataset.rowCount() == 0:
                QMessageBox.warning(self, 'Dataset Creation', "No data to query", QMessageBox.Ok)
                return
            
            dlg_dashBoard = PyWPdsGraph(self.preHeader, self.preDataset)
            dlg_dashBoard.setWindowFlags(Qt.Window)    
            dlg_dashBoard.exec_()

    # tab [하천수위예측 모형제작] call:파라메터 초기화
    def init_makemodelParam(self):
        self.sp_dl_dropOutRate.setValue(0)
        self.sp_dl_sequenceLength.setValue(0)
        self.sp_dl_hiddenDim.setValue(0)
        self.sp_dl_sizeOfBatch.setValue(0)
        self.sp_dl_learningRate.setValue(0)
        self.sp_dl_interation.setValue(0)
        self.sp_dl_valudatuinSplit.setValue(0)
        self.sp_dl_trainingRate.setValue(1.0)
        self.sp_dl_testRate.setValue(1.0)
        self.sp_dl_hiddenLayer.setValue(0)
        self.txtBox_dl_units.clear()
        self.cb_dl_activationFunc.setCurrentText("relu")
        self.cb_dl_optimizeFunc.setCurrentText("adam")
        self.cb_dl_lossFunc.setCurrentText("mean_squared_error")

    def auto_cast(self, value: str):
        try:
            # parsing 
            return ast.literal_eval(value)
        except (ValueError, SyntaxError):
            # original
            return value

    # tab [하천수위예측 모형제작] 파라메터(modelParam.txt) 불러오기 Button
    def LoadMakeModelParam(self):
        fileData, _ = QFileDialog.getOpenFileName(None, 'Open ModelParam file', '', 'txt file(modelParam*.txt)')
        # 선택된 파일이 없을때 리턴
        if fileData == '': return

        # control 초기화
        self.init_makemodelParam()                        

        modeldict_data = {}
        '''with open(fileData, "r", encoding="cp949") as file:
            for line in file:
                if ',' in line:
                    key, value = line.strip().split(',', 1)
                    key = key.strip()
                    value = value.strip()
                    if key == "watershed_with_target":
                        modeldict_data[key] = value
                    else:
                        modeldict_data[key] = self.auto_cast(value)'''
        try:
            with open(fileData, "r", encoding="cp949") as file:
                for lineno, line in enumerate(file, 1):
                    try:
                        if ',' not in line:
                            continue  # 콤마 없는 라인은 무시

                        key, value = line.strip().split(',', 1)
                        key = key.strip()
                        value = value.strip()

                        if key == "watershed_with_target":
                            modeldict_data[key] = value
                        else:
                            try:
                                modeldict_data[key] = self.auto_cast(value)
                            except (ValueError, TypeError) as e:
                                # 변환 실패 시 None으로 처리하고 로그
                                print(f"[Model Creation] Failed to convert value of {key} at line {lineno}. : {value} ({e})")
                                modeldict_data[key] = None

                    except Exception as e:
                        # split 등에서 발생할 수 있는 다른 예외 처리
                        print(f"[Model Creation] Failed to process line {lineno}.: {line.strip()} ({e})")

        except (FileNotFoundError, UnicodeDecodeError) as e:
            print(f"[Model Creation] Failed to open file.: {fileData} ({e})")

        # key_value_check
        model_keys = [
            "data_path",
            "save_path",
            "random_number",
            "model_name",
            "drop_out_rate",
            "seq_length",
            "hidden_dim",
            "size_of_batch",
            "learning_rate",
            "iterations",
            "patience_num",
            "training_rate",
            "test_start",
            "train_size",
            "test_size",
            "criteria_header",
            "criteria_wl",
            "Data_X_Column",
            "X_data_training_column_list",
            "watershed_with_target",
            "apply_realtime_Pred_WS",
            "realtime_Pred_WS_time",
            "Data_Y_Column",
            "Y_data_training_column_list",
            "data_dim",
            "output_dim",
            "lead_time",
            "Predict_time_index",
            "Predict_time_leadtime",
            "validation_rate",
            "hidden_layer_unit",
            "hidden_layer",
            "activation_func",
            "optimize_func",
            "loss_func",
            "Elapsed_time(sec)"
        ]

        missing_keys = [k for k in model_keys if k not in modeldict_data]
        if missing_keys:
            QMessageBox.warning(self, 'Model Creation', f"Please check the contents of the ModelParameter file.\nThe following keys are missing '{str(missing_keys)}'.", QMessageBox.Ok)
            return

        self.sp_dl_dropOutRate.setValue(float(modeldict_data.get("drop_out_rate")))
        self.sp_dl_sequenceLength.setValue(int(modeldict_data.get("seq_length")))
        self.sp_dl_hiddenDim.setValue(int(modeldict_data.get("hidden_dim")))
        self.sp_dl_sizeOfBatch.setValue(int(modeldict_data.get("size_of_batch")))
        self.sp_dl_learningRate.setValue(float(modeldict_data.get("learning_rate")))
        self.sp_dl_interation.setValue(int(modeldict_data.get("iterations")))
        self.sb_dl_patienceNum.setValue(int(modeldict_data.get("patience_num")))
        self.sp_dl_valudatuinSplit.setValue(float(modeldict_data.get("validation_rate")))
        self.sp_dl_trainingRate.setValue(float(modeldict_data.get("training_rate")))
        self.cb_dl_lossFunc.setCurrentText(str(modeldict_data.get("loss_func")))
        self.sp_dl_hiddenLayer.setValue(int(modeldict_data.get("hidden_layer")))

        tmp_hidden_layer_unit = re.findall(r'\d+', str(modeldict_data.get("hidden_layer_unit")))
        result_hidden_layer_unit = ', '.join(tmp_hidden_layer_unit)
        self.txtBox_dl_units.setText(result_hidden_layer_unit)
        
        self.cb_dl_activationFunc.setCurrentText(str(modeldict_data.get("activation_func")))
        self.cb_dl_optimizeFunc.setCurrentText(str(modeldict_data.get("optimize_func")))
        self.cb_dl_lossFunc.setCurrentText(str(modeldict_data.get("loss_func")))
        self.sp_dl_testRate.setValue(float(modeldict_data.get("test_start")))

        criteria_header = modeldict_data.get("criteria_header") 
        qlinetext =  ', '.join(criteria_header)
        self.txtBox_dl_criteriaHeader.setText(qlinetext)      
        
        criteria_wl = modeldict_data.get("criteria_wl") 
        qline_text = ', '.join(str(num) for num in criteria_wl)
        origin_wl_text = self.txtBox_dl_criteriaWL.text().strip()
        current_text = origin_wl_text.replace(", ", ",")  
        new_text = qline_text.strip().replace(", ", ",")

        if self.ckb_dl_applyRealtimePredWS.isEnabled():
            bPredws = modeldict_data.get("apply_realtime_Pred_WS")
            self.ckb_dl_applyRealtimePredWS.setCheckState(bPredws)
            if bPredws:
                pred_hour = int(modeldict_data.get("realtime_Pred_WS_time"))
                if (pred_hour>0) and (self.cb_dl_applyRealtimePredWsTime.count()>0):
                    index = self.cb_dl_applyRealtimePredWsTime.findText(str(pred_hour))
                    if (index>-1):
                        self.cb_dl_applyRealtimePredWsTime.setCurrentIndex(index)

        self.txtBox_dl_watershedWithTarget.setText(str(modeldict_data.get("watershed_with_target")))
        
        if not current_text:
            self.txtBox_dl_criteriaWL.setText(qline_text)  

        if (current_text!='') and (current_text != new_text):
            reply = QMessageBox.question(
                self,
                "Model Creation",
                f"Do you want to update the current value?\n\nCurrent Value : {origin_wl_text}\nNew value : {qline_text}",
                QMessageBox.Yes | QMessageBox.No,
                QMessageBox.No
            )

            if reply == QMessageBox.Yes:
                self.txtBox_dl_criteriaWL.setText(qline_text)
        else:
            self.txtBox_dl_criteriaWL.setText(qline_text)

    # tab [하천수위예측 모형제작] Save Path 설정 Button
    def SetMakeModelSavePath(self):
        path = QFileDialog.getExistingDirectory(self)
        if os.path.exists(path):
            self.txtBox_dl_saveParamPath.setText(path)
    
    # tab [하천수위예측 모형제작] ItemData All Select 설정 Checkbox
    def SetMakeModel_ItemDataSelect(self):
        bChecked = self.ckb_dl_itemdata_all.isChecked()        
        model_items = self.tbl_modelDatasetColumn.model()        
        if model_items is not None:
            for mIdx in range(model_items.rowCount()):                
                item = model_items.item(mIdx)                
                text = item.text()
                if text.startswith("Target_"):
                    item.setCheckState(True)
                else:
                    item.setCheckState(bChecked)

    # tab [하천수위예측 모형제작] Leadtime All Select 설정 Checkbox
    def SetMakeModel_LeadtimeSelect(self):
        bChecked = self.ckb_dl_leadtime_all.isChecked()        
        model_lead = self.tbl_modelDatasetLeadtime.model()        
        if model_lead is not None:
            for mIdx in range(model_lead.rowCount()):
                item = model_lead.item(mIdx)
                item.setCheckState(bChecked)

    # tab [하천수위예측 모형제작] call:모형제작에 필요한 입력자료 확인
    def checkInputParameter(self):
        # 1.데이터셋 파일이 설정되었는지,
        datafilepath = self.txtBox_dl_datasetFile.text()
        if datafilepath == "":
            QMessageBox.warning(self, 'Model Creation', "Please select a dataset file.", QMessageBox.Ok)
            return "None"

        # 1-1. 데이터셋에 Null값이 포함되었는지,
        #global isMakeModelDataNull
        if self.isMakeModelDataNull == True:
            QMessageBox.warning(self, 'Model Creation', "The dataset file contains NULL values.", QMessageBox.Ok)
            return "None"

        # 2.모형제작 저장경로(폴더) 설정되었는지,
        modelpath = self.txtBox_dl_saveParamPath.text()
        if modelpath == "":
            QMessageBox.warning(self, 'Model Creation', "Please select a folder to save the model.", QMessageBox.Ok)
            return "None"

        # 3.모형제작 모델명 설정되었는지,
        modelname = self.txtBox_dl_modelName.text()
        if modelname == "":
            QMessageBox.warning(self, 'Model Creation', "Please enter the model name.", QMessageBox.Ok)
            return "None"

        # 4.Hidden Layer 입력항목이 제대로 작성되었는지,
        tmpHiddenUnits = self.txtBox_dl_units.text().split(',')
        for tmpNumber in tmpHiddenUnits:
            try:
                intValues = int(tmpNumber.strip())
            except ValueError:
                QMessageBox.warning(self, 'Model Creation', "Please check the Hidden Layer input values.\n(Example: 32,64,32)",
                                    QMessageBox.Ok)
                return "None"

        # 5.Hidden Layer갯수에 따라 HiddenLayerUnit이 동일갯수로 입력되었는지,
        hiddenlayerunit = self.txtBox_dl_units.text().split(',')
        if (len(hiddenlayerunit) > 0 and hiddenlayerunit[0] != '' and int(hiddenlayerunit[0]) > 0):
            hidden_layer_unit = [int(i) for i in hiddenlayerunit]
            hiddenlayercount = self.sp_dl_hiddenLayer.value()
            if hiddenlayercount != len(hidden_layer_unit):
                QMessageBox.warning(self, 'Model Creation', "Please enter values according to the number of Hidden Layers.", QMessageBox.Ok)
                return "None"
        else:
            QMessageBox.warning(self, 'Model Creation', "Please enter values matching the number of Hidden Layers.", QMessageBox.Ok)
            return "None"

        # 6.사용할 컬럼이 선택되었는지 체크하기!
        useCol_checked = False
        model_col = self.tbl_modelDatasetColumn.model()
        for mIdx in range(model_col.rowCount() - 1):
            item = model_col.item(mIdx + 1)
            if item.checkState():
                useCol_checked = True
                break
        if useCol_checked == False:
            QMessageBox.warning(self, 'Model Creation', "Please select the data columns to use for model creation.", QMessageBox.Ok)
            return "None"

        # 7.사용할 leadtime이 설정되었는지,
        leadtime_checked = False
        model_lead = self.tbl_modelDatasetLeadtime.model()
        for mIdx in range(model_lead.rowCount()):
            item = model_lead.item(mIdx)
            if item.checkState():
                leadtime_checked = True
        if leadtime_checked == False:
            QMessageBox.warning(self, 'Model Creation', "Please select the lead time column to use for model creation.", QMessageBox.Ok)
            return "None"                
                            
        # 8.유역정보가 입력되었는지,
        watershed_code = self.txtBox_dl_watershedWithTarget.text()
        if watershed_code == "":
            QMessageBox.warning(self, 'Model Creation', "Please enter the standard watershed code information.", QMessageBox.Ok)
            return "None"
        
        # 9.유역정보가 데이터셋에 있는지,       
        watershed_info = False
        model_col = self.tbl_modelDatasetColumn.model()
        for mIdx in range(model_col.rowCount()):
            item = model_col.item(mIdx)
            col_text = item.text()
            col_text = col_text.replace('WS_', '')
            if ((col_text == watershed_code) and (int(item.checkState())>0)):
                watershed_info = True
                break        
        
        if watershed_info == False:
            QMessageBox.warning(self, 'Model Creation', "The standard watershed code (WS) information is missing or not selected in the dataset.", QMessageBox.Ok)
            return "None"
                        
        # 10. APPLY REALTIME PREDICT RAIN,
        bPredictRain = self.ckb_dl_applyRealtimePredWS.isChecked()
        if (bPredictRain):      
            # 9-1.predict_ws정보가 데이터셋에 있는지,
            watershed_rain_info = False
            model_col = self.tbl_modelDatasetColumn.model()
            for mIdx in range(model_col.rowCount()):
                item = model_col.item(mIdx)
                col_text = item.text()
                Predict_WS_hour =  int(self.cb_dl_applyRealtimePredWsTime.currentText())
                col_predictws = 'Predict_WS{}_'.format(Predict_WS_hour)
                col_text = col_text.replace(col_predictws, '')
                if ((col_text == watershed_code) and (int(item.checkState())>0)):
                    watershed_rain_info = True
                    break    
            if watershed_rain_info == False:
                QMessageBox.warning(self, 'Model Creation', "The standard watershed code (Predict_WS) information for applying observed rainfall is missing or not selected in the dataset.", QMessageBox.Ok)
                return "None"
        
            # 9-2.예측강우 사용시 예측강우 폴더가 설정되어 있는지,
            predict_rain_path = self.txtBox_dash_obsPath.text().strip()        
            if predict_rain_path == "":
                QMessageBox.warning(self, 'Model Creation', "To use Apply Realtime Predict_WS, please set the observed data folder path in System Configuration → Dashboard Settings.", QMessageBox.Ok)
                return "None"
            
        # 11. test_start가 1.0인지 확인,
        test_start_val = self.sp_dl_testRate.value()
        if test_start_val == 1.0:
            reply = QMessageBox.question(
                self,
                "Model Creation",
                f"No Test data is set. Do you want to proceed anyway?",
                QMessageBox.Yes | QMessageBox.No,
                QMessageBox.No
            )
            if reply == QMessageBox.Yes:
                return "OK"
            else:
                self.sp_dl_testRate.setFocus()
                return "None"
        elif test_start_val > 1.0:
            QMessageBox.warning(self, 'Model Creation', "Please reset the Test data.", QMessageBox.Ok)
            self.sp_dl_testRate.setFocus()
            return "None"
        else:
            return "OK"
            
    # [하천수위예측모형제작] Training_rate(sp_dl_trainingRate) == Test_start(sp_dl_testRate)        
    def ChangedValue_TrainingTestValue(self):
        val = self.sp_dl_trainingRate.value()
        self.sp_dl_testRate.setValue(val)

    # tab [하천수위예측 모형제작] 모형제작(Make Model) button
    def MakeModel(self):

        # PythonConsole이 있는지 확인
        self.load_pyConsole()

        # 모형제작에 필요한 입력자료 체크
        if self.checkInputParameter() == "None": return

        self.setCursor(QtGui.QCursor(QtCore.Qt.WaitCursor))

        # 모형제작 경로 설정
        datafilepath = self.txtBox_dl_datasetFile.text()
        modelpath = self.txtBox_dl_saveParamPath.text()
        modelname = self.txtBox_dl_modelName.text()

        save_path = modelpath + "/"
        model_name = modelname
        saveModelName = save_path + model_name
        saveReportPath = saveModelName + "/"

        if not os.path.exists(saveReportPath):
            os.makedirs(saveReportPath)
        else:
            buttonReply = QMessageBox.warning(self, 'Model Creation', "The folder already exists. Do you want to overwrite it?",
                                              QMessageBox.Yes | QMessageBox.No)
            if buttonReply == QMessageBox.No:
                self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
                return
            elif buttonReply == QMessageBox.Yes:
                shutil.rmtree(saveReportPath)
                os.makedirs(saveReportPath)
            else:                
                self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
                return
            
        # check_path_include_korean
        try:
            saveReportPath.encode('ascii')
        except UnicodeEncodeError:
            self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
            QMessageBox.warning(self, 'Model Creation', "The path contains Korean characters. Please change the path to use only English characters.", QMessageBox.Ok)
            return

        # load_dataset_file
        #data = pd.read_csv(datafilepath, encoding='cp949', date_parser=True)
        data = pd.DataFrame()
        try:
            data = pd.read_csv(datafilepath, encoding='utf-8')
            data['Date'] = pd.to_datetime(data['Date'], errors='coerce')
        except FileNotFoundError:
            self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
            print(f"[Model Creation] {datafilepath} not found. ")        
            return
        except Exception as e:
            self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
            print(f"[Model Creation] Failed to load. {e}")        
            return

        # 선택된 데이터셋 파일에서 설정자료 확인
        Data_X_Column = []  # data_col - data_column_index
        Data_Y_Column = []  # leadtime - data_column_index

        # 리드타임정보 확인
        lead_time = "timeseries"
        Predict_time_index = []  # leadtime - text
        Predict_time_leadtime = []  # leadtime - time

        model_col = self.tbl_modelDatasetColumn.model()
        for mIdx in range(model_col.rowCount()):
            item = model_col.item(mIdx)
            if item.checkState():
                Data_X_Column.append(mIdx + 1)

        model_lead = self.tbl_modelDatasetLeadtime.model()
        for mIdx in range(model_lead.rowCount()):
            item = model_lead.item(mIdx)
            if item.checkState():
                Data_Y_Column.append((model_col.rowCount() + mIdx + 1))
                leadtimeNm = item.text().strip().strip("Leadtime_")
                if (leadtimeNm.find("H") > 0):
                    leadtimeText = leadtimeNm.strip().strip("H""min")
                    Predict_time_index.append(leadtimeNm)
                    if (leadtimeText == "0.5"):
                         Predict_time_leadtime.append(30)
                    else:
                         Predict_time_leadtime.append(int(leadtimeText) * 60)
                else:
                    leadtimeText = leadtimeNm.strip().strip("H""min")
                    Predict_time_index.append(leadtimeNm)
                    Predict_time_leadtime.append(int(leadtimeText))

        data_dim = len(Data_X_Column)

        # Training parameter
        save_path = modelpath + "/"
        model_name = modelname
        patience_num = self.sb_dl_patienceNum.value()
        # save the start time
        start = time.time()
        # make a random number
        random_number = randrange(1, 1000)

        # dim : keras레이어에서 텐서의 차원수를 나타냄
        seq_length = self.sp_dl_sequenceLength.value()  # sequence length range : (10분~12시간 : 1~72)
        hidden_dim = self.sp_dl_hiddenDim.value()  # range : 1~256
        # data_dim : 학습 입력변수의 갯수 <- 선택된관측소에따라 자동입력(Target+Ref)
        # size_of_batch : 한번에 학습시킬 자료의 단위
        size_of_batch = self.sp_dl_sizeOfBatch.value()
        # output_dim : 예측 출력변수의 갯수 <- 관측소선택에따라 자동입력(타켓관측소)
        learning_rate = self.sp_dl_learningRate.value()  # 0.0004
        # iterations - epochs :재학습(학습데이터를 한번씩 모두 학습시킨 횟수, 10이라면 학습데이터를 총 10번 학습시켰음을 의미)
        iterations = self.sp_dl_interation.value()
        # Validation(검증)
        validation_rate = self.sp_dl_valudatuinSplit.value()  # 0.2  # 학습자료 중 validation에 활용하는 자료 비율
        # Dropout : 과적합방지용(Dropout(rate=0.2)라면 인풋데이터의 20%의 노드들을 무작위로 0으로 만드는 드롭아웃을 적용)
        drop_out_rate = self.sp_dl_dropOutRate.value()
                
        # 예측강우활용할 TargetPoint가 있는 곳의 표준유역코드
        watershed_with_target = self.txtBox_dl_watershedWithTarget.text()
        # 예측강우활용여부
        bUse_PredRain = self.ckb_dl_applyRealtimePredWS.isChecked()
        # 예측강우활용시, 예측강우시간정보
        if (bUse_PredRain):
            Predict_WS_hour =  int(self.cb_dl_applyRealtimePredWsTime.currentText())

        # activation_func : 활성화함수
        # linear-기본값으로 가중치결과값이 출력그대로 나옴
        # relu-ReLU함수, 은닉층에서 주로사용
        # sigmoid-주로 출력층에서 사용
        # softmax-출력값들의 합이 1.0이 되도록 하는함수로 보통 출력층에서 사용
        activation_func = self.cb_dl_activationFunc.currentText()  # 학습 모델의 activation function
        optimize_func = self.cb_dl_optimizeFunc.currentText()  # 학습 모델의 optimize function
        loss_func = self.cb_dl_lossFunc.currentText()  # 학습 모델의 loss function

        # traing hidden layer
        # hidden layer 갯수 = hidden layer unit 갯수
        hidden_layer = self.sp_dl_hiddenLayer.value()
        hidden_layer_unit = self.getHiddenLayerUnits(self.txtBox_dl_units.text())

        # rate of training data size
        training_rate = self.sp_dl_trainingRate.value()
        test_start = self.sp_dl_testRate.value()
        train_size = int(len(data) * training_rate)
        #test_size = len(data) - train_size
        test_size = len(data)-int(len(data)*test_start)

        # make data of training and test data
        data_training = data[:train_size]
        #data_test = data[train_size - seq_length:]
        data_test = data[int(len(data)*test_start):]
        
        # criteria_header
        criteria_header = []
        try:
            criteria_header = [x.strip() for x in self.txtBox_dl_criteriaHeader.text().split(',') if x.strip()]
        except ValueError:
            criteria_header = []

        # criteria_wl
        criteria_wl = []
        try:
            criteria_wl = [float(x.strip()) for x in self.txtBox_dl_criteriaWL.text().split(',') if x.strip()]
        except ValueError:
            criteria_wl = []

        # check the length of data
        print('Total = ', len(data))
        print('Train = ', len(data_training))
        print('Test = ', len(data_test))

        ####[ new model start ]#############################################################

        # data slicing

        X_data_training_drop = data_training.iloc[:,Data_X_Column]
        Y_data_training_drop = data_training.iloc[:,Data_Y_Column]

        X_data_test_drop = data_test.iloc[:,Data_X_Column]
        Y_data_test_drop = data_test.iloc[:,Data_Y_Column]

        # time slicing
        Current_time_test = data_test.iloc[seq_length-1:,[0]]
        Current_time_test = Current_time_test.reset_index(drop=True)

        # current time target data slicing
        Current_time_data = data_test.iloc[seq_length-1:,[1]]
        Current_time_data = Current_time_data.reset_index(drop=True)  

        # current time watershed rainfall data_slicing
        Current_time_watershed_rainfall = pd.DataFrame(data_test['WS_{}'.format(watershed_with_target)][seq_length-1:])
        Current_time_watershed_rainfall = Current_time_watershed_rainfall.reset_index(drop=True)
        Current_time_watershed_rainfall.columns = ['Rainfall']

        # Make a prediction time for each leadtime
        Predict_time = pd.DataFrame()
        for i in range(0, len(Predict_time_leadtime)): #Predict_time_leadtime
            Predict_time[Predict_time_index[i]] = pd.DatetimeIndex(Current_time_test['Date']) + timedelta(minutes=int(Predict_time_leadtime[i]))

        # extraction the header of X_data
        X_data_training_column = pd.DataFrame({"header" : X_data_training_drop.columns})
        X_data_training_column_list = list(X_data_training_column["header"])

        # extraction the header of XYdata
        Y_data_training_column = pd.DataFrame({"header" : Y_data_training_drop.columns})
        Y_data_training_column_list = list(Y_data_training_column["header"])

        # data normalize of training data
        output_dim = len(Predict_time_leadtime)
        
        Elapsed_time = int(time.time()-start)

        # save the model parameter
        modelParam_file = open(saveReportPath+"modelParam.txt", "w", encoding="cp949")
        print("data_path," + datafilepath, file=modelParam_file)
        print("save_path," + saveModelName, file=modelParam_file)  # saveModelName
        print("random_number,"+str(random_number), file=modelParam_file)
        print("model_name,"+model_name, file=modelParam_file)
        print("drop_out_rate,"+str(drop_out_rate), file=modelParam_file)
        print("seq_length,"+str(seq_length), file=modelParam_file)
        print("hidden_dim,"+str(hidden_dim), file=modelParam_file)
        print("size_of_batch,"+str(size_of_batch), file=modelParam_file)
        print("learning_rate,"+str(learning_rate), file=modelParam_file)
        print("iterations,"+str(iterations), file=modelParam_file)
        print("patience_num,"+str(patience_num), file=modelParam_file)
        print("training_rate,"+str(training_rate), file=modelParam_file)
        print("test_start,"+str(test_start), file=modelParam_file)
        print("train_size,"+str(train_size), file=modelParam_file)
        print("test_size,"+str(test_size), file=modelParam_file)        
        print("criteria_header,"+str(criteria_header), file=modelParam_file)
        print("criteria_wl,"+str(criteria_wl), file=modelParam_file)
        print("Data_X_Column,"+str(Data_X_Column), file=modelParam_file)
        print("X_data_training_column_list,"+str(X_data_training_column_list), file=modelParam_file)        
        # 유역정보추가
        print("watershed_with_target,"+str(watershed_with_target), file=modelParam_file)
        # 예측강우대체여부
        bUse_PredRain = self.ckb_dl_applyRealtimePredWS.isChecked()
        # 예측강우활용시, 예측강우시간정보와 예측강우대체시간
        if (bUse_PredRain):
            print("apply_realtime_Pred_WS, True", file=modelParam_file)
            print("realtime_Pred_WS_time, "+str(Predict_WS_hour), file=modelParam_file)
        else:
            print("apply_realtime_Pred_WS, False", file=modelParam_file)
            print("realtime_Pred_WS_time, "+str(0), file=modelParam_file)        
        print("Data_Y_Column,"+str(Data_Y_Column), file=modelParam_file)
        print("Y_data_training_column_list,"+str(Y_data_training_column_list), file=modelParam_file)
        print("data_dim,"+str(data_dim), file=modelParam_file)
        print("output_dim,"+str(output_dim), file=modelParam_file)
        print("lead_time,"+lead_time, file=modelParam_file)
        print("Predict_time_index,"+str(Predict_time_index), file=modelParam_file)
        print("Predict_time_leadtime,"+str(Predict_time_leadtime), file=modelParam_file)
        print("validation_rate,"+str(validation_rate), file=modelParam_file)
        print("hidden_layer_unit,"+str(hidden_layer_unit), file=modelParam_file)
        print("hidden_layer,"+str(hidden_layer), file=modelParam_file)
        print("activation_func,"+activation_func, file=modelParam_file)
        print("optimize_func,"+optimize_func, file=modelParam_file)
        print("loss_func,"+loss_func, file=modelParam_file)
        print("Elapsed_time(sec),"+str(Elapsed_time), file=modelParam_file)

        modelParam_file.close() 

        import subprocess       

        self.btn_makeModel.setEnabled(False)
        self.groupBox_makemodel_dataset.setEnabled(False)
        self.groupBox_makemodel_param.setEnabled(False)
        self.groupBox_makemodel_save.setEnabled(False)

        # 시스템 전체에서 python 위치 검색
        script_path = r'{}/{}.py'.format(self.program_path, 'makemodel')
        
        modelPath = saveReportPath+"modelParam.txt" 
        pyPath = self.path_python
        external_python = self.path_python
        realtime_rain_path = self.txtBox_dash_obsPath.text().strip()

        self.result_model = None

        if external_python:
            try:
                env = os.environ.copy()
                env.pop("PYTHONPATH", None)
                env.pop("PYTHONHOME", None)

                print ('Starting model creation...')

                CREATE_NEW_CONSOLE = subprocess.CREATE_NEW_CONSOLE  # 콘솔 창 플래그
                
                log_path = r"model_log.txt"
                if os.path.exists(log_path):
                    os.remove(log_path)

                self.result_model = subprocess.Popen(
                    [external_python, script_path, modelPath, pyPath, realtime_rain_path],
                    env=env,                    
                    creationflags=CREATE_NEW_CONSOLE 
                )
                
            except subprocess.CalledProcessError as e:
                print("[Model Creation] Error occurred : ", e.stderr)                
                print ('Failed to create the model.')
                self.btn_makeModel.setEnabled(True)
                self.groupBox_makemodel_dataset.setEnabled(True)
                self.groupBox_makemodel_param.setEnabled(True)
                self.groupBox_makemodel_save.setEnabled(True)
            except FileNotFoundError:
                print("[Model Creation] The file path is incorrect or the Python executable could not be found.")                  
                print ('Failed to create the model.')            
                self.btn_makeModel.setEnabled(True)
                self.groupBox_makemodel_dataset.setEnabled(True)
                self.groupBox_makemodel_param.setEnabled(True)
                self.groupBox_makemodel_save.setEnabled(True)
            except Exception as e:
                print("[Model Creation] Error occurred : ", e)                  
                print ('Failed to create the model.')
                self.btn_makeModel.setEnabled(True)
                self.groupBox_makemodel_dataset.setEnabled(True)
                self.groupBox_makemodel_param.setEnabled(True)
                self.groupBox_makemodel_save.setEnabled(True)
            finally:
                self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
        else:
            self.btn_makeModel.setEnabled(True)
            self.groupBox_makemodel_dataset.setEnabled(True)
            self.groupBox_makemodel_param.setEnabled(True)
            self.groupBox_makemodel_save.setEnabled(True)
            self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))        

        # 주기적으로 종료 체크
        def check_process_finished():
            log_path = r"model_log.txt"
            if self.result_model is None:  # 안전 체크
                iface.messageBar().pushMessage("Model Creation", "Failed to start the model creation process.", duration=5)
                return
            if self.result_model.poll() is None:
                # 아직 안 끝났으면 1초 후 다시 체크
                QTimer.singleShot(1000, check_process_finished)
            else:
                # 끝났으면 로그 출력
                self.btn_makeModel.setEnabled(True)
                self.groupBox_makemodel_dataset.setEnabled(True)
                self.groupBox_makemodel_param.setEnabled(True)
                self.groupBox_makemodel_save.setEnabled(True)

                if os.path.exists(log_path):
                    with open(log_path, "r", encoding="utf-8") as f:
                        log = f.read()
                    print("=== Model Log ===")
                    print(log)               
                    print ('Model creation has been completed.')
                    iface.messageBar().pushMessage("Model Creation", "Model creation has been completed.", duration=5)     
                    # result       
                    msgQuit = QMessageBox.information(self, 'Model Creation', "The model has been successfully created. Do you want to view the results?",
                                                    QMessageBox.Yes | QMessageBox.No)
                    if msgQuit == QMessageBox.Yes:
                        # 모형제작 결과를 확인한다.
                        os.startfile(save_path + model_name)
                else:
                    iface.messageBar().pushMessage("Model Creation", "No log file found.", duration=5)

        # 시작 시 최초 1초 후 체크
        QTimer.singleShot(1000, check_process_finished)

    # tab [하천수위예측 모형제작/예측수행및성능분석] call:입력파라메터 중 hidden layer unit 자료 가져오기
    def getHiddenLayerUnits(self, inputData):
        data = inputData.split(',')
        datas = []
        if len(data) == 0:
            return 0
        else:
            for idx in range(len(data)):
                datas.append(int(data[idx]))
            return datas

    # tab [하천수위예측 모형제작] 데이터셋 파일 불러오기 Button
    def LoadMakeModelDataset(self):
        
        # 데이터셋파일에 null값이 존재하는지 확인
        self.isMakeModelDataNull = False

        fileData, _ = QFileDialog.getOpenFileName(self, 'Open file', '', 'csv file(*.csv)')
        # 선택된 파일없을때 리턴
        if fileData == '': return
        
        # 데이터셋파일이 아닐경우 리턴
        fileinfo, fileext = os.path.splitext(fileData)
        if fileext != '.csv': return

        self.txtBox_dl_datasetFile.setText(fileData)
        self.tbl_readCsvFile.clearContents()
        self.cb_dl_applyRealtimePredWsTime.clear()

        self.ckb_dl_applyRealtimePredWS.setCheckState(False)
        self.txtBox_dl_watershedWithTarget.clear()

        self.ckb_dl_leadtime_all.setChecked(False)
        self.ckb_dl_itemdata_all.setChecked(False)
        
        # dataset 내용표기
        datas = []
        with open(fileData, 'r') as stream:
            for rowdata in csv.reader(stream):
                datas.append(rowdata)
        labels = datas[0]
        nb_row = len(datas)
        nb_col = len(datas[0])
        self.tbl_readCsvFile.setRowCount(nb_row - 1)
        self.tbl_readCsvFile.setColumnCount(nb_col)
        self.tbl_readCsvFile.setHorizontalHeaderLabels(labels)

        for row in range(nb_row - 1):
            for col in range(nb_col):
                # tbl_readCsvFile
                if ((self.isMakeModelDataNull == False) and (str(datas[row + 1][col]) == '')):
                    self.isMakeModelDataNull = True
                item = QTableWidgetItem(str(datas[row + 1][col]))
                if (col==0):
                    item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                else:
                    item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                self.tbl_readCsvFile.setItem(row, col, item)
        self.tbl_readCsvFile.resizeColumnsToContents()

        # dataset_file의 targetpoint에 따라 criteria_wl을 wl.csv파일에서 가져오기
        pluginPath = os.path.dirname(__file__)
        modelObservation_folder = pluginPath + "/station_info"  
        observ_path = os.path.join(modelObservation_folder, 'target_waterlevel.csv')
        target_point = labels[1].split('_')[-1]
        if os.path.exists(observ_path):
            target_waterlevel = pd.read_csv(observ_path, date_parser = True)
            target_value = target_waterlevel[target_waterlevel['target_point']==int(target_point)]        
            target_attention = 0.0
            target_watch = 0.0
            target_warning = 0.0
            target_severe = 0.0
            self.txtBox_dl_criteriaWL.clear()
            if not target_value.empty:
                target_attention = target_value['attention_level'].values[0]
                target_watch = target_value['watch_level'].values[0]
                target_warning = target_value['warning_level'].values[0]
                target_severe = target_value['severe_level'].values[0]
                self.txtBox_dl_criteriaWL.setText(f'{target_attention}, {target_watch}, {target_warning}, {target_severe}')   

        # dataset file 토대로 datacolumn, leadtime 설정 (datadim, outputdim은 선택에따라서)
        colList = datas[0]
        self.model_col = qgis.PyQt.QtGui.QStandardItemModel()
        self.model_lead = qgis.PyQt.QtGui.QStandardItemModel()
        data_targetPoint = ''
        for idx in range(len(colList) - 1):
            itemData = colList[idx + 1]
            item = qgis.PyQt.QtGui.QStandardItem(itemData)
            item.setCheckable(True)
            if ('Leadtime_' in itemData):
                self.model_lead.appendRow(item)
            elif ('Predict_WS' in itemData):
                predText = str(itemData).strip('Predict_WS')
                predTime = str(predText[0:predText.find('_')])      
                if (self.cb_dl_applyRealtimePredWsTime.findText(predTime) == -1):                
                    self.cb_dl_applyRealtimePredWsTime.addItem(predTime)
                self.model_col.appendRow(item)
            else:
                if ('Target_' in itemData):
                    item.setCheckable(False)
                    item.setCheckState(True)

                    try:
                        obs_num = re.search(r'\d+$', itemData)
                        if obs_num:                            
                            data_targetPoint = str(obs_num.group())
                    except Exception as e:
                        data_targetPoint = ''

                self.model_col.appendRow(item)
        self.tbl_modelDatasetColumn.setModel(self.model_col)
        self.tbl_modelDatasetLeadtime.setModel(self.model_lead)

        # set_modelName
        if data_targetPoint != '':
            self.txtBox_dl_modelName.setText(f"WL_{data_targetPoint}_timeseries")
        else:
            self.txtBox_dl_modelName.clear()

        # Apply_Realtime_Predict_WS_CONTROL_SET
        if (self.cb_dl_applyRealtimePredWsTime.count()>0):
            self.ckb_dl_applyRealtimePredWS.setEnabled(True)
            self.cb_dl_applyRealtimePredWsTime.setEnabled(True)
        else:
            self.ckb_dl_applyRealtimePredWS.setEnabled(False)
            self.cb_dl_applyRealtimePredWsTime.setEnabled(False)            

    # tab [예측수행및성능분석] ItemData All Select 설정 Checkbox
    def SetPredict_ItemDataSelect(self):

        bChecked = self.ckb_predictDatasetItemData_all.isChecked()        
        model_items = self.tbl_predictDatasetColumn.model()

        if model_items is not None:
            for mIdx in range(model_items.rowCount()):
                item = model_items.item(mIdx)
                text = item.text()
                if text.startswith("Target_"):
                    item.setCheckState(True)
                else:
                    item.setCheckState(bChecked)

    # tab [예측수행및성능분석] Leadtime All Select 설정 Checkbox
    def SetPredict_LeadtimeSelect(self):

        bChecked = self.ckb_predictDatasetLeadtime_all.isChecked()        
        model_lead = self.tbl_predictDatasetLeadtime.model()

        if model_lead is not None:
            for mIdx in range(model_lead.rowCount()):
                item = model_lead.item(mIdx)
                item.setCheckState(bChecked)

    # tab [예측수행및성능분석] Select Dataset File button
    def LoadPredictDataset(self):

        # 선택한 데이터셋 파일에 NUll값이 존재하는지 확인
        self.isPredictModelDataNull = False

        fileData, _ = QFileDialog.getOpenFileName(self, 'Open file', '', 'csv file(*.csv)')
        # 선택된 파일없을때 리턴
        if fileData == '': return
        # 데이터셋파일이 아닐경우 리턴
        fileinfo, fileext = os.path.splitext(fileData)
        if fileext != '.csv': return

        self.txtBox_pathSelectDataset.setText(fileData)
        self.tbl_selectCsvFile.clearContents()        
        self.cb_dl_applyRealtimePredWS_hour.clear()
        self.ckb_predictDatasetLeadtime_all.setChecked(False)
        self.ckb_predictDatasetItemData_all.setChecked(False)

        # dataset 내용표기
        datas = []
        with open(fileData, 'r') as stream:
            for rowdata in csv.reader(stream):
                datas.append(rowdata)
        labels = datas[0]
        nb_row = len(datas)
        nb_col = len(datas[0])
        self.tbl_selectCsvFile.setRowCount(nb_row - 1)
        self.tbl_selectCsvFile.setColumnCount(nb_col)
        self.tbl_selectCsvFile.setHorizontalHeaderLabels(labels)

        for row in range(nb_row - 1):
            for col in range(nb_col):
                if ((self.isPredictModelDataNull == False) and (str(datas[row + 1][col]) == '')):
                    self.isPredictModelDataNull = True
                item = QTableWidgetItem(str(datas[row + 1][col]))
                if (col==0):
                    item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                else:
                    item.setTextAlignment(Qt.AlignRight | Qt.AlignVCenter)
                self.tbl_selectCsvFile.setItem(row, col, item)
        self.tbl_selectCsvFile.resizeColumnsToContents()

        # dataset file 토대로 datacolumn, leadtime 설정 (datadim, outputdim은 선택에따라서)
        colList = datas[0]
        self.model_col = QtGui.QStandardItemModel()
        self.model_lead = QtGui.QStandardItemModel()        
        data_targetPoint = ''
        for idx in range(len(colList) - 1):
            itemData = colList[idx + 1]
            item = QtGui.QStandardItem(itemData)
            item.setCheckable(True)
            if ('Leadtime_' in itemData):
                self.model_lead.appendRow(item)            
            elif ('Predict_WS' in itemData):
                predText = str(itemData).strip('Predict_WS')
                predTime = str(predText[0:predText.find('_')])      
                if (self.cb_dl_applyRealtimePredWS_hour.findText(predTime) == -1):     
                    self.cb_dl_applyRealtimePredWS_hour.addItem(predTime)
                self.model_col.appendRow(item)
            else:
                if ('Target_' in itemData):
                    item.setCheckable(False)
                    item.setCheckState(True)

                    try:
                        obs_num = re.search(r'\d+$', itemData)
                        if obs_num:                            
                            data_targetPoint = str(obs_num.group())
                    except Exception as e:
                        data_targetPoint = ''  

                self.model_col.appendRow(item)
        self.tbl_predictDatasetColumn.setModel(self.model_col)
        self.tbl_predictDatasetLeadtime.setModel(self.model_lead)

        # set_modelName
        if data_targetPoint != '':
            self.txtBox_saveModelName.setText(f"inference_WL_{data_targetPoint}_timeseries")
        else:
            self.txtBox_saveModelName.clear()

        # Apply_Realtime_Predict_WS_CONTROL_SET
        if (self.cb_dl_applyRealtimePredWS_hour.count()>0):
            self.ckb_dl_predictApplyRealtimePredWS.setEnabled(True)
            self.cb_dl_applyRealtimePredWS_hour.setEnabled(True)
        else:
            self.ckb_dl_predictApplyRealtimePredWS.setEnabled(False)
            self.cb_dl_applyRealtimePredWS_hour.setEnabled(False)

        # 모델이 선택되었고, 데이터셋이 변경되었을때 (데이터컬럼 재선택)
        md_col = [self.cb_load_dl_datainfo.itemText(i) for i in range(self.cb_load_dl_datainfo.count())]        
        
        if (len(md_col)>0):
            model_dataColumnm = md_col           
            tbl_dataColumn = self.tbl_predictDatasetColumn.model()
            if tbl_dataColumn is not None:
                if ((len(model_dataColumnm)>0) and (tbl_dataColumn.rowCount()>0)):
                    for mIdx in range(tbl_dataColumn.rowCount()-1):
                        item = tbl_dataColumn.item(mIdx+1)          
                        item.setCheckState(False)              
                        itemData = item.text() 
                        if (itemData in model_dataColumnm):                                   
                            item.setCheckState(True)

        # 모델이 선택되었고, 데이터셋이 변경되었을때 (리드타임컬럼 재선택)
        md_lead = [self.cb_load_dl_leadtimeinfo.itemText(i) for i in range(self.cb_load_dl_leadtimeinfo.count())]
        if (len(md_lead)>0):
            model_leadColumnm = md_lead
            tbl_leadColumn = self.tbl_predictDatasetLeadtime.model()
            if tbl_leadColumn is not None:
                if ((len(model_leadColumnm)>0) and (tbl_leadColumn.rowCount()>0)):
                    for mIdx in range(tbl_leadColumn.rowCount()):
                        item = tbl_leadColumn.item(mIdx)          
                        item.setCheckState(False)              
                        itemData = item.text() 
                        if (itemData in model_leadColumnm):                                   
                            item.setCheckState(True)                 

    # tab [예측수행및성능분석] 생성한 모형 불러오기(폴더선택) Button
    def LoadModel(self):
        path = QFileDialog.getExistingDirectory(self, 'Open file')
        if os.path.exists(path):         
            modelName = path + "/modelParam.txt"
            self.txtBox_pathSelectModel.setText(path)
            self.load_modelParamFunc(path, modelName)

    # tab [예측수행및성능분석] 예측수행결과 저장경로 선택 Button
    def SetPredictResultSavePath(self):
        path = QFileDialog.getExistingDirectory(self)
        if os.path.exists(path):
            self.txtBox_saveModelPath.setText(path)

    # tab [예측수행및성능분석] call:예측수행 전 입력값 체크
    def checkModelParam_load(self):

        # 1.데이터셋 파일이 선택되었는지,
        datafilepath = self.txtBox_pathSelectDataset.text()
        if datafilepath == "":
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "Please select a dataset file.", QMessageBox.Ok)
            return "None"

        # 1-1. 데이터셋에 Null값이 포함되었는지,
        if self.isPredictModelDataNull == True:
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "The dataset file contains NULL values.", QMessageBox.Ok)
            return "None"

        # 2.예측수행할 모델이 선택되었는지(폴더),
        selectmodelpath = self.txtBox_pathSelectModel.text()
        if selectmodelpath == "":
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "Please select the model folder path.", QMessageBox.Ok)
            return "None"
        
        # 3.예측수행결과를 저장할 경로가 선택되었는지(폴더),
        modelpath = self.txtBox_saveModelPath.text()
        if modelpath == "":
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "Please select the folder path to save the prediction results.", QMessageBox.Ok)
            return "None"

        # 4.예측수행결과 폴더명을 입력하였는지,
        modelname = self.txtBox_saveModelName.text()
        if modelname == "":
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "Please enter the name for the prediction results.", QMessageBox.Ok)
            return "None"

        # 5. 데이터컬럼정보를 선택했는지,
        sel_col = []
        sel_status = False
        model_col = self.tbl_predictDatasetColumn.model()
        for mIdx in range(model_col.rowCount()):
            item = model_col.item(mIdx)
            if item.checkState():
                if mIdx > 0:
                    sel_status = True
                itemData = item.text()                
                sel_col.append(itemData)
        if sel_status == False:
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "Please select the data to use for prediction.", QMessageBox.Ok)
            return "None"

        # 6. 데이터컬럼정보와 모델의 데이터컬럼정보의 갯수가 일치하는지,
        md_col = [self.cb_load_dl_datainfo.itemText(i) for i in range(self.cb_load_dl_datainfo.count())]
        if (len(sel_col) != len(md_col)):
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "The number of data items used in the model and the data for prediction do not match.", QMessageBox.Ok)
            return "None"

        # 7. 데이터컬럼정보가 모델의 데이터컬럼정보와 일치하는지,
        collectData_flag = True
        for cIdx in range(len(md_col)):
            if (sel_col[cIdx] != md_col[cIdx]):
                collectData_flag = False
                break
        if collectData_flag == False:
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "The types of data used in the model and the data selected for prediction do not match.", QMessageBox.Ok)
            return "None"

        # 8. 리드타임정보를 선택했는지,
        lead_col = []
        lead_status = False
        model_lead = self.tbl_predictDatasetLeadtime.model()
        for mIdx in range(model_lead.rowCount()):
            item = model_lead.item(mIdx)
            if item.checkState():
                lead_status = True
                itemData = item.text()
                itemData = itemData[itemData.find('_', 0) + 1:]
                lead_col.append(itemData)
        if lead_status == False:
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "Please select the lead time to use for prediction.", QMessageBox.Ok)
            return "None"

        # 9. 선택한리드타임과 모델에서 사용한 리드타임이 같은지,
        md_lead = [self.cb_load_dl_leadtimeinfo.itemText(i) for i in range(self.cb_load_dl_leadtimeinfo.count())]        
        if (len(lead_col) != len(md_lead)):
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "The number of lead times used in the model and the lead times selected for prediction do not match.", QMessageBox.Ok)
            return "None"

        # 10. 리드타임컬럼정보가 모델의 리드타임컬럼정보와 일치하는지,
        collectData_flag = True
        for cIdx in range(len(md_lead)):
            # model의 leadtime 단위통일
            model_txt = md_lead[cIdx].strip().strip("Leadtime_")
            model_time = -1
            if (model_txt.find("H") > 0):
                leadtimeText = model_txt.strip().strip("H""min")
                if (leadtimeText == "0.5"):
                    model_time = 30
                else:
                    model_time = int(leadtimeText) * 60
            else:
                leadtimeText = model_txt.strip().strip("H""min")
                model_time = int(leadtimeText)
            # dataset의 leadtime 단위통일
            dataset_txt = lead_col[cIdx].strip().strip("Leadtime_")
            dataset_time = -1
            if (dataset_txt.find("H") > 0):
                leadtimeText = dataset_txt.strip().strip("H""min")
                dataset_time = int(leadtimeText) * 60
            else:
                leadtimeText = dataset_txt.strip().strip("H""min")
                dataset_time = int(leadtimeText)
            # leadtime 비교
            if (model_time != dataset_time):
                collectData_flag = False
                break
        if collectData_flag == False:
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "The types of lead times used in the model and the lead times selected for prediction do not match.", QMessageBox.Ok)
            return "None"
        
        # 11. 모델에 설정된 표준유역정보가 데이터셋에 있고 선택되어 있는지,
        watershed_code = self.txtBox_load_dl_watershedWithTarget.text()
        watershed_info = False
        model_col = self.tbl_predictDatasetColumn.model()
        for mIdx in range(model_col.rowCount()):
            item = model_col.item(mIdx)
            col_text = item.text()       
            col_text = col_text.replace('WS_', '')
            if ((col_text == watershed_code) and (int(item.checkState())>0)):
                watershed_info = True
                break
        if watershed_info == False:
            QMessageBox.warning(self, 'Prediction and Performance Analysis', "The standard watershed codes used in the model are missing or not selected in the dataset.", QMessageBox.Ok)
            return "None"

        # 12.예측강우 사용시 예측강우 폴더가 설정되어 있는지,
        bPredictRain = self.ckb_dl_predictApplyRealtimePredWS.isChecked()
        if (bPredictRain):      
            # 12-1.predict_ws정보가 데이터셋에 있는지,
            watershed_rain_info = False
            model_col = self.tbl_predictDatasetColumn.model()
            for mIdx in range(model_col.rowCount()):
                item = model_col.item(mIdx)
                col_text = item.text()
                Predict_WS_hour =  int(self.cb_dl_applyRealtimePredWS_hour.currentText())
                col_predictws = 'Predict_WS{}_'.format(Predict_WS_hour)
                col_text = col_text.replace(col_predictws, '')
                if ((col_text == watershed_code) and (int(item.checkState())>0)):
                    watershed_rain_info = True
                    break    
            if watershed_rain_info == False:
                QMessageBox.warning(self, 'Prediction and Performance Analysis', "The standard watershed code (Predict_WS) information for applying observed rainfall is missing or not selected in the dataset.", QMessageBox.Ok)
                return "None"

            # 12-2.예측강우 사용시 예측강우 폴더가 설정되어 있는지,
            predict_rain_path = self.txtBox_dash_obsPath.text().strip()        
            if predict_rain_path == "":
                QMessageBox.warning(self, 'Prediction and Performance Analysis', "To use Apply Realtime Predict_WS, please set the observed data folder path in System Configuration → Dashboard Settings.", QMessageBox.Ok)
                return "None"

    # tab [예측수행및성능분석] call:예측수행및성능분석에서 모델선택전 파라메터정보 초기화
    def init_modelParamFunc(self):
        self.txtBox_load_dl_modelName.clear()
        self.sp_load_dl_dropOutRate.setValue(0)
        self.sp_load_dl_sequenceLength.setValue(0)
        self.sp_load_dl_hiddenDim.setValue(0)
        self.sp_load_dl_sizeOfBatch.setValue(0)
        self.sb_load_dl_dataDim.setValue(0)
        self.sp_load_dl_outputDim.setValue(0)
        self.sp_load_dl_learningRate.setValue(0)
        self.sp_load_dl_interation.setValue(300)
        self.sp_load_dl_valudatuinSplit.setValue(0)
        self.sp_load_dl_trainingRate.setValue(0)
        self.sp_load_dl_hiddenLayer.setValue(0)
        self.txtBox_load_dl_units.clear()
        self.cb_load_dl_activationFunc.setCurrentText("relu")
        self.cb_load_dl_optimizeFunc.setCurrentText("adam")
        self.cb_load_dl_lossFunc.setCurrentText("mean_squared_error")
        self.cb_load_dl_datainfo.clear()
        self.cb_load_dl_leadtimeinfo.clear()
        self.ckb_load_dl_applyRealtimePredWS.setCheckState(False)
        self.cb_load_dl_applyRealtimePredWsTime.clear()
        self.txtBox_load_dl_watershedWithTarget.clear()
        self.txtBox_load_dl_criteriaWL.clear()
        self.txtBox_load_dl_criteriaHeader.clear()
        self.sb_dl_randomNum_2.setValue(1)
        self.sb_dl_patienceNum_2.setValue(1)
        self.sp_load_dl_testRate.setValue(1)

        tbl_dataColumn = self.tbl_predictDatasetColumn.model()
        if tbl_dataColumn is not None:
            for mIdx in range(tbl_dataColumn.rowCount()-1):
                item = tbl_dataColumn.item(mIdx+1)         
                item.setCheckState(False)              

        tbl_leadColumn = self.tbl_predictDatasetLeadtime.model()
        if tbl_leadColumn is not None:
            for mIdx in range(tbl_leadColumn.rowCount()):
                item = tbl_leadColumn.item(mIdx)          
                item.setCheckState(False)     

    # tab [예측수행및성능분석] call:모형 선택 Button
    def load_modelParamFunc(self, modelPath, modelName):

        # python console활성화
        self.load_pyConsole()

        # control 초기화
        self.init_modelParamFunc()

        # model file check
        if os.path.isfile(modelName) == False: 
            QMessageBox.warning(self, 'Prediction and Performance Analysis', f"The file {modelName} could not be found.", QMessageBox.Ok)
            return

        # load model
        fileData = modelName        

        modeldict_data = {}
        try:
            with open(fileData, "r", encoding="cp949") as file:
                for line in file:
                    if ',' in line:
                        key, value = line.strip().split(',', 1)
                        key = key.strip()
                        value = value.strip()

                        if key == "watershed_with_target":
                            modeldict_data[key] = value
                        else:
                            modeldict_data[key] = self.auto_cast(value)        
        except FileNotFoundError:
            print(f"[Prediction and Performance Analysis] The file {modelName} could not be found.")
            return
        except Exception as e:
            print(f"[Prediction and Performance Analysis] An error occurred while reading the file.: {e}")
            return

        self.sb_dl_randomNum_2.setValue(int(modeldict_data.get("random_number")))
        self.txtBox_load_dl_modelName.setText(str(modeldict_data.get("model_name")))
        self.sp_load_dl_dropOutRate.setValue(float(modeldict_data.get("drop_out_rate")))
        self.sp_load_dl_sequenceLength.setValue(int(modeldict_data.get("seq_length")))
        self.sp_load_dl_hiddenDim.setValue(int(modeldict_data.get("hidden_dim")))
        self.sp_load_dl_sizeOfBatch.setValue(int(modeldict_data.get("size_of_batch")))
        self.sb_load_dl_dataDim.setValue(int(modeldict_data.get("data_dim")))
        self.sp_load_dl_outputDim.setValue(int(modeldict_data.get("output_dim")))
        self.sp_load_dl_learningRate.setValue(float(modeldict_data.get("learning_rate")))
        self.sp_load_dl_interation.setValue(int(modeldict_data.get("iterations")))
        self.sb_dl_patienceNum_2.setValue(int(modeldict_data.get("patience_num")))
        self.sp_load_dl_valudatuinSplit.setValue(float(modeldict_data.get("validation_rate")))
        self.sp_load_dl_trainingRate.setValue(float(modeldict_data.get("training_rate")))
        self.sp_load_dl_testRate.setValue(float(modeldict_data.get("test_start")))
        self.sp_load_dl_hiddenLayer.setValue(int(modeldict_data.get("hidden_layer")))
        self.txtBox_load_dl_watershedWithTarget.setText(str(modeldict_data.get("watershed_with_target")))
        self.cb_load_dl_activationFunc.setCurrentText(str(modeldict_data.get("activation_func")))
        self.cb_load_dl_optimizeFunc.setCurrentText(str(modeldict_data.get("optimize_func")))
        self.cb_load_dl_lossFunc.setCurrentText(str(modeldict_data.get("loss_func")))
        tmp_hidden_layer_unit = re.findall(r'\d+', str(modeldict_data.get("hidden_layer_unit")))
        result_hidden_layer_unit = ', '.join(tmp_hidden_layer_unit)
        self.txtBox_load_dl_units.setText(result_hidden_layer_unit)

        criteria_header = modeldict_data.get("criteria_header")         
        criteria_wl = modeldict_data.get("criteria_wl")   
        qlinetext =  ', '.join(criteria_header)
        self.txtBox_load_dl_criteriaHeader.setText(qlinetext)
        
        qline_text = ', '.join(str(num) for num in criteria_wl)
        self.txtBox_load_dl_criteriaWL.setText(qline_text)   
        tmp_datainfo = re.findall(r'\d+', str(modeldict_data.get("X_data_training_column_list")))
        result_datainfo = ', '.join(tmp_datainfo)

        # datalist
        model_dataColumnm = []
        self.cb_load_dl_datainfo.clear()
        lst_data = modeldict_data.get("X_data_training_column_list")
        for data in lst_data:
            model_dataColumnm.append(data)
            self.cb_load_dl_datainfo.addItem(data)

        # 컬럼정보가 존재하고, 데이터셋이 불러져왔을때, 데이터컬럼 자동으로 컬럼선택
        tbl_dataColumn = self.tbl_predictDatasetColumn.model()
        bExist_predws = False
        if tbl_dataColumn is not None:
            if ((len(model_dataColumnm)>0) and (tbl_dataColumn.rowCount()>0)):
                for mIdx in range(tbl_dataColumn.rowCount()-1):
                    item = tbl_dataColumn.item(mIdx+1)         
                    item.setCheckState(False)              
                    itemData = item.text() 
                    if (itemData in model_dataColumnm):                                   
                        item.setCheckState(True)   
                    if ('Predict_WS' in itemData):
                        bExist_predws = True

        tmp_leadtimeinfo = re.findall(r'\d+', str(modeldict_data.get("Y_data_training_column_list")))
        result_leadtimeinfo = ', '.join(tmp_leadtimeinfo)

        # leadtimelist        
        model_leadColumnm = []        
        self.cb_load_dl_leadtimeinfo.clear()
        lst_data = modeldict_data.get("Y_data_training_column_list")
        for data in lst_data:
            model_leadColumnm.append(data)
            self.cb_load_dl_leadtimeinfo.addItem(data)

        # 컬럼정보가 존재하고, 데이터셋이 불러져왔을때, 리드타임 자동으로 컬럼선택
        tbl_leadColumn = self.tbl_predictDatasetLeadtime.model()
        if tbl_leadColumn is not None:
            if ((len(model_leadColumnm)>0) and (tbl_leadColumn.rowCount()>0)):
                for mIdx in range(tbl_leadColumn.rowCount()):
                    item = tbl_leadColumn.item(mIdx)          
                    item.setCheckState(False)              
                    itemData = item.text() 
                    if (itemData in model_leadColumnm):                                   
                        item.setCheckState(True)   

        # 예측강우정보불러오기 추가
        bPredws = modeldict_data.get("apply_realtime_Pred_WS")
        self.ckb_load_dl_applyRealtimePredWS.setCheckState(bPredws)
        predTime = str(modeldict_data.get("realtime_Pred_WS_time")).strip()
        if (predTime is not '0') and (self.cb_load_dl_applyRealtimePredWsTime.findText(predTime) == -1):
            self.cb_load_dl_applyRealtimePredWsTime.addItem(predTime) 

            if self.ckb_dl_predictApplyRealtimePredWS.isEnabled():
                self.ckb_dl_predictApplyRealtimePredWS.setCheckState(bPredws)
                if bPredws and bExist_predws:
                    pred_hour = int(modeldict_data.get("realtime_Pred_WS_time"))
                    if (pred_hour>0) and (self.cb_dl_applyRealtimePredWsTime.count()>0):
                        index = self.cb_dl_applyRealtimePredWS_hour.findText(str(pred_hour))
                        if (index>-1):
                            self.cb_dl_applyRealtimePredWS_hour.setCurrentIndex(index)

        import subprocess       

        # 시스템 전체에서 python 위치 검색
        script_path = r'{}/{}.py'.format(self.program_path, 'loadmodel')        
        modelPath = os.path.join(modelPath, 'best_model.h5')    # tf->h5
        pyPath = self.path_python
        external_python = self.path_python

        if external_python:
            try:
                env = os.environ.copy()
                env.pop("PYTHONPATH", None)
                env.pop("PYTHONHOME", None)

                print ('Loading model...')

                # subprocess.run으로 동기 실행
                result = subprocess.run(
                    [external_python, script_path, modelPath, external_python],
                    env=env,
                    capture_output=True,  # stdout, stderr 캡처
                    text=True
                )

                # 실행 결과 확인
                if result.returncode == 0:
                    print ('Model loaded successfully.')
                    print(result.stdout)
                else:
                    print ('Failed to load the model.')
                    print(result.stderr)
                    QMessageBox.warning(self, 'Prediction and Performance Analysis', f"{result.stderr}", QMessageBox.Ok)
                    self.init_modelParamFunc()    
                    self.txtBox_pathSelectModel.clear()
                                
            except subprocess.CalledProcessError as e:
                print("[Prediction and Performance Analysis] Error occurred : ", e.stderr)                              
                print ('Failed to load the model.')
                QMessageBox.warning(self, 'Prediction and Performance Analysis', f"{e.stderr}", QMessageBox.Ok)
                self.init_modelParamFunc()    
                self.txtBox_pathSelectModel.clear()
            except FileNotFoundError:
                print("[Prediction and Performance Analysis] The file path is incorrect, or the Python executable could not be found.")                             
                print ('Failed to load the model.')   
                QMessageBox.warning(self, 'Prediction and Performance Analysis', f"The file path is incorrect, or the Python executable could not be found.", QMessageBox.Ok)
                self.init_modelParamFunc()       
                self.txtBox_pathSelectModel.clear()        
            except Exception as e:
                print("[Prediction and Performance Analysis] Error occurred : ", e)                               
                print ('Failed to load the model.')    
                QMessageBox.warning(self, 'Prediction and Performance Analysis', f"{e}", QMessageBox.Ok)
                self.init_modelParamFunc()        
                self.txtBox_pathSelectModel.clear()    

    # tab [예측수행및성능분석] 예측수행(Running Model) Button
    def RunPredict(self):

        # PythonConsole이 있는지 확인
        self.load_pyConsole()

        # 예측수행 전, 입력값 체크
        if self.checkModelParam_load() == "None": return

        self.setCursor(QtGui.QCursor(QtCore.Qt.WaitCursor))

        # 예측수행 결과를 저장할 폴더 정보를 확인
        datafilepath = self.txtBox_pathSelectDataset.text()
        dataModelpath = self.txtBox_pathSelectModel.text()
        dataModelName = self.txtBox_load_dl_modelName.text()
        modelpath = self.txtBox_saveModelPath.text()
        modelName = self.txtBox_saveModelName.text()
        saveModelpath = modelpath + "/"
        saveReportPath = saveModelpath + modelName + "/"
        saveResultPath = saveModelpath + modelName

        if not os.path.exists(saveResultPath):
            os.makedirs(saveResultPath)
        else:
            buttonReply = QMessageBox.warning(self, 'Prediction and Performance Analysis', "The folder already exists. Do you want to overwrite it?",
                                              QMessageBox.Yes | QMessageBox.No)
            if buttonReply == QMessageBox.No:
                self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
                return
            elif buttonReply == QMessageBox.Yes:
                shutil.rmtree(saveReportPath)
                os.makedirs(saveReportPath)
            else:
                self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
                return
            
        self.result_pred = None
        
        import subprocess       
        
        self.btn_dl_reloadModel.setEnabled(False)
        self.groupBox_predict_dataset.setEnabled(False)
        self.groupBox_predict_model.setEnabled(False)
        self.groupBox_predict_save.setEnabled(False)
        self.groupBox_predict_dl.setEnabled(False)
        self.groupBox_predict_ap.setEnabled(False)

        script_path = r'{}/{}.py'.format(self.program_path, 'runpredict')
        
        modelParmaPath = os.path.join(dataModelpath,'modelParam.txt')
        external_python = self.path_python
        realtime_rain_path = self.txtBox_dash_obsPath.text().strip()
        
        if external_python:
            try:
                env = os.environ.copy()
                env.pop("PYTHONPATH", None)
                env.pop("PYTHONHOME", None)

                print ('Starting prediction...')

                CREATE_NEW_CONSOLE = subprocess.CREATE_NEW_CONSOLE 
                
                log_path = r"model_log.txt"
                if os.path.exists(log_path):
                    os.remove(log_path)

                self.result_pred = subprocess.Popen(
                    [external_python, script_path, datafilepath, modelParmaPath, realtime_rain_path, saveReportPath, modelName, external_python],
                    env=env,
                    #stdout=subprocess.PIPE,
                    #stderr=subprocess.PIPE,                
                    creationflags=CREATE_NEW_CONSOLE 
                )

                '''out, err = self.result_pred.communicate()
                if self.result_pred.returncode != 0:
                    print ('Prediction Failed.')  
                    print (err)'''
                
            except FileNotFoundError:                  
                print ('Prediction Failed.')  
                print("[Prediction and Performance Analysis] The file path is incorrect, or the Python executable could not be found.")   
                self.btn_dl_reloadModel.setEnabled(True)
                self.groupBox_predict_dataset.setEnabled(True)
                self.groupBox_predict_model.setEnabled(True)
                self.groupBox_predict_save.setEnabled(True)
                self.groupBox_predict_dl.setEnabled(True)
                self.groupBox_predict_ap.setEnabled(True)          
            except Exception as e:                      
                print ('Prediction Failed.')
                print("[Prediction and Performance Analysis] Exception occurred : ", e)     
                self.btn_dl_reloadModel.setEnabled(True)
                self.groupBox_predict_dataset.setEnabled(True)
                self.groupBox_predict_model.setEnabled(True)
                self.groupBox_predict_save.setEnabled(True)
                self.groupBox_predict_dl.setEnabled(True)
                self.groupBox_predict_ap.setEnabled(True)  
            finally:
                self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
        else:
            self.btn_dl_reloadModel.setEnabled(True)
            self.groupBox_predict_dataset.setEnabled(True)
            self.groupBox_predict_model.setEnabled(True)
            self.groupBox_predict_save.setEnabled(True)
            self.groupBox_predict_dl.setEnabled(True)
            self.groupBox_predict_ap.setEnabled(True)  
            self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))    
       
        # 주기적으로 종료 체크
        def check_process_finished():
            log_path = r"model_log.txt"
            if self.result_pred is None:  # 안전 체크
                iface.messageBar().pushMessage("Prediction and Performance Analysis", "Failed to start the prediction process.", duration=5)
                return
            if self.result_pred.poll() is None:
                QTimer.singleShot(1000, check_process_finished)
            else:
                self.btn_dl_reloadModel.setEnabled(True)
                self.groupBox_predict_dataset.setEnabled(True)
                self.groupBox_predict_model.setEnabled(True)
                self.groupBox_predict_save.setEnabled(True)
                self.groupBox_predict_dl.setEnabled(True)
                self.groupBox_predict_ap.setEnabled(True)       
                #if self.result_pred.returncode==0:                                             
                print ('Prediction has been completed.')
                msgQuit = QMessageBox.information(self, 'Prediction and Performance Analysis', "Prediction has been completed. Do you want to view the results?",
                                                QMessageBox.Yes | QMessageBox.No)
                if msgQuit == QMessageBox.Yes:
                    # 모형제작 결과를 확인한다.
                    os.startfile(saveResultPath)

        # 시작 시 최초 1초 후 체크
        QTimer.singleShot(1000, check_process_finished)

    # tab [실시간예측] : [2단계:모델선택] Select Model Directory button
    def LoadRealtimeModel(self):
        path = QFileDialog.getExistingDirectory(self, 'Open file')
        if os.path.exists(path):
            modelName = path + "/modelParam.txt"
            self.txtBox_pathSelectRealtimeModel.setText(path)
            self.load_realtimeModelParamFunc(path, modelName)

    # tab [실시간예측] : [2단계:모델선택] call:모형 선택 Button
    def load_realtimeModelParamFunc(self, modelPath, modelName):

        # python console활성화
        self.load_pyConsole()

        # control 초기화
        self.init_realtimeModelParamFunc()

        # model file check
        if os.path.isfile(modelName) == False: return

        # load model
        fileData = modelName        

        modeldict_data = {}
        with open(fileData, "r", encoding="cp949") as file:
            for line in file:
                if ',' in line:
                    key, value = line.strip().split(',', 1)
                    key = key.strip()
                    value = value.strip()

                    if key == "watershed_with_target":
                        modeldict_data[key] = value
                    else:
                        modeldict_data[key] = self.auto_cast(value)

        self.sb_rt_randomNum.setValue(int(modeldict_data.get("random_number")))
        self.txtBox_load_rt_modelName.setText(str(modeldict_data.get("model_name")))
        self.sp_load_rt_dropOutRate.setValue(float(modeldict_data.get("drop_out_rate")))
        self.sp_load_rt_sequenceLength.setValue(int(modeldict_data.get("seq_length")))
        self.sp_load_rt_hiddenDim.setValue(int(modeldict_data.get("hidden_dim")))
        self.sp_load_rt_sizeOfBatch.setValue(int(modeldict_data.get("size_of_batch")))
        self.sb_load_rt_dataDim.setValue(int(modeldict_data.get("data_dim")))
        self.sp_load_rt_outputDim.setValue(int(modeldict_data.get("output_dim")))
        self.sp_load_rt_learningRate.setValue(float(modeldict_data.get("learning_rate")))
        self.sp_load_rt_interation.setValue(int(modeldict_data.get("iterations")))
        self.sb_rt_patienceNum.setValue(int(modeldict_data.get("patience_num")))
        self.sp_load_rt_valudatuinSplit.setValue(float(modeldict_data.get("validation_rate")))
        self.sp_load_rt_trainingRate.setValue(float(modeldict_data.get("training_rate")))
        self.sp_load_rt_testRate.setValue(float(modeldict_data.get("test_start")))
        self.sp_load_rt_hiddenLayer.setValue(int(modeldict_data.get("hidden_layer")))
        self.txtBox_load_rt_watershedWithTarget.setText(str(modeldict_data.get("watershed_with_target")))
        self.cb_load_rt_activationFunc.setCurrentText(str(modeldict_data.get("activation_func")))
        self.cb_load_rt_optimizeFunc.setCurrentText(str(modeldict_data.get("optimize_func")))
        self.cb_load_rt_lossFunc.setCurrentText(str(modeldict_data.get("loss_func")))
        tmp_hidden_layer_unit = re.findall(r'\d+', str(modeldict_data.get("hidden_layer_unit")))
        result_hidden_layer_unit = ', '.join(tmp_hidden_layer_unit)
        self.txtBox_load_rt_units.setText(result_hidden_layer_unit)

        criteria_header = modeldict_data.get("criteria_header")         
        criteria_wl = modeldict_data.get("criteria_wl")   
        qlinetext =  ', '.join(criteria_header)
        self.txtBox_rt_criteriaHeader.setText(qlinetext)
        
        qline_text = ', '.join(str(num) for num in criteria_wl)
        self.txtBox_rt_criteriaWL.setText(qline_text)   

        # datalist
        model_dataColumnm = []
        self.listctrl_load_rt_datainfo.clear()
        lst_data = modeldict_data.get("X_data_training_column_list")
        for data in lst_data:
            model_dataColumnm.append(data)
            self.listctrl_load_rt_datainfo.addItem(data)
            
        # leadtimelist        
        model_leadColumnm = []        
        self.listctrl_load_rt_leadtimeinfo.clear()
        lst_data = modeldict_data.get("Y_data_training_column_list")
        for data in lst_data:
            model_leadColumnm.append(data)
            self.listctrl_load_rt_leadtimeinfo.addItem(data)        
 
        import subprocess       

        # 시스템 전체에서 python 위치 검색
        script_path = r'{}/{}.py'.format(self.program_path, 'loadmodel')
        modelPath = os.path.join(modelPath, 'best_model.h5')    # tf->h5변경
        pyPath = self.path_python
        external_python = self.path_python

        if external_python:
            try:
                env = os.environ.copy()
                env.pop("PYTHONPATH", None)
                env.pop("PYTHONHOME", None)

                result = subprocess.Popen([external_python, script_path, modelPath, pyPath],
                    env=env,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True
                )
                
                # 출력 결과 읽기
                stdout, stderr = result.communicate()

                # 출력된 모델 요약 결과
                if stdout:
                    print("[Real-time Prediction] Model Summary")
                    print(stdout)

                # 오류가 있을 경우
                if stderr:
                    print(f"[Real-time Prediction] Error occurred : {stderr}")
                
            except subprocess.CalledProcessError as e:
                print("[Real-time Prediction] Error occurred : ", e.stderr)
            except FileNotFoundError:
                print("[Real-time Prediction] The file path is incorrect, or the Python executable could not be found.")                
            except Exception as e:
                print("[Real-time Prediction] Exception occurred : ", e)    

    # tab [실시간예측] : [2단계:모델선택] call:예측수행및성능분석에서 모델선택전 파라메터정보 초기화
    def init_realtimeModelParamFunc(self):
        self.txtBox_load_rt_modelName.clear()
        self.sp_load_rt_dropOutRate.setValue(0)
        self.sp_load_rt_sequenceLength.setValue(0)
        self.sp_load_rt_hiddenDim.setValue(0)
        self.sp_load_rt_sizeOfBatch.setValue(0)
        self.sb_load_rt_dataDim.setValue(0)
        self.sp_load_rt_outputDim.setValue(0)
        self.sp_load_rt_learningRate.setValue(0)
        self.sp_load_rt_interation.setValue(0)
        self.sp_load_rt_valudatuinSplit.setValue(0)
        self.sp_load_rt_trainingRate.setValue(0)
        self.sp_load_rt_hiddenLayer.setValue(0)
        self.txtBox_load_rt_units.clear()
        self.cb_load_rt_activationFunc.setCurrentText("relu")
        self.cb_load_rt_optimizeFunc.setCurrentText("adam")
        self.cb_load_rt_lossFunc.setCurrentText("mean_squared_error")
        self.ckb_load_rt_applyRealtimePredWS.setCheckState(False) #사용x
        self.txtBox_load_rt_watershedWithTarget.clear()
        self.listctrl_load_rt_leadtimeinfo.clear()
        self.listctrl_load_rt_datainfo.clear()

    # tab [실시간예측] : [3단계] 저장경로 선택 Button
    def SaveRealtimeModelPath(self):
        path = QFileDialog.getExistingDirectory(self)
        if os.path.exists(path):
            self.txtBox_saveRealtimeModelPath.setText(path)

    # tab [실시간예측] : [3단계] call:실시간예측수행 전 입력값 체크
    def checkRealtimeModelParam(self, stdTime):

        # 1.실시간예측수행할 모델이 선택되었는지(폴더),
        selectmodelpath = self.txtBox_pathSelectRealtimeModel.text()
        if selectmodelpath == "":
            QMessageBox.warning(self, 'Real-time Prediction', "Please select the prediction model to use for real-time prediction.", QMessageBox.Ok)
            return "None"

        # 2.실시간예측수행결과를 저장할 경로가 선택되었는지(폴더),
        modelpath = self.txtBox_saveRealtimeModelPath.text()
        if modelpath == "":
            QMessageBox.warning(self, 'Real-time Prediction', "Please select the folder path to save the real-time prediction results.", QMessageBox.Ok)
            return "None"

    # tab [실시간예측] : [3단계] call:실시간예측을 위한 데이터조회 (LeadTime은 고려하지않는다)
    def get_realtimeDataset(self, stdTime):

        import mariadb

        # 조회기간(설정시간기준 sequence_length(분)만큼의 이전데이터) (1(10분)~72(12시간))
        sequenceLength = self.sp_load_rt_sequenceLength.value() * 10
        endDatetime = stdTime
        startTime = endDatetime - timedelta(minutes=sequenceLength)
        start = str(startTime.strftime("%Y-%m-%d %H:%M"))
        end = stdTime

        # list_가져오기
        data_items = [self.listctrl_load_rt_datainfo.item(i).text() for i in range(self.listctrl_load_rt_datainfo.count())]
        result_dict = {}
        for text in data_items:
            parts = text.split("_")
            category = parts[0]

            if category == "TE":
                number = "_".join(parts[1:])
            elif category in ("Target", "WL", "RF", "WS", "DI", "DR", "DC"):
                if category == "RF" and parts[1].startswith("cum"):
                    category = "RF_cum"
                    number = "".join(filter(str.isdigit, parts[1]))  
                else:
                    number = parts[-1]        
            elif category == "Predict":
                category = "Predict_WS"
                if len(parts) > 1 and parts[1].upper().startswith("WS"):
                    number = "".join(filter(str.isdigit, parts[1])) 
                else:
                    number = parts[-1] 
            else:
                continue
                        
            if category not in result_dict:
                result_dict[category] = []
            
            if number not in result_dict[category]:
                result_dict[category].append(number)

        dataTarget = result_dict.get("Target", [])
        targetText = ''
        if len(dataTarget)>0:
            targetText = dataTarget[0]

        dataWaterlevel = result_dict.get("WL", [])
        dataRainfall = result_dict.get("RF", [])
        dataDaminlet = result_dict.get("DI", [])
        dataDamrelease = result_dict.get("DR", [])
        dataFlowrate = result_dict.get("DC", [])
        dataElevation = result_dict.get("TE", [])
        dataThiessen = result_dict.get("WS", [])

        dataRFcum = result_dict.get("RF_cum", [])
        dataPredictWS = result_dict.get("Predict_WS", [])

        # 데이터조회
        conn = None

        # column header setting
        columnHeader = []
        resultset_now = []

        try:
            self.db_config["database"] = self.db_tablespace
            conn = mariadb.connect(**self.db_config)
            cur = conn.cursor()

            # 날짜정보
            sql_date = "date_format(DT_DATE, '%Y-%m-%d %H:%i') between '{0}' and '{1}'".format(start, end)

            # 1. get Target Data
            if targetText != "":
                columnHeader.append("Date")
                select_all_query = "select DT_DATE from waterlevel where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                    targetText, sql_date)
                cur.execute(select_all_query)
                resultsetData = cur.fetchall()
                resultset = []
                for idx in range(len(resultsetData)):
                    resultset.append(resultsetData[idx][0])
                resultset_now.append(resultset)

                columnHeader.append('Target_' + targetText)
                select_all_query = "select DT_DATA from waterlevel where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                    targetText, sql_date)
                cur.execute(select_all_query)
                resultsetData = cur.fetchall()
                resultset = []
                for idx in range(len(resultsetData)):
                    resultset.append(resultsetData[idx][0])
                resultset_now.append(resultset)

            # 2. get Waterlevel Data
            for obs_row in range(len(dataWaterlevel)):
                columnHeader.append('WL_' + dataWaterlevel[obs_row])
                select_all_query = "select DT_DATA from waterlevel where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                    dataWaterlevel[obs_row], sql_date)
                cur.execute(select_all_query)
                resultsetData = cur.fetchall()
                resultset = []
                for idx in range(len(resultsetData)):
                    resultset.append(resultsetData[idx][0])

                resultset_now.append(resultset)

            # 3. get Rainfall Data
            for obs_row in range(len(dataRainfall)):
                columnHeader.append('RF_' + dataRainfall[obs_row])
                select_all_query = "select DT_DATA from rainfall where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                    dataRainfall[obs_row], sql_date)
                cur.execute(select_all_query)
                resultsetData = cur.fetchall()
                resultset = []
                for idx in range(len(resultsetData)):
                    resultset.append(resultsetData[idx][0])
                resultset_now.append(resultset)

            # 4. get DamInlet Data
            for obs_row in range(len(dataDaminlet)):
                columnHeader.append('DI_' + dataDaminlet[obs_row])
                select_all_query = "select DT_DATA from daminlet where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                    dataDaminlet[obs_row], sql_date)
                cur.execute(select_all_query)
                resultsetData = cur.fetchall()
                resultset = []
                for idx in range(len(resultsetData)):
                    resultset.append(resultsetData[idx][0])
                resultset_now.append(resultset)

            # 5. get DamRelease Data
            for obs_row in range(len(dataDamrelease)):
                columnHeader.append('DR_' + dataDamrelease[obs_row])
                select_all_query = "select DT_DATA from damrelease where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                    dataDamrelease[obs_row], sql_date)
                cur.execute(select_all_query)
                resultsetData = cur.fetchall()
                resultset = []
                for idx in range(len(resultsetData)):
                    resultset.append(resultsetData[idx][0])
                resultset_now.append(resultset)

            # 6. get Flowarate Data
            for obs_row in range(len(dataFlowrate)):
                columnHeader.append('DC_' + dataFlowrate[obs_row])
                select_all_query = "select DT_DATA from discharge where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                    dataFlowrate[obs_row], sql_date)
                cur.execute(select_all_query)
                resultsetData = cur.fetchall()
                resultset = []
                for idx in range(len(resultsetData)):
                    resultset.append(resultsetData[idx][0])
                resultset_now.append(resultset)

            # 7. get Elevation Data
            for obs_row in range(len(dataElevation)):
                columnHeader.append('TE_' + dataElevation[obs_row])
                select_all_query = "select DT_DATA from tidelevel where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                    dataElevation[obs_row], sql_date)
                cur.execute(select_all_query)
                resultsetData = cur.fetchall()
                resultset = []
                for idx in range(len(resultsetData)):
                    resultset.append(resultsetData[idx][0])
                resultset_now.append(resultset)

            # 8. get Thiessen Data
            for obs_row in range(len(dataThiessen)):
                columnHeader.append('WS_' + dataThiessen[obs_row])
                select_all_query = "select DT_DATA from watershed where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                    dataThiessen[obs_row], sql_date)
                cur.execute(select_all_query)
                resultsetData = cur.fetchall()
                resultset = []
                for idx in range(len(resultsetData)):
                    resultset.append(resultsetData[idx][0])
                resultset_now.append(resultset)

            # 9. RF_CUM
            for obs_row in range(len(dataRainfall)):
                obs_id = dataRainfall[obs_row]

                # 3-2. 누적강우 조회
                resultset = []
                for cum_hour in dataRFcum:
                    new_col = f"RF_cum{cum_hour}_{obs_id}"
                    columnHeader.append(new_col)

                    select_cum_query = f"""
                        SELECT SUM(DT_DATA) OVER (
                                ORDER BY DT_DATE
                                ROWS {int(cum_hour)-1} PRECEDING
                            ) AS cum_rain
                        FROM rainfall
                        WHERE OBS_ID = '{obs_id}' AND {sql_date}
                        ORDER BY DT_DATE
                    """
                    cur.execute(select_cum_query)
                    resultsetData = cur.fetchall()
                    resultset = [row[0] for row in resultsetData]
                    resultset_now.append(resultset)

            # 10. predict_ws
            for obs_row in range(len(dataThiessen)):
                obs_id = dataThiessen[obs_row]

                # 3-2. 예측강우는 유역이랑 같은값으로 일단...처리하기!
                resultset = []
                for cum_hour in dataPredictWS:
                    new_col = f"Predict_WS{cum_hour}_{obs_id}"
                    search_col = f"WS_{obs_id}"
                    columnHeader.append(new_col)

                    idx = columnHeader.index(search_col)
                    resultset_now.append(resultset_now[idx])      

        
        except mariadb.Error as e:
            print("[Real-time Prediction] MariaDB Error occurred : {e}")
        except Exception as e:
            print("[Real-time Prediction] Exception occurred : {e}")
        finally:
            if conn:
                conn.close()

        # 조회결과가 없으면 리턴
        if len(resultset_now) == 0:
            QMessageBox.warning(self, 'Real-time Prediction', "No data found.", QMessageBox.Ok)
            return "None"

        # 관측소별 조회데이터 갯수가 다르면 리턴
        isDataSame = True
        isFirstValue = 0
        for idxs in range(len(resultset_now)):
            if idxs == 0:
                isFirstValue = len(resultset_now[idxs])
            else:
                isValue = len(resultset_now[idxs])
                if isFirstValue != isValue:
                    QMessageBox.warning(self, 'Real-time Prediction', "The number of data items varies by observation station.", QMessageBox.Ok)
                    return "None"

        # 조회된데이터 pd형태로 return
        df = pd.DataFrame(index=range(0, len(resultset_now[0])), columns=columnHeader)
        for pdIdx in range(len(resultset_now)):
            df[columnHeader[pdIdx]] = resultset_now[pdIdx]
        return df

    # tab [실시간예측] : [3단계] Realtime Run Model button
    def RunRealtimeModel(self):

        # PythonConsole이 있는지 확인
        self.load_pyConsole()

        # 실시간예측 기준시간 (10분단위로 분석)
        selectTime = self.dt_rt_datetime.text()
        interval_min = 10
        timTmp = pd.to_datetime(selectTime)
        selectTime = timTmp.replace(minute=timTmp.minute - timTmp.minute % interval_min, second=0, microsecond=0)
        stdTime = selectTime

        # 예측수행 전, 입력값 체크
        if self.checkRealtimeModelParam(stdTime) == "None": return

        # 예측수행 결과를 저장할 폴더 정보를 확인
        dataModelpath = self.txtBox_pathSelectRealtimeModel.text()
        modelpath = self.txtBox_saveRealtimeModelPath.text()
        saveModelpath = modelpath + "/"
        saveReportPath = modelpath + "/"
        saveResultPath = modelpath

        if not os.path.exists(saveResultPath):
            os.makedirs(saveResultPath)

        # 실시간예측
        if self.btn_realtimeModel.text() == "Start Real-Time Prediction":
            timer = 0
            self.btn_realtimeModel.setText("Stop Real-Time Prediction")
            self.txtBox_logRealtime.clear()
            self.realtimeModel(dataModelpath, saveModelpath, saveReportPath, timer, stdTime)

        else:
            # 실시간예측 종료하기
            if threading.active_count() > 1:
                myThread.cancel()
            self.btn_realtimeModel.setText("Start Real-Time Prediction")

    # tab [실시간예측] : [3단계] call:Realtime Run Model
    def realtimeModel(self, dataModelpath, saveModelpath, saveReportMainPath, timer, stdTime):

        saveReportPath = saveReportMainPath

        if not os.path.exists(saveReportPath):
            os.makedirs(saveReportPath)

        # pythonconsole clear
        from PyQt5.QtWidgets import QTextEdit
        pythonConsole = iface.mainWindow().findChild(QTextEdit, 'PythonConsoleOutput')
        if pythonConsole:
            pythonConsole.clear()

        # 시간체크(10분씩 분석)
        startTime = stdTime + timedelta(minutes=10)
        nextTime = startTime

        # 실시간예측(10분=600초)
        global myThread
        myThread = threading.Timer(interval=600, function=self.realtimeModel, args=(dataModelpath, saveModelpath, saveReportMainPath, timer + 1, nextTime))
        myThread.start()                

        random_number = self.sb_rt_randomNum.value()

        # 선택된 모델의 lead_time 체크
        data_items = [self.listctrl_load_rt_leadtimeinfo.item(i).text() for i in range(self.listctrl_load_rt_leadtimeinfo.count())]
        leadtime_list = [text.replace("Leadtime_", "").replace("min", "") for text in data_items]
        leadtime_list = [text.replace("Leadtime_", "") for text in data_items]

        lead_time = "1H" #leadtime_list#self.txtBox_load_rt_leadtimeinfo.text()

        datainfo = [self.listctrl_load_rt_datainfo.item(i).text() for i in range(self.listctrl_load_rt_datainfo.count())]
        target_point = datainfo[0]

        # write log
        logfilePath = saveReportMainPath + "logfile.txt"

        seq_length = self.sp_load_rt_sequenceLength.value()
        data_dim = self.sb_load_rt_dataDim.value()
        drop_out_rate = self.sp_load_rt_dropOutRate.value()

        file_nm = f"predict_result_{target_point}_{lead_time}out_{str(drop_out_rate)}_seq_length_{str(seq_length)}.csv"
        resultFileName = os.path.join(saveReportPath, file_nm)

        # 데이터셋 파일 정보확인
        data = self.get_realtimeDataset(stdTime)

        if (len(data) == self.sp_load_rt_sequenceLength.value()+1):
            # 데이터셋 헤더정보 확인
            header = data.columns.values
            datadim_count = 0  # target+ref
            outputdim_count = 0  # targer
            for idx in range(len(header)):
                # data_dim index = target+ref
                if ('Target_' in header[idx] or 'WL_' in header[idx] or 'RF_' in header[idx] or 'DI_' in header[
                    idx] or 'DR_' in header[idx] or 'DC_' in header[idx] or 'TE_' in header[idx] or 'WS_' in header[
                        idx] or 'Predict_' in header[idx]) == True:
                    datadim_count = datadim_count + 1
                # output_dim index = target
                if ('Target_' in header[idx]) == True:
                    outputdim_count = outputdim_count + 1

            # make data of training and test data
            data_test = data

            # check the length of data
            print('Total = ', len(data))
            print('Test = ', len(data_test))

            # make dataset of test
            data_test_drop = data_test.iloc[:, np.r_[1:datadim_count + 1]]

            Current_time_test = data_test.iloc[:, [0]]
            Current_time_test = Current_time_test.reset_index(drop=True)

            # Make a prediction time for each leadtime
            Predict_time_leadtime = 0
            leadtimeNm = lead_time
            if (leadtimeNm.find("H") > 0):
                leadtimeText = leadtimeNm.strip().strip("H""min")
                if (leadtimeText == "0.5"):
                    Predict_time_leadtime = 30
                else:
                    Predict_time_leadtime = int(leadtimeText) * 60
            else:
                leadtimeText = leadtimeNm.strip().strip("H""min")
                Predict_time_leadtime=int(leadtimeText)
            Predict_time = stdTime + timedelta(minutes=Predict_time_leadtime)

            import subprocess       

            # 시스템 전체에서 python 위치 검색
            script_path = r'{}/{}.py'.format(self.program_path, 'realtimepredict')
            external_python = self.path_python

            if external_python:
                try:
                    env = os.environ.copy()
                    env.pop("PYTHONPATH", None)
                    env.pop("PYTHONHOME", None)

                    print ("Start Real-Time Prediction...")
                    
                    arg2 = f'{random_number}'
                    arg3 = f'{seq_length}'
                    arg4 = f'{data_dim}'
                    arg5 = f'{stdTime}'
                    arg6 = f'{Predict_time}'

                    csv_data = data_test_drop.to_csv(index=False)
                    from io import StringIO

                    result = subprocess.Popen([external_python, script_path, 
                                               dataModelpath, arg2, arg3, arg4, arg5, arg6, resultFileName, external_python],
                        env=env,
                        stdin=subprocess.PIPE,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                    )
                    
                    # 출력 결과 읽기
                    stdout, stderr = result.communicate(input=csv_data.encode('utf-8'))
                    self.txtBox_logRealtime.appendPlainText(str(stdTime) + "_predict")

                    # 출력된 모델 요약 결과                    
                    if stdout:
                        print("Model Summary:")
                        print(stdout)                        
                        print ("Finish Real-Time Prediction.")

                    # 오류가 있을 경우
                    if stderr:
                        print(f"Warning occurred : {stderr}")
                    
                except subprocess.CalledProcessError as e:
                    print("[Real-time Prediction] Error occurred : ", e.stderr)
                except FileNotFoundError:
                    print("[Real-time Prediction] The file path is incorrect, or the Python executable could not be found.")                
                except Exception as e:
                    print("[Real-time Prediction] Exception occurred : ", e)                

        else:
            if not os.path.isfile(logfilePath):
                logFile = open(logfilePath, 'w')
            else:
                logFile = open(logfilePath, 'a')

            self.txtBox_logRealtime.appendPlainText(str(stdTime) + "_error")
            logFile.write(str(stdTime) + "_error\n")
            logFile.close()

    # ESC_KEY_EVENT
    def keyPressEvent(self, event):
        # ESC 또는 Enter 키를 눌렀을 때 아무 동작도 하지 않음
        if event.key() == Qt.Key_Escape or event.key() == Qt.Key_Return:
            event.ignore()  # 키 이벤트를 무시하여 기본 동작을 방지
        else:
            super().keyPressEvent(event)

# 데이터셋 그래프 화면
class PyWPdsGraph(QDialog):

    def __init__(self, dataHeader, dataOriginal):        

        super().__init__()
        # set_plugin_path
        program_path = os.path.dirname(__file__)  
        # 아이콘 설정
        self.setWindowIcon(QIcon(os.path.join(program_path,'icon.png')))

        self.setWindowTitle("Dataset Graph")
        self.setMinimumSize(1000, 600)

        self.setWindowFlags(Qt.Window | 
                            Qt.WindowMinimizeButtonHint | 
                            Qt.WindowCloseButtonHint)
        
        palette = QPalette()
        palette.setColor(QPalette.Window, QColor("white"))
        self.setPalette(palette)
        self.setAutoFillBackground(True)

        # 데이터셋 그래프 자료 셋팅하기
        self.arrHeader = dataHeader
        self.arrDatas = dataOriginal

        # 전체 레이아웃
        main_layout = QVBoxLayout()
        self.setLayout(main_layout)

        # [1] 상단 조회 영역
        search_layout = QHBoxLayout()        
        search_layout.setSpacing(10)

        self.lbl_title = QLabel("[Dataset Period Information]")
        self.lbl_title.setFixedHeight(31)
        self.lbl_title.setAlignment(Qt.AlignCenter)

        self.dt_data_startTime = QDateEdit()
        self.dt_data_startTime.setDate(QDate(2011, 1, 1))
        self.dt_data_startTime.setCalendarPopup(True)
        self.dt_data_startTime.setFixedHeight(31)

        self.dt_data_endTime = QDateEdit()
        self.dt_data_endTime.setDate(QDate(2011, 12, 31))
        self.dt_data_endTime.setCalendarPopup(True)
        self.dt_data_endTime.setFixedHeight(31)

        btn_reDraw = QPushButton("Search")
        btn_reDraw.clicked.connect(self.setData)
        btn_reDraw.setFixedHeight(31)
        
        btn_allDraw = QPushButton("View All")
        btn_allDraw.clicked.connect(self.resetData)
        btn_allDraw.setFixedHeight(31)

        search_layout.addWidget(QLabel("Query Period : "))
        search_layout.addWidget(self.lbl_title)
        search_layout.addWidget(self.dt_data_startTime)
        search_layout.addWidget(QLabel("~"))
        search_layout.addWidget(self.dt_data_endTime)
        search_layout.addWidget(btn_reDraw)        
        search_layout.addWidget(btn_allDraw)      
        search_layout.addStretch()

        #main_layout.addLayout(search_layout)

        # 하단 그래프 영역
        from PyQt5.QtWebEngineWidgets import QWebEngineView

        self.web_view = QWebEngineView()
        main_layout.addWidget(self.web_view)
        
        self.initControl()
        self.setData()


    def initControl(self):       

        # 데이터셋 그래프 자료 셋팅하기
        # graph_data_set
        self.x_date = [i[1] for i in self.arrDatas[0]]

        # 조회기간 설정
        self.dt_data_startTime.setDateTime(self.arrDatas[0][0][1])
        self.dt_data_endTime.setDateTime(self.arrDatas[0][len(self.arrDatas[0])-1][1])

        startDatetime = self.dt_data_startTime.dateTime().toString("yyyy-MM-dd HH:mm")
        endDatetime = self.dt_data_endTime.dateTime().toString("yyyy-MM-dd HH:mm")

        strLblText = "[Dataset Period Information] {0} ~ {1}".format(startDatetime, endDatetime)
        dateLblText = "Dataset Graph Period Information ({0} ~ {1})".format(startDatetime, endDatetime)

        self.setWindowTitle(dateLblText)

        # init_title
        self.lbl_title.setText(strLblText)

    # ESC_KEY_EVENT
    def keyPressEvent(self, event):
        # ESC 또는 Enter 키를 눌렀을 때 아무 동작도 하지 않음
        if event.key() == Qt.Key_Escape or event.key() == Qt.Key_Return:
            event.ignore()  # 키 이벤트를 무시하여 기본 동작을 방지
        else:
            super().keyPressEvent(event)    
   
    # 전체보기 버튼 이벤트
    def resetData(self):
        self.initControl()
        self.setData()

    # 데이터초기화 (컨트롤 값, 배열분할)
    def setData(self):        

        # graph_data_set
        self.x_date = [i[1] for i in self.arrDatas[0]]

        # 데이터셋 데이터종류(table) 셋팅하기
        nb_row = len(self.arrHeader) - 1
        nb_col = 1
        self.model_col = QtGui.QStandardItemModel()
        for idx in range(len(self.arrDatas)):
            itemData = self.arrHeader[idx + 1]
            if ('Leadtime_' in itemData) == False:
                item = QtGui.QStandardItem(itemData)
                item.setCheckable(True)
                item.setCheckState(QtCore.Qt.Checked)
                self.model_col.appendRow(item)

        # 그래프 초기화
        import plotly.graph_objs as go
        import plotly.io as pio
        import random

        strStartDate = self.dt_data_startTime.dateTime().toString("yyyy-MM-dd")
        strEndDate = self.dt_data_endTime.dateTime().toString("yyyy-MM-dd")

        strTitle = "{0} ~ {1}".format(strStartDate, strEndDate)

        # 데이터셋 그래프그리기
        # x축 데이터, y축 데이터
        layout = go.Layout(
            font=dict(family="Malgun Gothic, sans-serif"),  
            xaxis=dict(
                title="time",
                tickformat="%Y-%m-%d %H:%M",   
            ),
            yaxis=dict(title="data"),
            legend=dict(
                x=1.05,             
                y=1,                
                xanchor='left',     
                yanchor='top',     
                bgcolor='rgba(255,255,255,0.5)',  
            ),
        )

        myfig = go.Figure(layout=layout)

        # date
        x_dateMonth = [str(i)[0:10] for i in self.x_date]
        startIdx = x_dateMonth.index(strStartDate) if strStartDate in x_dateMonth else 0

        x_dateMonth.reverse()
        endIdx = (len(x_dateMonth) - x_dateMonth.index(strEndDate) - 1) if strEndDate in x_dateMonth else len(x_dateMonth)-1

        # 조회기간 설정
        self.dt_data_startTime.setDateTime(self.arrDatas[0][startIdx][1])
        self.dt_data_endTime.setDateTime(self.arrDatas[0][endIdx][1])

        # data
        x_data = self.x_date[startIdx : endIdx + 1]
        arr_ydata = []
        for idx in range(len(self.arrDatas)):
            y_temp = [self.convert_data_nullToNan(i[2]) for i in self.arrDatas[idx][startIdx : endIdx + 1]]
            arr_ydata.append(y_temp)

        for idx in range(len(self.arrDatas)):
            itemData = self.arrHeader[idx + 1]
            if ('Leadtime_' in itemData) == False:
                myfig.add_trace(go.Scatter(x=x_data, y=arr_ydata[idx], mode='lines', name=itemData))
        
        # 레이아웃 및 인터랙션 설정
        myfig.update_layout(
            xaxis=dict(title='Time', rangeslider_visible=True),
            yaxis=dict(title='Value'),
            margin=dict(l=0, r=60, t=30, b=0),
            legend=dict(x=1.02, y=1, xanchor='left', yanchor='top')
        )
        
        # HTML로 임시 저장
        with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as f:
            temp_html_path = f.name
            myfig.write_html(temp_html_path)

        # QWebEngineView에 HTML 로드
        self.web_view.load(QtCore.QUrl.fromLocalFile(temp_html_path))         

    # 데이터 조회 시, NULL 값 체크해서 변환하는 함수
    def convert_data_nullToNan(self, data):
        if str(data) == 'None':
            return np.NAN
        else:
            return float(data)

# DashBoard 화면
class DashBoard(QDialog):    
    
    def __init__(self, model_rt_path, modelObservation_path, lst_model, lst_year, lst_riverRegion, lst_modelName, lst_infName):

        super().__init__()

        self.ui = uic.loadUi(os.path.join(os.path.dirname(__file__), 'waterlevel_prediction_dashboard_base.ui'), self)
        # set_plugin_path
        program_path = os.path.dirname(__file__)  
        # 아이콘 설정
        self.setWindowIcon(QIcon(os.path.join(program_path,'icon.png')))
        
        self.setWindowFlags(Qt.Window | 
                            Qt.WindowMinimizeButtonHint | 
                            Qt.WindowCloseButtonHint)
        
        self.riverRegion = ''
        self.target_point = ''
        self.model = ''
        self.year = ''

        self.BASIC = 0
        self.PREDRF = 1
        self.SCENARIO = 2                      
                        
        self.basic_validation_path = ''
        self.basic_inference_path = ''
        self.basic_validation_fileNm = ''
        self.basic_inference_fileNm = ''

        self.predRf_validation_path = ''
        self.predRf_inference_path = ''
        self.predRf_validation_fileNm = ''
        self.predRf_inference_fileNm = ''

        self.sce_validation_path = ''
        self.sce_inference_path = ''
        self.sce_validation_fileNm = ''
        self.sce_inference_fileNm = ''

        #global checked_list     
        self.checked_list = []

        self.modelFolder = lst_model      #['Basic', 'Predict_RF', 'Scenario']
        self.validationFolder = lst_modelName      #['WL_{}_timeseries', 'Predict_RF_WL_{}_timeseries', 'Scenario_WL_{}_timeseries']
        self.inferenceFolder = lst_infName   #[inference_모델명]
        
        # model&file_path_initialize
        self.model_root_path = model_rt_path         #model_root_folder_path
        self.obs_root_path = modelObservation_path   #관측소제원정보_folder_path

        # basic_model - validation, inference 결과파일(*.csv)
        self.basic_validation_fileNm = 'predict_result_{}_timeseries_drop-out_{}_seq_length_{}.csv'  
        self.basic_inference_fileNm = 'predict_result_{}_timeseries_seq_length_ChangeValue.csv'

        # predict_rainfall_model - validation, inference 결과파일(*.csv) - realtime/none
        self.predRf_validation_fileNm = 'predict_result_{}_timeseries_drop-out_{}_seq_length_{}.csv'        
        self.predRf_inference_fileNm = 'predict_result_{}_timeseries_seq_length_ChangeValue.csv'
        
        # scenario_model - validation, inference 결과파일(*.csv)
        self.sce_validation_fileNm = 'predict_result_{}_timeseries_drop-out_{}_seq_length_{}.csv'
        self.sce_inference_fileNm = 'predict_result_{}_timeseries_seq_length_ChangeValue.csv'
        
        # control_initialize       
        if (len(self.modelFolder)>0):
            self.txtBox_modelName.setText(self.modelFolder[self.BASIC])

        self.cb_year.clear()
        self.cb_riverRegion.clear()
        self.cb_targetPoint.clear()        
        if (len(lst_year)>0):   #['2022', '2023', '2024']

            lst_year.sort()
            for year in lst_year:
                self.cb_year.addItem(str(year))

        if (len(lst_riverRegion)>0): #['Han', 'Nakdong', 'Yeongsan', 'Guem']
            for region in lst_riverRegion:
                self.cb_riverRegion.addItem(str(region))                   

        # comtrol - basic_model_information
        self.btn_basicValidation_prev.clicked.connect(self.Draw_Basic_Graph_Validation_Prev)
        self.btn_basicValidation_next.clicked.connect(self.Draw_Basic_Graph_Validation_Next)        
        self.cb_basicValidation.currentIndexChanged.connect(self.Draw_Basic_Graph_Validation)

        self.btn_basicInference_prev.clicked.connect(self.Draw_Basic_Graph_Inference_Prev)
        self.btn_basicInference_next.clicked.connect(self.Draw_Basic_Graph_Inference_Next)  
        self.cb_basicInference.currentIndexChanged.connect(self.Draw_Basic_Graph_Inference)
        
        self.btn_basic_pc_time_prev.clicked.connect(self.Draw_Basic_Graph_PerformanceCheck_Prev)
        self.btn_basic_pc_time_next.clicked.connect(self.Draw_Basic_Graph_PerformanceCheck_Next)   
        self.btn_basic_pc_search.clicked.connect(self.Set_Basic_Combobox_PerformanceCheck_Time) 

        self.rb_basic_pd_interval1.clicked.connect(self.Set_Basic_Combobox_PerformanceCheck_Time)
        self.rb_basic_pd_interval2.clicked.connect(self.Set_Basic_Combobox_PerformanceCheck_Time)
        self.rb_basic_pd_interval3.clicked.connect(self.Set_Basic_Combobox_PerformanceCheck_Time)

        self.btn_basic_saveGraphValidation.clicked.connect(self.Save_Basic_ImgValidation_SavePath)

        self.btn_basic_saveGraphInference.clicked.connect(self.Save_Basic_ImgInference_SavePath)

        self.btn_basic_saveGraphPC.clicked.connect(self.Save_Basic_ImgPerformanceCheck_SavePath)

        self.cb_basic_pc_time.currentIndexChanged.connect(self.Draw_Basic_Graph_PerformanceCheck)      

        # control - predict_rainfall_model_information        
        self.rb_predValidation_origin.clicked.connect(self.Draw_PredictRF_Graph_Validation_type)
        self.rb_predValidation_realtime.clicked.connect(self.Draw_PredictRF_Graph_Validation_type)        
        self.rb_predInference_origin.clicked.connect(self.Draw_PredictRF_Graph_Inference_type)
        self.rb_predInference_realtime.clicked.connect(self.Draw_PredictRF_Graph_Inference_type)

        self.btn_predRfValidation_prev.clicked.connect(self.Draw_PredictRF_Graph_Validation_Prev)
        self.btn_predRfValidation_next.clicked.connect(self.Draw_PredictRF_Graph_Validation_Next)    
        self.cb_predRfValidation.currentIndexChanged.connect(self.Draw_PredictRF_Graph_Validation)

        self.btn_predRfInference_prev.clicked.connect(self.Draw_PredictRF_Graph_Inference_Prev)
        self.btn_predRfInference_next.clicked.connect(self.Draw_PredictRF_Graph_Inference_Next) 
        self.cb_predRfInference.currentIndexChanged.connect(self.Draw_PredictRF_Graph_Inference)        

        self.btn_predRf_pc_time_prev.clicked.connect(self.Draw_PredictRF_Graph_PerformanceCheck_Prev)
        self.btn_predRf_pc_time_next.clicked.connect(self.Draw_PredictRF_Graph_PerformanceCheck_Next) 
        self.btn_predRf_pc_search.clicked.connect(self.Set_PredictRF_Combobox_PerformanceCheck_Time)   

        self.rb_predRf_pd_interval1.clicked.connect(self.Set_PredictRF_Combobox_PerformanceCheck_Time)
        self.rb_predRf_pd_interval2.clicked.connect(self.Set_PredictRF_Combobox_PerformanceCheck_Time)
        self.rb_predRf_pd_interval3.clicked.connect(self.Set_PredictRF_Combobox_PerformanceCheck_Time)
        
        self.btn_rf_saveGraphValidation.clicked.connect(self.Save_PredictRF_ImgValidation_SavePath)

        self.btn_rf_saveGraphInference.clicked.connect(self.Save_PredictRF_ImgInference_SavePath)

        self.btn_rf_saveGraphPC.clicked.connect(self.Save_PredictRF_ImgPerformanceCheck_SavePath)
        
        self.cb_predRf_pc_time.currentIndexChanged.connect(self.Draw_PredictRF_Graph_PerformanceCheck)

        # control - scenario_model_information
        self.btn_sceValidation_prev.clicked.connect(self.Draw_Scenario_Graph_Validation_Prev)
        self.btn_sceValidation_next.clicked.connect(self.Draw_Scenario_Graph_Validation_Next)        
        self.cb_sceValidation.currentIndexChanged.connect(self.Draw_Scenario_Graph_Validation)

        self.btn_sceInference_prev.clicked.connect(self.Draw_Scenario_Graph_Inference_Prev)
        self.btn_sceInference_next.clicked.connect(self.Draw_Scenario_Graph_Inference_Next)  
        self.cb_sceInference.currentIndexChanged.connect(self.Draw_Scenario_Graph_Inference)
        
        self.btn_sce_pc_time_prev.clicked.connect(self.Draw_Scenario_Graph_PerformanceCheck_Prev)
        self.btn_sce_pc_time_next.clicked.connect(self.Draw_Scenario_Graph_PerformanceCheck_Next)   
        self.btn_sce_pc_search.clicked.connect(self.Set_Scenario_Combobox_PerformanceCheck_Time) 

        self.rb_sce_pd_interval1.clicked.connect(self.Set_Scenario_Combobox_PerformanceCheck_Time)
        self.rb_sce_pd_interval2.clicked.connect(self.Set_Scenario_Combobox_PerformanceCheck_Time)
        self.rb_sce_pd_interval3.clicked.connect(self.Set_Scenario_Combobox_PerformanceCheck_Time)
        
        self.btn_sce_saveGraphValidation.clicked.connect(self.Save_Scenario_ImgValidation_SavePath)

        self.btn_sce_saveGraphInference.clicked.connect(self.Save_Scenario_ImgInference_SavePath)

        self.btn_sce_saveGraphPC.clicked.connect(self.Save_Scenario_ImgPerformanceCheck_SavePath)

        self.cb_sce_pc_time.currentIndexChanged.connect(self.Draw_Scenario_Graph_PerformanceCheck)

        # control - export_reporting        
        self.btn_exportReport.clicked.connect(self.ExportReport)
        
        # control - dash board info control setting
        self.cb_year.currentIndexChanged.connect(self.SetCombobox_TargetPoint)
        self.cb_riverRegion.currentIndexChanged.connect(self.SetCombobox_TargetPoint)
        self.cb_targetPoint.currentIndexChanged.connect(self.SetObservationInfo)

        # control - graph   
        self.target_fig = plt.Figure()
        self.target_canvas = FigureCanvas(self.target_fig)
        self.vl_targetDataGraph.addWidget(self.target_canvas)     
        self.target_ax = self.target_fig.add_subplot(111)
        self.target_fig.tight_layout()
        self.target_canvas.draw()
        
        self.ref_fig = plt.Figure()
        self.ref_canvas = FigureCanvas(self.ref_fig)
        self.vl_referenceDataGraph.addWidget(self.ref_canvas)
        self.ref_ax = self.ref_fig.add_subplot(111)
        self.ref_ax = self.ref_fig.add_subplot(111)
        self.ref_fig.tight_layout()
        self.ref_canvas.draw()
                
        self.basic_val_fig = plt.Figure()
        self.basic_val_canvas = FigureCanvas(self.basic_val_fig)
        self.vl_basicValidation.addWidget(self.basic_val_canvas)
        self.basic_val_ax = self.basic_val_fig.add_subplot(111)
        self.basic_val_fig.tight_layout()
        self.basic_val_canvas.draw()   
                
        self.basic_inf_fig = plt.Figure()
        self.basic_inf_canvas = FigureCanvas(self.basic_inf_fig)
        self.vl_basicInference.addWidget(self.basic_inf_canvas)
        self.basic_inf_ax = self.basic_inf_fig.add_subplot(111)
        self.basic_inf_fig.tight_layout()
        self.basic_inf_canvas.draw()
        
        self.basic_pc_fig = plt.Figure()
        self.basic_pc_canvas = FigureCanvas(self.basic_pc_fig)
        self.vl_basicPerformanceCheck.addWidget(self.basic_pc_canvas)
        self.basic_pc_ax = self.basic_pc_fig.add_subplot(111)
        self.basic_pc_fig.tight_layout()
        self.basic_pc_canvas.draw()
        
        self.predRF_val_fig = plt.Figure()
        self.predRF_val_canvas = FigureCanvas(self.predRF_val_fig)
        self.vl_predValidation.addWidget(self.predRF_val_canvas)
        self.predRF_val_ax = self.predRF_val_fig.add_subplot(111)
        self.predRF_val_fig.tight_layout()
        self.predRF_val_canvas.draw()               
        
        self.predRF_inf_fig = plt.Figure()
        self.predRF_inf_canvas = FigureCanvas(self.predRF_inf_fig)
        self.vl_predInference.addWidget(self.predRF_inf_canvas)
        self.predRF_inf_ax = self.predRF_inf_fig.add_subplot(111)
        self.predRF_inf_fig.tight_layout()
        self.predRF_inf_canvas.draw()

        self.predRF_pc_fig = plt.Figure()
        self.predRF_pc_canvas = FigureCanvas(self.predRF_pc_fig)
        self.vl_predPerformanceCheck.addWidget(self.predRF_pc_canvas)
        self.predRF_pc_ax = self.predRF_pc_fig.add_subplot(111)
        self.predRF_pc_fig.tight_layout()
        self.predRF_pc_canvas.draw()

        self.sce_val_fig = plt.Figure()
        self.sce_val_canvas = FigureCanvas(self.sce_val_fig)
        self.vl_sceValidation.addWidget(self.sce_val_canvas)
        self.sce_val_ax = self.sce_val_fig.add_subplot(111)
        self.sce_val_fig.tight_layout()
        self.sce_val_canvas.draw()     

        self.sce_inf_fig = plt.Figure()
        self.sce_inf_canvas = FigureCanvas(self.sce_inf_fig)
        self.vl_sceInference.addWidget(self.sce_inf_canvas)
        self.sce_inf_ax = self.sce_inf_fig.add_subplot(111)
        self.sce_inf_fig.tight_layout()
        self.sce_inf_canvas.draw()

        self.sce_pc_fig = plt.Figure()
        self.sce_pc_canvas = FigureCanvas(self.sce_pc_fig)
        self.vl_scePerformanceCheck.addWidget(self.sce_pc_canvas)
        self.sce_pc_ax = self.sce_pc_fig.add_subplot(111)
        self.sce_pc_fig.tight_layout()
        self.sce_pc_canvas.draw()
        
        # label 초기화        
        lst_linkedLabel = [
            self.lbl_targetPointFile,
            self.lbl_refPointFile,
            self.lbl_basicValidation,
            self.lbl_basicInference,
            self.lbl_basicPerformanceCheck,
            self.lbl_predValidation,
            self.lbl_predInference,
            self.lbl_predPerformanceCheck,
            self.lbl_sceValidation,
            self.lbl_sceInference,
            self.lbl_scePerformanceCheck]

        for lbl in lst_linkedLabel:
            lbl_text = '<a href="{}" style="color: gray; text-decoration: underline; font-weight: bold;">View File Info</a>'.format(lbl.objectName())
            lbl.setText(lbl_text)
            lbl.setOpenExternalLinks(False)
            lbl.linkActivated.connect(self.GetDashboardFileInfo)
        
        # model_infomation (target & reference)          
        self.SetCombobox_TargetPoint()           

        # show
        self.show()

    # ESC_KEY_EVENT
    def keyPressEvent(self, event):
        # ESC 또는 Enter 키를 눌렀을 때 아무 동작도 하지 않음
        if event.key() == Qt.Key_Escape or event.key() == Qt.Key_Return:
            event.ignore()  # 키 이벤트를 무시하여 기본 동작을 방지
        else:
            super().keyPressEvent(event)

    # [Initialize_control]
    def chart_initialize(self, fig, ax, canvas):
        fig.clf()
        ax = fig.add_subplot(111)
        fig.tight_layout()
        fig.subplots_adjust(left=0.1, right=0.95, top=0.9, bottom=0.2)

        x_labels_cnt = []
        x_labels_name = []
        # draw_reference_graphs
        ax.set_xticks(x_labels_cnt)
        ax.set_xticklabels(x_labels_name, size=6)     
        for tl in ax.yaxis.get_majorticklabels():
            tl.set_fontsize(6)

        ax.legend(prop={'size': 8})

        canvas.draw()

    def Init_Controls(self):

        # 1. graph_초기화
        self.chart_initialize(self.target_fig, self.target_ax, self.target_canvas)       
        self.chart_initialize(self.ref_fig, self.ref_ax, self.ref_canvas)
        self.chart_initialize(self.basic_val_fig, self.basic_val_ax, self.basic_val_canvas)
        self.chart_initialize(self.basic_inf_fig, self.basic_inf_ax, self.basic_inf_canvas)
        self.chart_initialize(self.basic_pc_fig, self.basic_pc_ax, self.basic_pc_canvas)
        self.chart_initialize(self.predRF_val_fig, self.predRF_val_ax, self.predRF_val_canvas)
        self.chart_initialize(self.predRF_inf_fig, self.predRF_inf_ax, self.predRF_inf_canvas)
        self.chart_initialize(self.predRF_pc_fig, self.predRF_pc_ax, self.predRF_pc_canvas)
        self.chart_initialize(self.sce_val_fig, self.sce_val_ax, self.sce_val_canvas)
        self.chart_initialize(self.sce_inf_fig, self.sce_inf_ax, self.sce_inf_canvas)
        self.chart_initialize(self.sce_pc_fig, self.sce_pc_ax, self.sce_pc_canvas)

        # 2. table_widget 초기화
        self.tbl_targetInfo.clearContents()        
        self.tbl_referenceInfo.clearContents()        
        self.tbl_basicValidation.clearContents()        
        self.tbl_basicInference.clearContents()        
        self.tbl_predValidation.clearContents()        
        self.tbl_predInference.clearContents()        
        self.tbl_sceValidation.clearContents()        
        self.tbl_sceInference.clearContents()

        # 3. combobox 초기화
        self.cb_basicValidation.clear()        
        self.cb_basicInference.clear()        
        self.cb_predRfValidation.clear()        
        self.cb_predRfInference.clear()
        self.cb_sceValidation.clear()        
        self.cb_sceInference.clear()   
        self.cb_basic_pc_time.clear()
        self.cb_predRf_pc_time.clear()
        self.cb_sce_pc_time.clear()

        # radiobutton
        self.rb_predValidation_origin.setChecked(True)
        self.rb_predInference_origin.setChecked(True)
        self.rb_predRf_pd_interval1.setChecked(True)
        self.rb_basic_pd_interval1.setChecked(True)
        self.rb_sce_pd_interval1.setChecked(True)

    def GetDashboardFileInfo(self, link):
        
        msg = ''

        if link == "lbl_targetPointFile":
            
            # dataset_graph (target_point & ref_point)
            path_dataset = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point,'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))        
            if os.path.isfile(path_dataset):                
                msg = f"[Target Point File Information]\n{path_dataset} exists."
            else:                            
                msg = f"[Target Point File Information]\n{path_dataset} does not exist."

        elif link == "lbl_refPointFile":

            ref_obs_list = []
            for i in range(len(self.checked_list)):
                if self.checked_list[i].checkState() == QtCore.Qt.Checked:
                    obs_type = str(self.tbl_referenceInfo.item(i, 1).text())  
                    obs_code = str(self.tbl_referenceInfo.item(i, 2).text()) 
                    obs_name = '{}_{}'.format(obs_type, obs_code)     
                    ref_obs_list.append(obs_name)

            # get_reference_point_info
            if (len(ref_obs_list) > 0):
                model_name = self.validationFolder[self.BASIC].format(self.target_point)                
                # get_basic_model_dataset_file (basic_model > year > target_point > file 사용. modelparam의 dataset_path는 경로가 달라서 사용하지않음.)     
                path_dataset = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point,'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))                    
                if os.path.isfile(path_dataset):
                    msg = f"[Reference Point File Information]\n{path_dataset} exists."
                else:                            
                    msg = f"[Reference Point File Information]\n{path_dataset} does not exist."
            else:
                return

        elif link == "lbl_basicValidation":

            # validation
            model_name = self.validationFolder[self.BASIC].format(self.target_point)
            nse_name = 'nse_{}.csv'.format(self.target_point)
            nse_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, model_name, nse_name)        
            validation_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, model_name, self.basic_validation_path)   
            param_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, model_name, 'modelParam.txt')        
            
            if os.path.isfile(nse_path):
                msg = f"[NSE File Information]\n{nse_path} exists."
            else:                            
                msg = f"[NSE File Information]\n{nse_path} does not exist."
                
            if os.path.isfile(validation_path):
                msg += f"[Validation File Information]\n{validation_path} exists."
            else:                            
                msg += f"[Validation File Information]\n{validation_path} does not exist."            

        elif link == "lbl_basicInference":

            # inference
            inference_name = self.inferenceFolder[self.BASIC].format(self.target_point)   
            nse_name = 'nse_{}.csv'.format(self.target_point)
            nse_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, inference_name, nse_name)  
            inference_path = os.path.join(self.model_root_path , self.model, self.year, self.riverRegion, self.target_point, inference_name, self.basic_inference_path)
  
            if os.path.isfile(nse_path):
                msg = f"[NSE File Information]\n{nse_path} exists."
            else:                            
                msg = f"[NSE File Information]\n{nse_path} does not exist."
                
            if os.path.isfile(inference_path):
                msg += f"[Inference File Information]\n{inference_path} exists."
            else:                            
                msg += f"[Inference File Information]\n{inference_path} does not exist."                        

        elif link == "lbl_basicPerformanceCheck":

            # performancecheck
            target_waterlevel = os.path.join(self.obs_root_path, 'target_waterlevel.csv') 

            # set_inference_foldername
            inference_name = self.inferenceFolder[self.BASIC].format(self.target_point)   

            # 2022_to_2023_inference_file
            year_inf = '2023'
            if (self.cb_year.count() >= self.cb_year.currentIndex()+1):
                year_inf = self.cb_year.itemText(self.cb_year.currentIndex()+1)
                    
            # 2022_to_2023_inference_file
            inference_path =  os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, inference_name, self.basic_inference_path)

            # 2023_model_dataset
            file_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], year_inf, self.riverRegion, self.target_point)
            dataset_filepath = os.path.join(file_path, 'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))

            if os.path.isfile(inference_path):
                msg = f"[{self.year}Dataset File Information]\n{inference_path} exists."
            else:                            
                msg = f"[{self.year}Dataset File Information]\n{inference_path} does not exist."
                
            if os.path.isfile(dataset_filepath):
                msg += f"[{year_inf}Dataset File Information]\n{dataset_filepath} exists."
            else:                            
                msg += f"[{year_inf}Dataset File Information]\n{dataset_filepath} does not exist."       
            
        elif link == "lbl_predValidation":

            # get_model_name
            model_name = '' 
            if (self.rb_predValidation_origin.isChecked()):
                model_name = self.validationFolder[self.PREDRF].format(self.target_point)      
            else:
                model_name = 'Realtime_{}'.format(self.validationFolder[self.PREDRF].format(self.target_point))
        
            # get_validation_data
            nse_name = 'nse_{}.csv'.format(self.target_point)
            nse_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, model_name, nse_name)

            # get_validation_file      
            validation_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, model_name, self.predRf_validation_path)
   
            if os.path.isfile(nse_path):
                msg = f"[NSE File Information]\n{nse_path} exists."
            else:                            
                msg = f"[NSE File Information]\n{nse_path} does not exist."
                
            if os.path.isfile(validation_path):
                msg += f"[Validation File Information]\n{validation_path} exists."
            else:                            
                msg += f"[Validation File Information]\n{validation_path} does not exist."   
            
        elif link == "lbl_predInference":

            # get_inference_file_name
            inference_name = ''
            if (self.rb_predInference_origin.isChecked()):
                inference_name = self.inferenceFolder[self.PREDRF].format(self.target_point)   
            else:
                inference_name = 'inference_Realtime_{}'.format(self.validationFolder[self.PREDRF].format(self.target_point))       

            # initialize_control
            nse_name = 'nse_{}.csv'.format(self.target_point)
            nse_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, inference_name, nse_name)

            # validation - data
            inference_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, inference_name, self.predRf_inference_path)
            
            if os.path.isfile(nse_path):
                msg = f"[NSE File Information]\n{nse_path} exists."
            else:                            
                msg = f"[NSE File Information]\n{nse_path} does not exist."
                
            if os.path.isfile(inference_path):
                msg += f"[Inference File Information]\n{inference_path} exists."
            else:                            
                msg += f"[Inference File Information]\n{inference_path} does not exist."   
            
        elif link == "lbl_predPerformanceCheck":

            # target_point_alarm_info
            target_waterlevel = os.path.join(self.obs_root_path, 'target_waterlevel.csv')

            # set_inference_foldername
            inference_name = self.inferenceFolder[self.PREDRF].format(self.target_point)   
                    
            # 2022_to_2023_inference_file
            year_inf = '2023'
            if (self.cb_year.count() >= self.cb_year.currentIndex()+1):
                year_inf = self.cb_year.itemText(self.cb_year.currentIndex()+1)

            inference_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, inference_name, self.predRf_inference_path)
            
            # 2023_model_dataset
            file_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], year_inf, self.riverRegion, self.target_point)
            dataset_filepath = os.path.join(file_path, 'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))

            if os.path.isfile(inference_path):
                msg = f"[{self.year}Dataset File Information]\n{inference_path} exists."
            else:                            
                msg = f"[{self.year}Dataset File Information]\n{inference_path} does not exist."
                
            if os.path.isfile(dataset_filepath):
                msg += f"[{year_inf}Dataset File Information]\n{dataset_filepath} exists."
            else:                            
                msg += f"[{year_inf}Dataset File Information]\n{dataset_filepath} does not exist."      
            
        elif link == "lbl_sceValidation":

            # get_model_name 
            model_name = self.validationFolder[self.SCENARIO].format(self.target_point)        
                
            # 1. validation(nse) info(nse table, nse시간콤보박스선택에 따라 graph표출)  
            nse_name = 'nse_{}.csv'.format(self.target_point)
            nse_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, model_name, nse_name)
            validation_path = os.path.join(self.model_root_path , "Scenario", self.year, self.riverRegion, self.target_point, model_name, self.sce_validation_path)

            if os.path.isfile(nse_path):
                msg = f"[NSE File Information]\n{nse_path} exists."
            else:                            
                msg = f"[NSE File Information]\n{nse_path} does not exist."
                
            if os.path.isfile(validation_path):
                msg += f"[Validation File Information]\n{validation_path} exists."
            else:                            
                msg += f"[Validation File Information]\n{validation_path} does not exist."      
            
        elif link == "lbl_sceInference":

            inference_name = self.inferenceFolder[self.SCENARIO].format(self.target_point)   
            nse_name = 'nse_{}.csv'.format(self.target_point)
            nse_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, inference_name, nse_name)
            inference_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, inference_name, self.sce_inference_path)

            if os.path.isfile(nse_path):
                msg = f"[NSE File Information]\n{nse_path} exists."
            else:                            
                msg = f"[NSE File Information]\n{nse_path} does not exist."
                
            if os.path.isfile(inference_path):
                msg += f"[Inference File Information]\n{inference_path} exists."
            else:                            
                msg += f"[Inference File Information]\n{inference_path} does not exist."                         
            
        elif link == "lbl_scePerformanceCheck":

            # target_point_alarm_info
            target_waterlevel = os.path.join(self.obs_root_path, 'target_waterlevel.csv')

            # set_inference_foldername
            inference_name = self.inferenceFolder[self.SCENARIO].format(self.target_point)   

            # 2022_to_2023_inference_file
            year_inf = '2023'
            if (self.cb_year.count() >= self.cb_year.currentIndex()+1):
                year_inf = self.cb_year.itemText(self.cb_year.currentIndex()+1)

            # 2022_to_2023_inference_file
            inference_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, inference_name, self.sce_inference_path)
                    
            # 2023_model_dataset
            file_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], year_inf, self.riverRegion, self.target_point)
            dataset_filepath = os.path.join(file_path, 'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))    

            if os.path.isfile(inference_path):
                msg = f"[{self.year}Dataset File Information]\n{inference_path} exists."
            else:                            
                msg = f"[{self.year}Dataset File Information]\n{inference_path} does not exist."
                
            if os.path.isfile(dataset_filepath):
                msg += f"[{year_inf}Dataset File Information]\n{dataset_filepath} exists."
            else:                            
                msg += f"[{year_inf}Dataset File Information]\n{dataset_filepath} does not exist."         
        
        else:
            return 

        QMessageBox.information(self, "Dashboard File Information", msg)

    # [Info] : Combobox_Event - 연도설정 및 권역설정 변경시,
    def SetCombobox_TargetPoint(self):
        
        self.cb_targetPoint.clear()

        model = self.txtBox_modelName.text()
        year = self.cb_year.currentText()
        riverRegion = self.cb_riverRegion.currentText()

        path_targetPoint = os.path.join(self.model_root_path , model, year, riverRegion)        
        if not os.path.exists(path_targetPoint):
            return
        
        lst_targetPoint = os.listdir(path_targetPoint)       
        if (len(lst_targetPoint)>0):
            for pointNm in lst_targetPoint:
                self.cb_targetPoint.addItem(str(pointNm))    
            
            self.cb_targetPoint.setCurrentIndex(0)       

    # [Info] : Combobox_Event - 수위관측소코드 변경시, 대시보드정보 표출
    def SetObservationInfo(self):      

        # initialize_all_control
        self.Init_Controls()    
                       
        self.model = self.txtBox_modelName.text()
        self.year = self.cb_year.currentText()
        self.riverRegion = self.cb_riverRegion.currentText()
        self.target_point = self.cb_targetPoint.currentText()

        if (self.target_point == ''):
            return
        
        # 0. Target Point Info.
        path_waterlevel_info = os.path.join(self.obs_root_path, 'WL.csv')
        if not os.path.isfile(path_waterlevel_info):
            return
        
        data = pd.read_csv(path_waterlevel_info, encoding='cp949', date_parser=True)
        pd_data = pd.DataFrame(data)

        wl_info = pd_data[pd_data['StationCo'] == int(self.target_point)]

        if not wl_info.empty:
            obs_name = str(wl_info['Name_Kor'].values[0])            
            if ((obs_name == '') or (obs_name == 'nan')):
                obs_name = ''
            obs_begin = str(wl_info['Beginning'].values[0])
            if ((obs_begin == '') or (obs_begin == 'nan')):
                obs_begin = ''
            obs_hydroModel = str(wl_info['Hydro model'].values[0])
            if ((obs_hydroModel == '') or (obs_hydroModel == 'nan')):
                obs_hydroModel = ''
            obs_ratingcurve = str(wl_info['Rating curve'].values[0])
            if ((obs_ratingcurve == '') or (obs_ratingcurve == 'nan')):
                obs_ratingcurve = ''
            obs_basicmodel = str(wl_info['Basic Model'].values[0])
            if ((obs_basicmodel == '') or (obs_basicmodel == 'nan')):
                obs_basicmodel = ''
            obs_predmodel = str(wl_info['Predict Rainfall Model'].values[0])
            if ((obs_predmodel == '') or (obs_predmodel == 'nan')):
                obs_predmodel = ''
            obs_scemodel = str(wl_info['Scenario model'].values[0])   
            if ((obs_scemodel == '') or (obs_scemodel == 'nan')):
                obs_scemodel = ''
            obs_represent = str(wl_info['Representative'].values[0])      
            if ((obs_represent == '') or (obs_represent == 'nan')):
                obs_represent = ''

            labels = ['Name', 'Beginning', 'Hydro model', 'Rating curve', 'Basic Model', 'Predict Rainfall Model', 'Scenario model']
            self.tbl_targetInfo.clearContents()
            nb_row = 1
            nb_col = len(labels)
            self.tbl_targetInfo.setRowCount(nb_row)
            self.tbl_targetInfo.setColumnCount(nb_col)
            self.tbl_targetInfo.setHorizontalHeaderLabels(labels)

            for row in range(nb_row):
                item = QTableWidgetItem(obs_name)
                self.tbl_targetInfo.setItem(row, 0, item)
                self.tbl_targetInfo.setColumnWidth(0, 200)
                self.tbl_targetInfo.item(row, 0).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                item = QTableWidgetItem(obs_begin)
                self.tbl_targetInfo.setItem(row, 1, item)
                self.tbl_targetInfo.setColumnWidth(1, 120)
                self.tbl_targetInfo.item(row, 1).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                item = QTableWidgetItem(obs_hydroModel)
                self.tbl_targetInfo.setItem(row, 2, item)
                self.tbl_targetInfo.setColumnWidth(2, 110)
                self.tbl_targetInfo.item(row, 2).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                item = QTableWidgetItem(obs_ratingcurve)
                self.tbl_targetInfo.setItem(row, 3, item)
                self.tbl_targetInfo.setColumnWidth(3, 110)
                self.tbl_targetInfo.item(row, 3).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                item = QTableWidgetItem(obs_basicmodel)
                self.tbl_targetInfo.setItem(row, 4, item)
                self.tbl_targetInfo.setColumnWidth(4, 160)
                self.tbl_targetInfo.item(row, 4).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                item = QTableWidgetItem(obs_predmodel)
                self.tbl_targetInfo.setItem(row, 5, item)
                self.tbl_targetInfo.setColumnWidth(5, 170)
                self.tbl_targetInfo.item(row, 5).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                item = QTableWidgetItem(obs_scemodel)
                self.tbl_targetInfo.setItem(row, 6, item)
                self.tbl_targetInfo.setColumnWidth(6, 160)
                self.tbl_targetInfo.item(row, 6).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
  
        # 1. Basic Model
        # 1-1. reference_point - info (basic_model > year > riverRegion > targetPoint > basic_modelName > modelParam.txt)  
        model_name = self.validationFolder[self.BASIC].format(self.target_point)
        model_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, model_name, 'modelParam.txt')
        if os.path.isfile(model_path):        
            data = []
            with open(model_path, 'r') as stream:
                for rowdata in csv.reader(stream):
                    data.append(rowdata)

            paramHeader = ['X_data_training_column_list', 'model_name', 'drop_out_rate', 'seq_length']

            lst_referencePoint = []

            #global checked_list
            self.checked_list = []
            file_model_name = ''
            file_drop_out_rate = ''
            file_seq_length = ''

            nb_row = len(data)
            for row in range(nb_row):
                col_text = str(data[row][0])
                if col_text == 'X_data_training_column_list':
                    data_text = str(data[row]).replace('\"', "")
                    tempdatalist = data_text.split(',')
                    strDataInfo = ""
                    for obsIdx in range(len(tempdatalist) - 1):
                        obsData = tempdatalist[obsIdx + 1]
                        strDataInfo += obsData.translate(str.maketrans("", "", "[]'\"")).strip() + ","
                    setText = strDataInfo.rstrip(',')
                    lst_referencePoint = setText.split(',')
                elif col_text == 'model_name':
                    file_model_name = str(data[row][1]).strip()            
                elif col_text == 'drop_out_rate':
                    file_drop_out_rate = str(data[row][1]).strip()    
                elif col_text == 'seq_length':
                    file_seq_length = str(data[row][1]).strip()
                else:
                    file_data_txt = 0
            
            self.basic_validation_path = self.basic_validation_fileNm.format(file_model_name, file_drop_out_rate, file_seq_length)
            self.basic_inference_path = self.basic_inference_fileNm.format(file_model_name).replace('ChangeValue', file_seq_length)

            if (len(lst_referencePoint)>0):
                labels = ['No.', 'Type', 'Code', 'Name', 'Beginning', 'Hydro Model', 'Rating curve', 'View']
                self.tbl_referenceInfo.clearContents()
                nb_row = len(lst_referencePoint)
                nb_col = len(labels)
                self.tbl_referenceInfo.setRowCount(nb_row)
                self.tbl_referenceInfo.setColumnCount(nb_col)
                self.tbl_referenceInfo.setHorizontalHeaderLabels(labels)

                nIndex = 0
                for row in range(nb_row):
                    obs_text = lst_referencePoint[row]
                    obs_No = nIndex + 1
                    obs_fileNm = ''
                    obs_type = ''
                    obs_code = ''
                    obs_name = ''
                    obs_begin = ''
                    obs_hydroModel = ''
                    obs_ratingcurve = ''

                    if ('WL' in obs_text):
                        obs_type = obs_text[obs_text.find('WL_'):obs_text.rfind('_')]
                        obs_code = obs_text[obs_text.rfind('_')+1:]
                        obs_fileNm = 'WL.csv'                  
                    elif ('DC' in obs_text):
                        obs_type = obs_text[obs_text.find('DC_'):obs_text.rfind('_')]
                        obs_code = obs_text[obs_text.rfind('_')+1:]
                        obs_fileNm = 'DC.csv'
                    elif ('DI' in obs_text):
                        obs_type = obs_text[obs_text.find('DI_'):obs_text.rfind('_')]
                        obs_code = obs_text[obs_text.rfind('_')+1:]
                        obs_fileNm = 'IN.csv'
                    elif ('DR' in obs_text):
                        obs_type = obs_text[obs_text.find('DR_'):obs_text.rfind('_')]
                        obs_code = obs_text[obs_text.rfind('_')+1:]
                        obs_fileNm = 'REL.csv'
                    elif ('TD' in obs_text):
                        obs_type = obs_text[obs_text.find('TD_'):obs_text.rfind('_')]
                        obs_code = obs_text[obs_text.rfind('_')+1:]
                        obs_fileNm = 'TD.csv'
                    elif ('Predict_WS' in obs_text):
                        obs_type = obs_text[obs_text.find('Predict_WS'):obs_text.rfind('_')]
                        obs_code = obs_text[obs_text.rfind('_')+1:]
                        obs_fileNm = 'WS.csv'
                    elif ('WS' in obs_text):
                        obs_type = obs_text[obs_text.find('WS_'):obs_text.rfind('_')]
                        obs_code = obs_text[obs_text.rfind('_')+1:]                    
                        obs_fileNm = 'WS.csv'
                    elif ('RF_cum' in obs_text):
                        obs_type = obs_text[obs_text.find('RF_cum'):obs_text.rfind('_')]
                        obs_code = obs_text[obs_text.rfind('_')+1:]
                        obs_fileNm = 'RF.csv'
                    elif ('RF' in obs_text):
                        obs_type = obs_text[obs_text.find('RF_'):obs_text.rfind('_')]
                        obs_code = obs_text[obs_text.rfind('_')+1:]
                        obs_fileNm = 'RF.csv'
                    else:
                        obs_type = ''
                        obs_code = ''
                        
                    if ((obs_type != '') and (obs_code != '')):

                        obs_No = nIndex + 1
                        obs_name = ''
                        obs_begin = ''
                        obs_hydroModel = ''
                        obs_ratingcurve = ''

                        path_obsInfo = os.path.join(self.obs_root_path, obs_fileNm)
                        if not os.path.isfile(path_obsInfo):
                            return
                        
                        data = pd.read_csv(path_obsInfo, encoding='cp949', date_parser=True)
                        pd_data = pd.DataFrame(data)  

                        if (obs_type == 'WL'):
                            obs_info = pd_data[pd_data['StationCo'] == int(obs_code)]
                            if not obs_info.empty:
                                obs_name = str(obs_info['Name_Kor'].values[0])
                                if ((obs_name == '') or (obs_name == 'nan')):
                                    obs_name = ''
                                obs_begin = str(obs_info['Beginning'].values[0])
                                if ((obs_begin == '') or (obs_begin == 'nan')):
                                    obs_begin = ''
                                obs_hydroModel = str(obs_info['Hydro model'].values[0])
                                if ((obs_hydroModel == '') or (obs_hydroModel == 'nan')):
                                    obs_hydroModel = ''
                                obs_ratingcurve = str(obs_info['Rating curve'].values[0])
                                if ((obs_ratingcurve == '') or (obs_ratingcurve == 'nan')):
                                    obs_ratingcurve = ''

                        elif (obs_type == 'DC'):
                            obs_info = pd_data[pd_data['obs_code'] == int(obs_code)]
                            if not obs_info.empty:
                                obs_name = str(obs_info['name_K'].values[0])
                                if ((obs_name == '') or (obs_name == 'nan')):
                                    obs_name = ''
                        
                        elif (obs_type == 'DI'):
                            obs_info = pd_data[pd_data['obs_code'] == int(obs_code)]
                            if not obs_info.empty:
                                obs_name = str(obs_info['name_K'].values[0])
                                if ((obs_name == '') or (obs_name == 'nan')):
                                    obs_name = ''
                        
                        elif (obs_type == 'DR'):
                            obs_info = pd_data[pd_data['obs_code'] == int(obs_code)]
                            if not obs_info.empty:
                                obs_name = str(obs_info['name_K'].values[0])
                                if ((obs_name == '') or (obs_name == 'nan')):
                                    obs_name = ''
                        
                        elif (obs_type == 'TD'):
                            obs_info = pd_data[pd_data['obs_code'] == int(obs_code)]
                            if not obs_info.empty:
                                obs_name = str(obs_info['name_K'].values[0])
                                if ((obs_name == '') or (obs_name == 'nan')):
                                    obs_name = ''
                        
                        elif (('Predict_WS' in obs_type) or (obs_type == 'WS')):
                            obs_info = pd_data[pd_data['sbsncd'] == int(obs_code)]
                            if not obs_info.empty:
                                obs_name = str(obs_info['sbsnnm_1'].values[0])
                                if ((obs_name == '') or (obs_name == 'nan')):
                                    obs_name = ''
                        
                        elif (('RF_cum' in obs_type) or (obs_type == 'RF')):
                            obs_info = pd_data[pd_data['obs_code'] == int(obs_code)]
                            if not obs_info.empty:
                                obs_name = str(obs_info['name_K_1'].values[0])
                                if ((obs_name == '') or (obs_name == 'nan')):
                                    obs_name = ''
                                obs_begin = str(obs_info['start_1'].values[0])
                                if ((obs_begin == '') or (obs_begin == 'nan')):
                                    obs_begin = ''
                        
                        else:                            
                            obs_name = ''

                        item = QTableWidgetItem(str(obs_No))
                        self.tbl_referenceInfo.setItem(nIndex, 0, item)
                        self.tbl_referenceInfo.setColumnWidth(0, 80)
                        self.tbl_referenceInfo.item(nIndex, 0).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                        item = QTableWidgetItem(obs_type)
                        self.tbl_referenceInfo.setItem(nIndex, 1, item)
                        self.tbl_referenceInfo.setColumnWidth(1, 140)
                        self.tbl_referenceInfo.item(nIndex, 1).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                        item = QTableWidgetItem(obs_code)
                        self.tbl_referenceInfo.setItem(nIndex, 2, item)
                        self.tbl_referenceInfo.setColumnWidth(2, 130)
                        self.tbl_referenceInfo.item(nIndex, 2).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                        item = QTableWidgetItem(obs_name)
                        self.tbl_referenceInfo.setItem(nIndex, 3, item)
                        self.tbl_referenceInfo.setColumnWidth(3, 200)
                        self.tbl_referenceInfo.item(nIndex, 3).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                        item = QTableWidgetItem(obs_begin)
                        self.tbl_referenceInfo.setItem(nIndex, 4, item)
                        self.tbl_referenceInfo.setColumnWidth(4, 130)
                        self.tbl_referenceInfo.item(nIndex, 4).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                        item = QTableWidgetItem(obs_hydroModel)
                        self.tbl_referenceInfo.setItem(nIndex, 5, item)
                        self.tbl_referenceInfo.setColumnWidth(5, 130)
                        self.tbl_referenceInfo.item(nIndex, 5).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                        item = QTableWidgetItem(obs_ratingcurve)
                        self.tbl_referenceInfo.setItem(nIndex, 6, item)
                        self.tbl_referenceInfo.setColumnWidth(6, 130)
                        self.tbl_referenceInfo.item(nIndex, 6).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                        item = QTableWidgetItem("")
                        self.tbl_referenceInfo.setItem(nIndex, 7, item)
                        self.tbl_referenceInfo.setColumnWidth(7, 70)
                        self.tbl_referenceInfo.item(nIndex, 7).setTextAlignment(QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter)
                        nIndex = nIndex+1

                self.tbl_referenceInfo.setRowCount(nIndex)
                
                for i in range(nb_row):
                    self.ckbox = QCheckBox()
                    self.ckbox.clicked.connect(self.click_items)
                    self.checked_list.append(self.ckbox)

                for i in range(nb_row):              
                    cellWidget = QWidget()
                    layoutCB = QHBoxLayout(cellWidget)
                    layoutCB.addWidget(self.checked_list[i])
                    layoutCB.setAlignment(QtCore.Qt.AlignCenter)            
                    layoutCB.setContentsMargins(0,0,0,0)
                    cellWidget.setLayout(layoutCB)
                    self.tbl_referenceInfo.setCellWidget(i,7,cellWidget)      
                       
            # 1-3. Set Basic Model Tab
            self.Get_BasicModel()
            
            # 1-2 Training Data Graph (basic_model > self.target_point), (basic_model > reference_point - 표에서 선택할때 적용한다)
            self.Draw_Graph_TargetPoint()
        
        # 2. Predict rainfall Model
        predRF_model_name = self.validationFolder[self.PREDRF].format(self.target_point)       
        predRF_model_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, predRF_model_name, 'modelParam.txt')
        if os.path.isfile(predRF_model_path):        
            data = []
            with open(predRF_model_path, 'r') as stream:
                for rowdata in csv.reader(stream):
                    data.append(rowdata)

            predRF_file_model_name = ''
            predRF_file_model_inf_name = ''
            predRF_file_drop_out_rate = ''
            predRF_file_seq_length = ''

            nb_row = len(data)
            for row in range(nb_row):
                col_text = str(data[row][0])
                if col_text == 'model_name': 
                    predRF_file_model_name = str(data[row][1]).strip()
                    predRF_file_model_inf_name = str(data[row][1]).strip()
                elif col_text == 'drop_out_rate':
                    predRF_file_drop_out_rate = str(data[row][1]).strip()    
                elif col_text == 'seq_length':
                    predRF_file_seq_length = str(data[row][1]).strip()
                else:
                    file_data_txt = 0
            
            self.predRf_validation_path = self.predRf_validation_fileNm.format(predRF_file_model_name, predRF_file_drop_out_rate, predRF_file_seq_length)
            self.predRf_inference_path = self.predRf_inference_fileNm.format(predRF_file_model_inf_name).replace('ChangeValue', predRF_file_seq_length)

            # 2-1. Set Predict rainfall Model Tab
            self.Get_PredictRFModel()

        # 3. Scenario Model   
        scenario_model_name = self.validationFolder[self.SCENARIO].format(self.target_point)        
        scenario_model_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, scenario_model_name, 'modelParam.txt')
        if os.path.isfile(scenario_model_path):        
            data = []
            with open(scenario_model_path, 'r') as stream:
                for rowdata in csv.reader(stream):
                    data.append(rowdata)

            scenario_file_model_name = ''
            scenario_file_model_infname = ''
            scenario_file_drop_out_rate = ''
            scenario_file_seq_length = ''

            nb_row = len(data)
            for row in range(nb_row):
                col_text = str(data[row][0])
                if col_text == 'model_name':   
                    scenario_file_model_name = str(data[row][1]).strip()  
                    scenario_file_model_infname = str(data[row][1]).strip()       
                elif col_text == 'drop_out_rate':
                    scenario_file_drop_out_rate = str(data[row][1]).strip()    
                elif col_text == 'seq_length':
                    scenario_file_seq_length = str(data[row][1]).strip()
                else:
                    file_data_txt = 0
                        
            self.sce_validation_path = self.sce_validation_fileNm.format(scenario_file_model_name, scenario_file_drop_out_rate, scenario_file_seq_length)
            self.sce_inference_path = self.sce_inference_fileNm.format(scenario_file_model_infname).replace('ChangeValue', scenario_file_seq_length)

            # 3-1. Set Scenario Model Tab
            self.Get_ScenarioModel()

    # [Trainning Data Graph - Target Point] : draw_target_point_trainning_graph
    def Draw_Graph_TargetPoint(self):
        
        # initialize_graph
        self.target_fig.clf()
        self.target_ax = self.target_fig.add_subplot(111)

        # get_basic_model_dataset_file (basic_model > year > target_point > file 사용. modelparam의 dataset_path는 경로가 달라서 사용하지않음.)     
        path_dataset = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point,'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))        
        if os.path.isfile(path_dataset):
            # read_dataset_file
            row_data = pd.read_csv(path_dataset, encoding='cp949', date_parser=True)
            col_target = 'Target_{}'.format(self.target_point)            
            pd_graph_data = pd.DataFrame(row_data)           
         
            # draw_dataset_graph
            x_temp = list(range(len(pd_graph_data.loc[:,'Date'])))
            y_temp = pd_graph_data.loc[:,col_target]

            self.target_ax.set_title(col_target, size=10)
            self.target_ax.set_xlabel('Time', size=8)
            self.target_ax.set_ylabel('Waterlevel', size=8)

            list_cnt = int(len(pd_graph_data["Date"])/5)
            x_labels_cnt = []
            x_labels_name = []
            for i in range(5):
                x_labels_cnt.append(list_cnt*(i))
                x_labels_name.append(str(x_temp[list_cnt*(i)]))
            
            x_labels_cnt.append(len(x_temp)-1)
            x_labels_name.append(str(x_temp[len(x_temp)-1]))

            self.target_ax.set_xticks(x_labels_cnt)
            self.target_ax.set_xticklabels(x_labels_name, size=6)
            self.target_ax.plot(x_temp, y_temp)        
            
            for tl in self.target_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)
        
        #from PyQt5.QtCore import QTimer
        QTimer.singleShot(100, lambda: self.finalize_plot(self.target_fig, self.target_canvas))

    def finalize_plot(self, fig, canvas):
        fig.tight_layout()
        fig.subplots_adjust(left=0.1, right=0.95, top=0.9, bottom=0.2)
        canvas.draw()
    
    # [Trainning Data Graph - Reference Point] : draw_reference_point_trainning_graph
    def Draw_Graph_ReferencePoint(self, ref_obs_list):
        

        # initialize_graph
        self.ref_fig.clf()
        self.ref_ax = self.ref_fig.add_subplot(111)
        
        # get_reference_point_info
        if (len(ref_obs_list) > 0):
            model_name = self.validationFolder[self.BASIC].format(self.target_point)
            
            # get_basic_model_dataset_file (basic_model > year > target_point > file 사용. modelparam의 dataset_path는 경로가 달라서 사용하지않음.)     
            path_dataset = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point,'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))                    
            if os.path.isfile(path_dataset):
                # get_data_info
                row_data = pd.read_csv(path_dataset, encoding='cp949', date_parser=True)
                col_target = 'Target_{}'.format(self.target_point)
                
                pd_graph_data = pd.DataFrame(row_data)       
                x_temp = list(range(len(pd_graph_data.loc[:,'Date'])))
                list_cnt = int(len(pd_graph_data["Date"])/5)
                x_labels_cnt = []
                x_labels_name = []
                for i in range(5):
                    x_labels_cnt.append(list_cnt*(i))
                    x_labels_name.append(str(x_temp[list_cnt*(i)]))            
                x_labels_cnt.append(len(x_temp)-1)
                x_labels_name.append(str(x_temp[len(x_temp)-1]))

                # draw_reference_graphs
                self.ref_ax.set_xticks(x_labels_cnt)
                self.ref_ax.set_xticklabels(x_labels_name, size=6)     
                for obs_name in ref_obs_list:
                    y_temp = pd_graph_data.loc[:,obs_name]
                    self.ref_ax.plot(x_temp, y_temp, label=obs_name)

                for tl in self.ref_ax.yaxis.get_majorticklabels():
                    tl.set_fontsize(6)

                self.ref_ax.legend(prop={'size': 8})

        else:
            self.ref_fig.subplots_adjust(left=0.1, right=0.95, top=0.9, bottom=0.2)

            x_labels_cnt = []
            x_labels_name = []
            # draw_reference_graphs
            self.ref_ax.set_xticks(x_labels_cnt)
            self.ref_ax.set_xticklabels(x_labels_name, size=6)     
            for tl in self.ref_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)
            self.ref_ax.legend(prop={'size': 8})

        QTimer.singleShot(100, lambda: self.finalize_plot(self.ref_fig, self.ref_canvas))  
        
    # [Trainning Data Graph - Reference Point] : reference_point_table에서 view클릭시 발생하는 event
    def click_items(self, item):
        ref_obs_list = []
        for i in range(len(self.checked_list)):
            if self.checked_list[i].checkState() == QtCore.Qt.Checked:
                obs_type = str(self.tbl_referenceInfo.item(i, 1).text())  
                obs_code = str(self.tbl_referenceInfo.item(i, 2).text()) 
                obs_name = '{}_{}'.format(obs_type, obs_code)     
                ref_obs_list.append(obs_name)
            
        # draw_reference_point_trainning_graph
        self.Draw_Graph_ReferencePoint(ref_obs_list)    

    # [Tab - Predict Ranifall Model] : validation, inference, performance_check 정보 셋팅
    def Get_PredictRFModel(self):
                                
        # 1. validation(nse) info(nse table, nse시간콤보박스선택에 따라 graph표출)   
        self.Draw_PredictRF_Graph_Validation_type()

        # 2. inference(nse) info(nse table, nse시간콤보박스선택에 따라 graph표출)                
        self.Draw_PredictRF_Graph_Inference_type()

        # 3. performance_check (result 파일만들고 graph 표출)
        self.Make_PredictRF_PerformanceCheck() 

    # [Tab - Predict Ranifall Model] : validation_graph_prev_event
    def Draw_PredictRF_Graph_Validation_Prev(self):
        item_cnt = self.cb_predRfValidation.count()
        if (item_cnt>0):
            col_idx = self.cb_predRfValidation.currentIndex()
            if (col_idx == 0): return    
            else: self.cb_predRfValidation.setCurrentIndex(col_idx-1)

    # [Tab - Predict Ranifall Model] : validation_graph_next_event
    def Draw_PredictRF_Graph_Validation_Next(self):
        item_cnt = self.cb_predRfValidation.count()
        if (item_cnt>0):
            col_idx = self.cb_predRfValidation.currentIndex()
            if (col_idx == item_cnt-1): return    
            else: self.cb_predRfValidation.setCurrentIndex(col_idx+1)
    
    # [Tab - Predict Ranifall Model] : validation_graph_type_event (original, realtime)
    def Draw_PredictRF_Graph_Validation_type(self):
        self.Show_PredictRF_Table_Validation()
        self.Draw_PredictRF_Graph_Validation()

    # [Tab - Predict Ranifall Model] : draw_validation_graph
    def Draw_PredictRF_Graph_Validation(self):    
                
        # initialize_graph
        self.predRF_val_fig.clf()
        self.predRF_val_ax = self.predRF_val_fig.add_subplot(111)

        # get_validation_info
        item_cnt = self.cb_predRfValidation.count()
        if (item_cnt <= 0): 
            self.predRF_val_fig.tight_layout()     
            self.predRF_val_canvas.draw()
            return

        # set_validation_info
        col_name = self.cb_predRfValidation.currentText().strip()
        model_name = ''
        if (self.rb_predValidation_origin.isChecked()): #original
            model_name = self.validationFolder[self.PREDRF].format(self.target_point)      
        else:                                           #realtime
            model_name = 'Realtime_{}'.format(self.validationFolder[self.PREDRF].format(self.target_point))

        # get_validation_file      
        validation_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, model_name, self.predRf_validation_path)
        if os.path.isfile(validation_path):        
            valid_data = pd.read_csv(validation_path, encoding='cp949', date_parser=True)
            pd_valid = pd.DataFrame(valid_data)                       
            
            col_true = 'Y_true_{}'.format(col_name)
            col_pred = 'Y_pred_{}'.format(col_name)

            x_temp = list(range(len(pd_valid.loc[:,'Date'])))
            y_temp_true = pd_valid.loc[:,col_true]
            y_temp_pred = pd_valid.loc[:,col_pred]

            list_cnt = int(len(x_temp)/5)
            x_labels_cnt = []
            x_labels_name = []
            for i in range(5):
                x_labels_cnt.append(list_cnt*(i))
                x_labels_name.append(str(x_temp[list_cnt*(i)]))
            
            x_labels_cnt.append(len(x_temp)-1)
            x_labels_name.append(str(x_temp[len(x_temp)-1]))

            # get_nse_info
            nse_value = ''
            if (self.tbl_predValidation.rowCount()>0):
                nse_value = str(self.tbl_predValidation.item(0, self.cb_predRfValidation.currentIndex()).text()).strip()  

            # draw_validation_graph
            self.predRF_val_ax.set_title('Water Level Prediction (NSE={})'.format(nse_value), size=6)
            self.predRF_val_ax.set_xticks(x_labels_cnt)
            self.predRF_val_ax.set_xticklabels(x_labels_name, size=6)            
            self.predRF_val_ax.set_xlabel('Time', size=6)
            self.predRF_val_ax.set_ylabel('Waterlevel', size=6)
            self.predRF_val_ax.plot(x_temp, y_temp_true, label='Observed Waterlevel')
            self.predRF_val_ax.plot(x_temp, y_temp_pred, label='Predicted Waterlevel')
            
            for tl in self.predRF_val_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)
            
            self.predRF_val_ax.legend(loc='upper right', prop={'size': 8})
        
        QTimer.singleShot(100, lambda: self.finalize_plot(self.predRF_val_fig, self.predRF_val_canvas))
    
    # [Tab - Predict Ranifall Model] : set_validation_table
    def Show_PredictRF_Table_Validation(self):
                
        # get_model_name
        model_name = '' 
        if (self.rb_predValidation_origin.isChecked()):
            model_name = self.validationFolder[self.PREDRF].format(self.target_point)      
        else:
            model_name = 'Realtime_{}'.format(self.validationFolder[self.PREDRF].format(self.target_point))
    
        # initialize_control        
        self.cb_predRfValidation.clear()       
        self.tbl_predValidation.clearContents()
        
        # get_validation_data
        nse_name = 'nse_{}.csv'.format(self.target_point)
        nse_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, model_name, nse_name)
        if os.path.isfile(nse_path):        
            nse_data = pd.read_csv(nse_path, encoding='cp949', date_parser=True)
            nse_list = pd.DataFrame(nse_data)  

            validation_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, model_name, self.predRf_validation_path)
            if os.path.isfile(validation_path):        
                valid_data = pd.read_csv(validation_path, encoding='cp949', date_parser=True)
                lst_col = valid_data.filter(regex='min').columns.tolist()
                nse_col = []
                for col in range(0, int(len(lst_col)/3), 1):
                    nse_col.append(str(lst_col[col*3]))

                self.tbl_predValidation.setRowCount(1)
                self.tbl_predValidation.setColumnCount(len(nse_col))
                self.tbl_predValidation.setHorizontalHeaderLabels(nse_col)

                # set_validation_table&combobox
                for i in range(len(nse_col)):

                    nse_val = nse_list.iat[i,0]
                    item_val = round(nse_val, 3)
                    item = QTableWidgetItem(str(item_val))
                    item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                    self.tbl_predValidation.setItem(0, i, item)
                    self.cb_predRfValidation.addItem(nse_col[i])
                
                self.cb_predRfValidation.setCurrentIndex(0)
                self.tbl_predValidation.resizeColumnsToContents()

    # [Tab - Predict Ranifall Model] : inference_graph_prev_event
    def Draw_PredictRF_Graph_Inference_Prev(self):
        item_cnt = self.cb_predRfInference.count()
        if (item_cnt>0):
            col_idx = self.cb_predRfInference.currentIndex()
            if (col_idx == 0): return    
            else: self.cb_predRfInference.setCurrentIndex(col_idx-1)

    # [Tab - Predict Ranifall Model] : inference_graph_next_event
    def Draw_PredictRF_Graph_Inference_Next(self):
        item_cnt = self.cb_predRfInference.count()
        if (item_cnt>0):
            col_idx = self.cb_predRfInference.currentIndex()
            if (col_idx == item_cnt-1): return    
            else: self.cb_predRfInference.setCurrentIndex(col_idx+1)
    
    # [Tab - Predict Ranifall Model] : inference_graph_type_event (original, realtime)
    def Draw_PredictRF_Graph_Inference_type(self):
        self.Show_PredictRF_Table_Inference()
        self.Draw_PredictRF_Graph_Inference()

    # [Tab - Predict Ranifall Model] : draw_inference_graph
    def Draw_PredictRF_Graph_Inference(self):
                                     
        # initialize_control
        self.predRF_inf_fig.clf()
        self.predRF_inf_ax = self.predRF_inf_fig.add_subplot(111)

        if (self.cb_predRfInference.count() <= 0): 
            self.predRF_inf_fig.tight_layout()                
            self.predRF_inf_canvas.draw()   
            return
            
        col_name = self.cb_predRfInference.currentText().strip()

        # get_inference_model_name
        inference_name = ''  #original
        if (self.rb_predInference_origin.isChecked()):
            inference_name = self.inferenceFolder[self.PREDRF].format(self.target_point)   
        else:               #realtime
            inference_name = 'inference_Realtime_{}'.format(self.validationFolder[self.PREDRF].format(self.target_point))         

        # get_inference_file
        inference_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, inference_name, self.predRf_inference_path)        
        if os.path.isfile(inference_path):        
            valid_data = pd.read_csv(inference_path, encoding='cp949', date_parser=True)
            pd_valid = pd.DataFrame(valid_data)           
                    
            col_true = 'Y_true_{}'.format(col_name)
            col_pred = 'Y_pred_{}'.format(col_name)
            
            x_temp = list(range(len(pd_valid.loc[:,'Date'])))
            y_temp_true = pd_valid.loc[:,col_true]
            y_temp_pred = pd_valid.loc[:,col_pred]

            list_cnt = int(len(x_temp)/5)
            x_labels_cnt = []
            x_labels_name = []
            for i in range(5):
                x_labels_cnt.append(list_cnt*(i))
                x_labels_name.append(str(x_temp[list_cnt*(i)]))
            
            x_labels_cnt.append(len(x_temp)-1)
            x_labels_name.append(str(x_temp[len(x_temp)-1]))

            # get_nse_info
            nse_value = ''
            if (self.tbl_predInference.rowCount()>0):
                nse_value = str(self.tbl_predInference.item(0, self.cb_predRfInference.currentIndex()).text()).strip()  

            # draw_validation_graph
            self.predRF_inf_ax.set_title('Water Level Prediction (NSE={})'.format(nse_value), size=6)
            self.predRF_inf_ax.set_xticks(x_labels_cnt)
            self.predRF_inf_ax.set_xticklabels(x_labels_name, size=6)
            self.predRF_inf_ax.set_xlabel('Time', size=6)
            self.predRF_inf_ax.set_ylabel('Waterlevel', size=6)
            self.predRF_inf_ax.plot(x_temp, y_temp_true, label='Observed Waterlevel')
            self.predRF_inf_ax.plot(x_temp, y_temp_pred, label='Predicted Waterlevel')

            for tl in self.predRF_inf_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)
            
            self.predRF_inf_ax.legend(loc='upper right', prop={'size': 8})
                
        QTimer.singleShot(100, lambda: self.finalize_plot(self.predRF_inf_fig, self.predRF_inf_canvas))

    # [Tab - Predict Ranifall Model] : draw_inference_table
    def Show_PredictRF_Table_Inference(self):
                
        # get_inference_file_name
        inference_name = ''
        if (self.rb_predInference_origin.isChecked()):
            inference_name = self.inferenceFolder[self.PREDRF].format(self.target_point)   
        else:
            inference_name = 'inference_Realtime_{}'.format(self.validationFolder[self.PREDRF].format(self.target_point))       

        # initialize_control
        self.cb_predRfInference.clear()        
        self.tbl_predInference.clearContents()
        nse_name = 'nse_{}.csv'.format(self.target_point)
        nse_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, inference_name, nse_name)
        if os.path.isfile(nse_path):        
            nse_data = pd.read_csv(nse_path, encoding='cp949', date_parser=True)
            nse_list = pd.DataFrame(nse_data)  

            # validation - data
            inference_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, inference_name, self.predRf_inference_path)
            if os.path.isfile(inference_path):        
                valid_data = pd.read_csv(inference_path, encoding='cp949', date_parser=True)

                lst_col = valid_data.filter(regex='min').columns.tolist()
                nse_col = []
                for col in range(0, int(len(lst_col)/3), 1):
                    nse_col.append(str(lst_col[col*3]))

                self.tbl_predInference.setRowCount(1)
                self.tbl_predInference.setColumnCount(len(nse_col))
                self.tbl_predInference.setHorizontalHeaderLabels(nse_col)

                for i in range(len(nse_col)):
                    nse_val = nse_list.iat[i,0]
                    item_val = round(nse_val, 3)
                    item = QTableWidgetItem(str(item_val))
                    item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                    self.tbl_predInference.setItem(0, i, item)                    
                    self.cb_predRfInference.addItem(nse_col[i])
                
                self.cb_predRfInference.setCurrentIndex(0)
                self.tbl_predInference.resizeColumnsToContents()

    # [Tab - Predict Ranifall Model] : make_report_resultfile_performance_check
    def Make_PredictRF_PerformanceCheck(self):
                
        global data_dataset
        
        self.cb_predRf_pc_time.clear()

        # target_point_alarm_info
        target_waterlevel = pd.read_csv(os.path.join(self.obs_root_path, 'target_waterlevel.csv'), date_parser = True)
        target_value = target_waterlevel[target_waterlevel['target_point']==int(self.target_point)]        
        target_name = ''
        Watch_level = 0
        Warning_level = 0
        if not target_value.empty:
            target_name = target_value['target_name'].values[0]
            Watch_level = target_value['watch_level'].values[0]
            Warning_level = target_value['warning_level'].values[0]

        # set_inference_foldername
        inference_name = self.inferenceFolder[self.PREDRF].format(self.target_point)   
                
        # 2022_to_2023_inference_file
        year_inf = '2023'
        if (self.cb_year.count() >= self.cb_year.currentIndex()+1):
            year_inf = self.cb_year.itemText(self.cb_year.currentIndex()+1)

        inference_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], self.year, self.riverRegion, self.target_point, inference_name, self.predRf_inference_path)
        
        # 2023_model_dataset
        file_path = os.path.join(self.model_root_path , self.modelFolder[self.PREDRF], year_inf, self.riverRegion, self.target_point)
        dataset_filepath = os.path.join(file_path, 'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))

        if (os.path.isfile(inference_path) and os.path.isfile(dataset_filepath)):      
            dataset = pd.read_csv(dataset_filepath, parse_dates=['Date'])
            
            modified_dataset = dataset[dataset['Date'].dt.year == 2023].drop_duplicates(subset='Date')
            modified_dataset = pd.concat([modified_dataset.iloc[:, 0], modified_dataset[modified_dataset.columns[modified_dataset.columns.str.startswith('WS_')].tolist()]], axis=1)

            load_result = pd.read_csv(inference_path, parse_dates=['Date'])
            
            merged_result = pd.merge(modified_dataset,load_result, on="Date")
                            
            WS_columns = [col for col in merged_result.columns if col.startswith('WS_')]
                            
            WS_data = merged_result[merged_result.columns[merged_result.columns.str.startswith('WS_')].tolist()[len(WS_columns)-1]]
            
            merged_result = merged_result.drop(columns=WS_columns)
            merged_result['Rainfall'] = WS_data
                            
            # make_report_result_file
            result_file_name = 'Results_'+ str(self.target_point) +'.csv'
            if not os.path.exists(os.path.join(self.model_root_path ,'report', self.modelFolder[self.PREDRF], str(self.target_point))):
                os.makedirs(os.path.join(self.model_root_path ,'report', self.modelFolder[self.PREDRF], str(self.target_point)))
            merged_result.to_csv(os.path.join(self.model_root_path ,'report', self.modelFolder[self.PREDRF], str(self.target_point), result_file_name), index=False)

            # make_report_performance_check_graph_img
            save_path = os.path.join(self.model_root_path ,'report', self.modelFolder[self.PREDRF], str(self.target_point), 'images_all')
            
            # Unless save_path folder exist, make the save_path folder
            if not os.path.exists(save_path):
                os.makedirs(save_path)
                
            # get_result_file
            results_data = pd.read_csv(os.path.join(self.model_root_path ,'report', self.modelFolder[self.PREDRF], str(self.target_point), result_file_name), parse_dates=['Date'])
            Obs_data = results_data.iloc[:,[0,1]]
            Obs_data.columns = ['Date','Obs']
            
            # make predict data
            predict_header = list(range(10,370,10))
        
            for j in range(len(predict_header)):                 
                txt_dateCol = '{}min'.format(predict_header[j])         
                txt_predCol = 'Y_pred_{}min'.format(predict_header[j])        
                globals()['Pred_{}'.format(str(predict_header[j]))] = results_data.loc[:,[txt_dateCol, txt_predCol]]
                globals()['Pred_{}'.format(str(predict_header[j]))].columns = ['Date', 'Pred_{}'.format(str(predict_header[j]))]            
            
            Rainfall = results_data.loc[:,['Date','Rainfall']]
            Rainfall.columns = ['Date','Rainfall']
    
            for k in range(len(predict_header)):
                if k==0 :
                    Obs_data['Date'] = pd.to_datetime(Obs_data['Date'])
                    eval('Pred_{}'.format(str(predict_header[k])))['Date'] = pd.to_datetime(eval('Pred_{}'.format(str(predict_header[k])))['Date'])

                    Graph_dataset = pd.merge(Obs_data, eval('Pred_{}'.format(str(predict_header[k]))), on='Date')
                else :
                    # 데이터 준비
                    Pred_df = eval('Pred_{}'.format(str(predict_header[k])))
                    # 날짜 타입 맞추기
                    Graph_dataset['Date'] = pd.to_datetime(Graph_dataset['Date'], errors='coerce')
                    Pred_df['Date'] = pd.to_datetime(Pred_df['Date'], errors='coerce')

                    Graph_dataset = pd.merge(Graph_dataset,eval('Pred_{}'.format(str(predict_header[k]))), on="Date")
                    
            Graph_dataset = pd.merge(Graph_dataset, Rainfall, on="Date")
        
            # peak index_graph_setting
            peak_index = Graph_dataset.Obs.index[Graph_dataset['Obs'] == max(Graph_dataset.Obs)].to_list()               

            end_tmp = Graph_dataset.Date[peak_index[0]]
            end_time = pd.to_datetime(end_tmp)
            
            std_tmp = Graph_dataset.Date[peak_index[0]-36]
            std_time = pd.to_datetime(std_tmp)
            
            self.dt_predRf_pc_startTime.setDate(QtCore.QDate(std_time.year, std_time.month, std_time.day))           
            self.dt_predRf_pc_startTime.setTime(QtCore.QTime(std_time.hour, std_time.minute, 0))     
            self.dt_predRf_pc_endTime.setDate(QtCore.QDate(end_time.year, end_time.month, end_time.day))        
            self.dt_predRf_pc_endTime.setTime(QtCore.QTime(end_time.hour, end_time.minute, 0))       

            # combobox
            interval_time = 0
            if (self.rb_predRf_pd_interval1.isChecked()):    #30분간격
                interval_time = 30
            elif (self.rb_predRf_pd_interval2.isChecked()):  #1시간간격
                interval_time = 60
            elif (self.rb_predRf_pd_interval3.isChecked()):  #2시간간격
                interval_time = 120
            else:
                interval_time = 0
            
            # set_performance_check_time_combobox
            diff_date = end_time - std_time
            loof_cnt = int((diff_date.seconds/60) / interval_time)
            now_date = std_time

            while(now_date<=end_time):                    
                self.cb_predRf_pc_time.addItem(str(now_date)[:-3])
                now_date = now_date + timedelta(minutes=interval_time) 

            if (self.cb_predRf_pc_time.count()>0):
                self.cb_predRf_pc_time.setCurrentIndex(self.cb_predRf_pc_time.count()-1)
        
            tick_interval = 18
            all_interval = int(math.ceil(len(Graph_dataset)/6/10)*10)            
            start = peak_index[0]-36
            
            # make img
            for m in range(start,peak_index[0]+1,3):
                nowtime = m

                # make prediction Dataframe
                predict_data = pd.DataFrame()
                for q in range(len(predict_header)):
                    temp_predict_data = Graph_dataset.iloc[nowtime+q+1:nowtime+q+2,[q+2]]
                    temp_predict_data.columns = ['predict_data']
                    predict_data = pd.concat([predict_data,temp_predict_data],axis=0)                   
                
                # make imagefile (for report)
                fig= plt.figure(figsize=(14,7))
                gs = gridspec.GridSpec(nrows=3, # row 몇 개 
                                ncols=1, # col 몇 개 
                                height_ratios=[1,4,2])
                ax0 = plt.subplot(gs[0])
                ax0.bar(list(range(nowtime-54,nowtime+1)), Graph_dataset['Rainfall'][nowtime-54:nowtime+1], color = 'cyan', label = 'Observed Water Level')
                ax0.bar(list(range(nowtime+1,nowtime+55)), Graph_dataset['Rainfall'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
                ax0.set_title(self.target_point + '\n' + 'Current time : ' + Graph_dataset['Date'][nowtime].strftime('%Y-%m-%d %H:%M'))

                ax0.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[])
                ax0.set_ylabel('Rainfall(mm)')
                ax0.set_ylim([math.floor(min(Graph_dataset['Rainfall'][:])),math.ceil(max(Graph_dataset['Rainfall'][:]))])
                
                ax1 = plt.subplot(gs[1]) 
                ax1.plot([nowtime-54,nowtime+54],[Watch_level,Watch_level], color = 'yellow', label = 'Flood watch')
                ax1.text(nowtime-44, Watch_level + 0.1, 'Flood watch', ha='center', va='bottom', size = 12)
                ax1.plot([nowtime-54,nowtime+54],[Warning_level,Warning_level], color = 'red', label = 'Flood warning')
                ax1.text(nowtime-44, Warning_level + 0.1, 'Flood warning', ha='center', va='bottom', size = 12)
                ax1.plot(Graph_dataset['Obs'][nowtime-54:nowtime+1], color = 'black', label = 'Observed Water Level')
                ax1.plot(Graph_dataset['Obs'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
                ax1.plot(Graph_dataset['Obs'][nowtime:nowtime+1], color = 'blue', label = 'Observed Water Level', marker= 'o')
                ax1.plot(predict_data, color = 'salmon', label = 'Predicted  Water Level', marker= 'o' )                    
                ax1.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[Graph_dataset['Date'][nowtime-54].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*1].strftime('%m-%d %H:%M'),\
                                                                    Graph_dataset['Date'][nowtime-54+tick_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*3].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][nowtime-54+tick_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][nowtime-54+tick_interval*5].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][nowtime-54+tick_interval*6].strftime('%m-%d %H:%M')] )
                ax1.set_xlabel('Time')
                ax1.set_ylabel('Water Level')
                ax1.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),max(math.ceil(max(Graph_dataset['Obs'][:])),Warning_level+1)])
                
                ax2 = plt.subplot(gs[2]) 
                ax2.plot(Graph_dataset['Obs'][:nowtime+1], color = 'blue', label = 'Observed Water Level')
                ax2.plot(Graph_dataset['Obs'][nowtime+1:], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
                ax2.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),math.ceil(max(Graph_dataset['Obs'][:]))])
                ax2.set_xticks(range(0,all_interval*6+1,all_interval),[Graph_dataset['Date'][0].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*1].strftime('%m-%d %H:%M'),\
                                                                    Graph_dataset['Date'][all_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*3].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][all_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][all_interval*5].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][len(Graph_dataset)-1].strftime('%m-%d %H:%M')])
                ax2.set_ylabel('Water Level')                    
                
                date_str = Graph_dataset['Date'][nowtime].strftime('%Y%m%d%H%M%S')  # 문자열 변환 + 원하는 포맷
                safe_date_str = re.sub(r"[^a-zA-Z0-9]", "", date_str)
                plt.savefig(save_path + r'\Prediction_graph_' + f"{0:05d}" + '(' + safe_date_str + ').png')
                    
    # [Tab - Predict Ranifall Model] : draw_performance_check_graph
    def Draw_PredictRF_Graph_PerformanceCheck(self):        
                                        
        if (self.cb_predRf_pc_time.currentText()==''): 
            self.predRF_pc_fig.clf()
            self.predRF_pc_ax = self.predRF_pc_fig.add_subplot(111)
            self.predRF_pc_canvas.draw()
            return
                
        # initialize_control    
        self.predRF_pc_fig.clf()
        
        # get_targetpoint_info
        target_waterlevel = pd.read_csv(os.path.join(self.obs_root_path, 'target_waterlevel.csv'), date_parser = True)
        target_value = target_waterlevel[target_waterlevel['target_point']==int(self.target_point)]
        target_name = ''
        Watch_level = 0
        Warning_level = 0
        if not target_value.empty:
            target_name = target_value['target_name'].values[0]   
            Watch_level = target_value['watch_level'].values[0]
            Warning_level = target_value['warning_level'].values[0]

        # get_result_file   
        result_file_name = 'Results_'+ str(self.target_point) +'.csv'
        report_path = os.path.join(self.model_root_path ,'report', self.modelFolder[self.PREDRF], str(self.target_point), result_file_name)
        if os.path.exists(report_path):
            
            results_data = pd.read_csv(report_path, parse_dates=['Date'])

            Obs_data = results_data.iloc[:,[0,1]]
            Obs_data.columns = ['Date','Obs']
            
            # make predict data
            predict_header = list(range(10,370,10))
        
            for j in range(len(predict_header)):
                txt_dateCol = '{}min'.format(predict_header[j])         
                txt_predCol = 'Y_pred_{}min'.format(predict_header[j])                                 
                globals()['Pred_{}'.format(str(predict_header[j]))] = results_data.loc[:,[txt_dateCol,txt_predCol]]
                globals()['Pred_{}'.format(str(predict_header[j]))].columns = ['Date', 'Pred_{}'.format(str(predict_header[j]))]            
            
            Rainfall = results_data.loc[:,['Date','Rainfall']]
            Rainfall.columns = ['Date','Rainfall']
        
            for k in range(len(predict_header)):
                if k==0 :
                    Obs_data['Date'] = pd.to_datetime(Obs_data['Date'])
                    eval('Pred_{}'.format(str(predict_header[k])))['Date'] = pd.to_datetime(eval('Pred_{}'.format(str(predict_header[k])))['Date'])

                    Graph_dataset = pd.merge(Obs_data, eval('Pred_{}'.format(str(predict_header[k]))), on='Date')
                else :
                    # 데이터 준비
                    Pred_df = eval('Pred_{}'.format(str(predict_header[k])))

                    # 날짜 타입 맞추기
                    Graph_dataset['Date'] = pd.to_datetime(Graph_dataset['Date'], errors='coerce')
                    Pred_df['Date'] = pd.to_datetime(Pred_df['Date'], errors='coerce')
                    
                    Graph_dataset = pd.merge(Graph_dataset,eval('Pred_{}'.format(str(predict_header[k]))), on="Date")
                    
            Graph_dataset = pd.merge(Graph_dataset, Rainfall, on="Date")
        
            # set_combobox - peaktime(end_time)
            end_tmp = '{}:00'.format(str(self.cb_predRf_pc_time.currentText()))            
            end_time = pd.to_datetime(end_tmp)

            # peak index
            peak_index = Graph_dataset.Date.index[Graph_dataset['Date'] == end_tmp].to_list()

            tick_interval = 18
            all_interval = int(math.ceil(len(Graph_dataset)/6/10)*10)   
            nowtime = peak_index[0]
            
            # make prediction Dataframe
            predict_data = pd.DataFrame()
            for q in range(len(predict_header)):
                temp_predict_data = Graph_dataset.iloc[nowtime+q+1:nowtime+q+2,[q+2]]
                temp_predict_data.columns = ['predict_data']
                predict_data = pd.concat([predict_data,temp_predict_data],axis=0)
            
            # draw performance_check graph
            gs = gridspec.GridSpec(nrows=3, 
                            ncols=1, 
                            height_ratios=[1,4,2])
                       
            # draw - rainfall graph
            self.predRF_pc_ax = self.predRF_pc_fig.add_subplot(gs[0])
            self.predRF_pc_ax.bar(list(range(nowtime-54,nowtime+1)), Graph_dataset['Rainfall'][nowtime-54:nowtime+1], color = 'cyan', label = 'Observed Water Level')
            self.predRF_pc_ax.bar(list(range(nowtime+1,nowtime+55)), Graph_dataset['Rainfall'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
            
            self.predRF_pc_ax.set_title('Current time : ' + Graph_dataset['Date'][peak_index[0]].strftime('%Y-%m-%d %H:%M'), size=6)
            self.predRF_pc_ax.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[])
            self.predRF_pc_ax.set_ylabel('Rainfall(mm)', size = 6)
            self.predRF_pc_ax.set_ylim([math.floor(min(Graph_dataset['Rainfall'][:])),math.ceil(max(Graph_dataset['Rainfall'][:]))])            
            for tl in self.predRF_pc_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)
            
            # draw - predict
            self.predRF_pc_ax = self.predRF_pc_fig.add_subplot(gs[1])
            self.predRF_pc_ax.plot([nowtime-54,nowtime+54],[Watch_level,Watch_level], color = 'yellow', label = 'Flood watch', linewidth=0.8)
            self.predRF_pc_ax.text(nowtime-44, Watch_level + 0.1, 'Flood watch', ha='center', va='bottom', size = 6)
            self.predRF_pc_ax.plot([nowtime-54,nowtime+54],[Warning_level,Warning_level], color = 'red', label = 'Flood warning', linewidth=0.8)
            self.predRF_pc_ax.text(nowtime-44, Warning_level + 0.1, 'Flood warning', ha='center', va='bottom', size = 6)
            self.predRF_pc_ax.plot(Graph_dataset['Obs'][nowtime-54:nowtime+1], color = 'black', label = 'Observed Water Level', linewidth=0.8)
            self.predRF_pc_ax.plot(Graph_dataset['Obs'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--", linewidth=0.8)
            self.predRF_pc_ax.plot(Graph_dataset['Obs'][nowtime:nowtime+1], color = 'blue', label = 'Observed Water Level', marker= 'o', markersize=1)
            self.predRF_pc_ax.plot(predict_data, color = 'salmon', label = 'Predicted  Water Level', marker= 'o', markersize=1)            
            self.predRF_pc_ax.set_xticks(range(nowtime-54,nowtime+55,tick_interval))
            self.predRF_pc_ax.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[Graph_dataset['Date'][nowtime-54].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*1].strftime('%m-%d %H:%M'),\
                                                Graph_dataset['Date'][nowtime-54+tick_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*3].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][nowtime-54+tick_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][nowtime-54+tick_interval*5].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][nowtime-54+tick_interval*6].strftime('%m-%d %H:%M')] )
            self.predRF_pc_ax.set_xticklabels([Graph_dataset['Date'][nowtime-54].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*1].strftime('%m-%d %H:%M'),\
                                                Graph_dataset['Date'][nowtime-54+tick_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*3].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][nowtime-54+tick_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][nowtime-54+tick_interval*5].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][nowtime-54+tick_interval*6].strftime('%m-%d %H:%M')] , fontsize=5)
            self.predRF_pc_ax.set_ylabel('Water Level', size = 6)
            self.predRF_pc_ax.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),max(math.ceil(max(Graph_dataset['Obs'][:])),Warning_level+1)])            
            for tl in self.predRF_pc_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)                      
            
            # draw - waterlevel
            self.predRF_pc_ax = self.predRF_pc_fig.add_subplot(gs[2])
            self.predRF_pc_ax.plot(Graph_dataset['Obs'][:nowtime+1], color = 'blue', label = 'Observed Water Level', linewidth=0.8)
            self.predRF_pc_ax.plot(Graph_dataset['Obs'][nowtime+1:], color = 'lightgray', label = 'Observed Water Level', linestyle="--", linewidth=0.8)
            self.predRF_pc_ax.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),math.ceil(max(Graph_dataset['Obs'][:]))])
            self.predRF_pc_ax.set_xticks(range(0,all_interval*6+1,all_interval),[Graph_dataset['Date'][0].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*1].strftime('%m-%d %H:%M'),\
                                                Graph_dataset['Date'][all_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*3].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][all_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][all_interval*5].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][len(Graph_dataset)-1].strftime('%m-%d %H:%M')])
            self.predRF_pc_ax.set_xticklabels([Graph_dataset['Date'][0].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*1].strftime('%m-%d %H:%M'),\
                                                Graph_dataset['Date'][all_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*3].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][all_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][all_interval*5].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][len(Graph_dataset)-1].strftime('%m-%d %H:%M')], fontsize=5)
            self.predRF_pc_ax.set_ylabel('Water Level', size = 6)            
            for tl in self.predRF_pc_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)                                   
                 
        QTimer.singleShot(100, lambda: self.finalize_plot(self.predRF_pc_fig, self.predRF_pc_canvas)) 

    # [Tab - Predict Ranifall Model] : set_performance_check_combobox_event (search, change interval)
    def Set_PredictRF_Combobox_PerformanceCheck_Time(self):        
                        
        global data_dataset
                         
        # initialize_control        
        self.cb_predRf_pc_time.clear()

        # get_result_file (rf_perfofrmance_check)
        result_file_name = 'Results_'+ str(self.target_point) +'.csv'
        report_path = os.path.join(self.model_root_path , 'report', self.modelFolder[self.PREDRF], str(self.target_point), result_file_name)
        if os.path.exists(report_path):            
            results_data = pd.read_csv(report_path, parse_dates=['Date'])

            Obs_data = results_data.iloc[:,[0,1]]
            Obs_data.columns = ['Date','Obs']
            
            # make predict data
            predict_header = list(range(10,370,10))
        
            for j in range(len(predict_header)):
                txt_dateCol = '{}min'.format(predict_header[j])         
                txt_predCol = 'Y_pred_{}min'.format(predict_header[j])                                      
                globals()['Pred_{}'.format(str(predict_header[j]))] = results_data.loc[:,[txt_dateCol,txt_predCol]]
                globals()['Pred_{}'.format(str(predict_header[j]))].columns = ['Date', 'Pred_{}'.format(str(predict_header[j]))]
                        
            Rainfall = results_data.loc[:,['Date','Rainfall']]
            Rainfall.columns = ['Date','Rainfall']
        
            for k in range(len(predict_header)):
                if k==0 :
                    Obs_data['Date'] = pd.to_datetime(Obs_data['Date'])
                    eval('Pred_{}'.format(str(predict_header[k])))['Date'] = pd.to_datetime(eval('Pred_{}'.format(str(predict_header[k])))['Date'])

                    Graph_dataset = pd.merge(Obs_data, eval('Pred_{}'.format(str(predict_header[k]))), on='Date')
                else :
                    # 데이터 준비
                    Pred_df = eval('Pred_{}'.format(str(predict_header[k])))

                    # 날짜 타입 맞추기
                    Graph_dataset['Date'] = pd.to_datetime(Graph_dataset['Date'], errors='coerce')
                    Pred_df['Date'] = pd.to_datetime(Pred_df['Date'], errors='coerce')
                    
                    Graph_dataset = pd.merge(Graph_dataset,eval('Pred_{}'.format(str(predict_header[k]))), on="Date")               
            
            Graph_dataset = pd.merge(Graph_dataset, Rainfall, on="Date")

            end_tmp = '{}:00'.format(str(self.dt_predRf_pc_endTime.text()))
            end_time = pd.to_datetime(end_tmp)
            std_tmp = '{}:00'.format(str(self.dt_predRf_pc_startTime.text()))
            std_time = pd.to_datetime(std_tmp)

            # check_interval
            if (std_time <= end_time):   
                interval_time = 0
                if (self.rb_predRf_pd_interval1.isChecked()):    #30분간격
                    interval_time = 30
                elif (self.rb_predRf_pd_interval2.isChecked()):  #1시간간격
                    interval_time = 60
                elif (self.rb_predRf_pd_interval3.isChecked()):  #2시간간격
                    interval_time = 120
                else:
                    interval_time = 0
                
                loof_start = std_time
                loof_out = 0

                diff_date = end_time - std_time
                loof_cnt = int((diff_date.seconds/60) / interval_time)
                now_date = std_time
                
                # set_performance_check_time_combobox
                while(now_date<=end_time):                    
                    wl_info = Graph_dataset[Graph_dataset['Date'] == str(now_date)]
                    if not wl_info.empty:
                        self.cb_predRf_pc_time.addItem(str(now_date)[:-3])
                    now_date = now_date + timedelta(minutes=interval_time) 

                if (self.cb_predRf_pc_time.count()>0):
                    self.cb_predRf_pc_time.setCurrentIndex(self.cb_predRf_pc_time.count()-1)

    # [Tab - Predict Ranifall Model] : set_performance_check_prev_event
    def Draw_PredictRF_Graph_PerformanceCheck_Prev(self):
        item_cnt = self.cb_predRf_pc_time.count()
        if (item_cnt>0):
            col_idx = self.cb_predRf_pc_time.currentIndex()
            if (col_idx == 0): return    
            else:
                self.cb_predRf_pc_time.setCurrentIndex(col_idx-1)

    # [Tab - Predict Ranifall Model] : set_performance_check_next_event
    def Draw_PredictRF_Graph_PerformanceCheck_Next(self):
        item_cnt = self.cb_predRf_pc_time.count()
        if (item_cnt>0):
            col_idx = self.cb_predRf_pc_time.currentIndex()
            if (col_idx == item_cnt-1): return    
            else:
                self.cb_predRf_pc_time.setCurrentIndex(col_idx+1)

    # [Tab - Predict Ranifall Model] : save_validation_graph
    def Save_PredictRF_ImgValidation_SavePath(self):        

        timeText = self.cb_predRfValidation.currentText()
        saveFile = ''
        if (self.rb_predValidation_origin.isChecked()):
            saveFile = '{0}_{1}_{2}_{3}_validation_{4}.png'.format('Predict_RF', self.year, self.riverRegion, self.target_point, timeText)     
        else:
            saveFile = '{0}_{1}_{2}_{3}_realtime_validation_{4}.png'.format('Predict_RF', self.year, self.riverRegion, self.target_point, timeText)

        file_path, _ = QFileDialog.getSaveFileName(
            self, 
            "[Dashboard] Save PredictRF Validation Image", 
            saveFile,
            "PNG(*.png);;JPEG(*.jpg);;All(*.*)"
        )

        if file_path:
            # save_img
            self.predRF_val_fig.savefig(file_path, dpi=500)     
    
    # [Tab - Predict Ranifall Model] : save_inference_graph
    def Save_PredictRF_ImgInference_SavePath(self):        

        timeText = self.cb_predRfInference.currentText()
        saveFile = '{0}_{1}_{2}_{3}_inference_{4}.png'.format('Predict_RF', self.year, self.riverRegion, self.target_point, timeText)
        
        saveFile = ''
        if (self.rb_predInference_origin.isChecked()):
            saveFile = '{0}_{1}_{2}_{3}_inference_{4}.png'.format('Predict_RF', self.year, self.riverRegion, self.target_point, timeText)
        else:
            saveFile = '{0}_{1}_{2}_{3}_realtime_inference_{4}.png'.format('Predict_RF', self.year, self.riverRegion, self.target_point, timeText)

        file_path, _ = QFileDialog.getSaveFileName(
            self, 
            "[Dashboard] Save PredictRF Inference Image", 
            saveFile,
            "PNG(*.png);;JPEG(*.jpg);;All(*.*)"
        )

        if file_path:
            # save_img
            self.predRF_inf_fig.savefig(file_path, dpi=500)     
    
    # [Tab - Predict Ranifall Model] : save_performancecheck_graph
    def Save_PredictRF_ImgPerformanceCheck_SavePath(self):     

        timeText = self.cb_predRf_pc_time.currentText()
        timeText = timeText.translate(str.maketrans('', '', '- :'))
        saveFile = '{0}_{1}_{2}_{3}_performanceCheck_{4}.png'.format('Predict_RF', self.year, self.riverRegion, self.target_point, timeText)

        file_path, _ = QFileDialog.getSaveFileName(
            self, 
            "[Dashboard] Save PredictRF PerformanceCheck Image", 
            saveFile,
            "PNG(*.png);;JPEG(*.jpg);;All(*.*)"
        )

        if file_path:
            # save_img
            self.predRF_pc_fig.savefig(file_path, dpi=500)    

    # [Tab - Basic Model] : validation, inference, performance_check 정보 셋팅
    def Get_BasicModel(self):
                
        # get_model_name
        model_name = self.validationFolder[self.BASIC].format(self.target_point)

        # 1. validation(nse) info(nse table, nse시간콤보박스선택에 따라 graph표출)  
        self.cb_basicValidation.clear()
        self.tbl_basicValidation.clearContents()
       
        nse_name = 'nse_{}.csv'.format(self.target_point)
        nse_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, model_name, nse_name)        
        validation_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, model_name, self.basic_validation_path)   
        param_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, model_name, 'modelParam.txt')     

        if (os.path.isfile(nse_path) and os.path.isfile(validation_path)):        
            valid_data = pd.read_csv(validation_path, encoding='cp949', date_parser=True)
            nse_data = pd.read_csv(nse_path, encoding='cp949', date_parser=True)
            nse_list = pd.DataFrame(nse_data)  
            
            lst_col = valid_data.filter(regex='min').columns.tolist()
            nse_col = []
            for col in range(0, int(len(lst_col)/3), 1):
                nse_col.append(str(lst_col[col*3]))

            self.tbl_basicValidation.setRowCount(1)
            self.tbl_basicValidation.setColumnCount(len(nse_col))
            self.tbl_basicValidation.setHorizontalHeaderLabels(nse_col)                
            for i in range(len(nse_col)):
                nse_val = nse_list.iat[i,0]
                item_val = round(nse_val, 3)
                item = QTableWidgetItem(str(item_val))
                item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                self.tbl_basicValidation.setItem(0, i, item)                
                self.cb_basicValidation.addItem(nse_col[i])

            self.tbl_basicValidation.resizeColumnsToContents()            
            self.cb_basicValidation.setCurrentIndex(0)

        # 2. inference(nse) info(nse table, nse시간콤보박스선택에 따라 graph표출)    
        self.cb_basicInference.clear()        
        self.tbl_basicInference.clearContents()

        inference_name = self.inferenceFolder[self.BASIC].format(self.target_point)   
        nse_name = 'nse_{}.csv'.format(self.target_point)
        nse_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, inference_name, nse_name)  
        inference_path = os.path.join(self.model_root_path , self.model, self.year, self.riverRegion, self.target_point, inference_name, self.basic_inference_path)
       
        if (os.path.isfile(nse_path) and os.path.isfile(inference_path)):
            nse_data = pd.read_csv(nse_path, encoding='cp949', date_parser=True)
            nse_list = pd.DataFrame(nse_data)       
            valid_data = pd.read_csv(inference_path, encoding='cp949', date_parser=True)

            lst_col = valid_data.filter(regex='min').columns.tolist()
            nse_col = []
            for col in range(0, int(len(lst_col)/3), 1):
                nse_col.append(str(lst_col[col*3]))

            self.tbl_basicInference.setRowCount(1)
            self.tbl_basicInference.setColumnCount(len(nse_col))
            self.tbl_basicInference.setHorizontalHeaderLabels(nse_col)
            for i in range(len(nse_col)):
                nse_val = nse_list.iat[i,0]
                item_val = round(nse_val, 3)
                item = QTableWidgetItem(str(item_val))
                item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                self.tbl_basicInference.setItem(0, i, item)                
                self.cb_basicInference.addItem(nse_col[i])

            self.tbl_basicInference.resizeColumnsToContents()
            self.cb_basicInference.setCurrentIndex(0)
                
        # 3. performance_check (result 파일만들고 graph 표출)
        self.Make_Basic_PerformanceCheck() 
    
    # [Tab - Basic Model] : validation_graph_prev_event
    def Draw_Basic_Graph_Validation_Prev(self):
        item_cnt = self.cb_basicValidation.count()
        if (item_cnt>0):
            col_idx = self.cb_basicValidation.currentIndex()
            if (col_idx == 0): return    
            else:
                self.cb_basicValidation.setCurrentIndex(col_idx-1)

    # [Tab - Basic Model] : validation_graph_next_event
    def Draw_Basic_Graph_Validation_Next(self):
        item_cnt = self.cb_basicValidation.count()
        if (item_cnt>0):
            col_idx = self.cb_basicValidation.currentIndex()
            if (col_idx == item_cnt-1): return    
            else:
                self.cb_basicValidation.setCurrentIndex(col_idx+1)

    # [Tab - Basic Model] : draw_validation_graph
    def Draw_Basic_Graph_Validation(self):
                                
        # initialize_control
        self.basic_val_fig.clf()
        self.basic_val_ax = self.basic_val_fig.add_subplot(111)
        
        if (self.cb_basicValidation.count()<=0):
            self.basic_val_fig.tight_layout()                
            self.basic_val_canvas.draw()   
            return

        col_name = self.cb_basicValidation.currentText().strip()

        # get_validation_file
        model_name = self.validationFolder[self.BASIC].format(self.target_point)   
        validation_path = os.path.join(self.model_root_path , self.model, self.year, self.riverRegion, self.target_point, model_name, self.basic_validation_path)
        if os.path.isfile(validation_path):        
            valid_data = pd.read_csv(validation_path, encoding='cp949', date_parser=True)
            pd_valid = pd.DataFrame(valid_data)                       
            
            col_true = 'Y_true_{}'.format(col_name)
            col_pred = 'Y_pred_{}'.format(col_name)

            x_temp = list(range(len(pd_valid.loc[:,'Date'])))
            y_temp_true = pd_valid.loc[:,col_true]
            y_temp_pred = pd_valid.loc[:,col_pred]

            list_cnt = int(len(x_temp)/5)
            x_labels_cnt = []
            x_labels_name = []
            for i in range(5):
                x_labels_cnt.append(list_cnt*(i))
                x_labels_name.append(str(x_temp[list_cnt*(i)]))
            
            x_labels_cnt.append(len(x_temp)-1)
            x_labels_name.append(str(x_temp[len(x_temp)-1]))

            # get_nse_info
            nse_value = ''
            if (self.tbl_basicValidation.rowCount()>0):
                nse_value = str(self.tbl_basicValidation.item(0, self.cb_basicValidation.currentIndex()).text()).strip()  

            self.basic_val_ax.set_title('Water Level Prediction (NSE={})'.format(nse_value), size=6)
            self.basic_val_ax.set_xticks(x_labels_cnt)
            self.basic_val_ax.set_xticklabels(x_labels_name, size=6)            
            self.basic_val_ax.set_xlabel('Time', size=6)
            self.basic_val_ax.set_ylabel('Waterlevel', size=6)
            self.basic_val_ax.plot(x_temp, y_temp_true, label='Observed Waterlevel')
            self.basic_val_ax.plot(x_temp, y_temp_pred, label='Predicted Waterlevel')

            for tl in self.basic_val_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)

            self.basic_val_ax.legend(loc='upper right', prop={'size': 8})
            
        QTimer.singleShot(100, lambda: self.finalize_plot(self.basic_val_fig, self.basic_val_canvas))
    
    # [Tab - Basic Model] : inference_graph_prev_event
    def Draw_Basic_Graph_Inference_Prev(self):
        item_cnt = self.cb_basicInference.count()
        if (item_cnt>0):
            col_idx = self.cb_basicInference.currentIndex()
            if (col_idx == 0): return    
            else:
                self.cb_basicInference.setCurrentIndex(col_idx-1)

    # [Tab - Basic Model] : inference_graph_next_event
    def Draw_Basic_Graph_Inference_Next(self):
        item_cnt = self.cb_basicInference.count()
        if (item_cnt>0):
            col_idx = self.cb_basicInference.currentIndex()
            if (col_idx == item_cnt-1): return    
            else:
                self.cb_basicInference.setCurrentIndex(col_idx+1)

    # [Tab - Basic Model] : draw_inference_graph
    def Draw_Basic_Graph_Inference(self):
                        
        # initialize_control
        self.basic_inf_fig.clf()
        self.basic_inf_ax = self.basic_inf_fig.add_subplot(111)
        
        if (self.cb_basicInference.count()<=0):
            self.basic_inf_fig.tight_layout()                
            self.basic_inf_canvas.draw()   
            return        

        col_name = self.cb_basicInference.currentText().strip()

        # get_model_info
        model_name = self.inferenceFolder[self.BASIC].format(self.target_point)    
        inference_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, model_name, self.basic_inference_path)
        if os.path.isfile(inference_path):        
            valid_data = pd.read_csv(inference_path, encoding='cp949', date_parser=True)
            pd_valid = pd.DataFrame(valid_data)           
                   
            col_true = 'Y_true_{}'.format(col_name)
            col_pred = 'Y_pred_{}'.format(col_name)

            x_temp = list(range(len(pd_valid.loc[:,'Date'])))
            y_temp_true = pd_valid.loc[:,col_true]
            y_temp_pred = pd_valid.loc[:,col_pred]

            list_cnt = int(len(x_temp)/5)
            x_labels_cnt = []
            x_labels_name = []
            for i in range(5):
                x_labels_cnt.append(list_cnt*(i))
                x_labels_name.append(str(x_temp[list_cnt*(i)]))
            
            x_labels_cnt.append(len(x_temp)-1)
            x_labels_name.append(str(x_temp[len(x_temp)-1]))
            
            # get_nse_info
            nse_value = ''
            if (self.tbl_basicInference.rowCount()>0):
                nse_value = str(self.tbl_basicInference.item(0, self.cb_basicInference.currentIndex()).text()).strip()  

            self.basic_inf_ax.set_xticks(x_labels_cnt)
            self.basic_inf_ax.set_xticklabels(x_labels_name, size=6)           
            self.basic_inf_ax.set_title('Water Level Prediction (NSE={})'.format(nse_value), size=6)
            self.basic_inf_ax.set_xlabel('Time', size=6)
            self.basic_inf_ax.set_ylabel('Waterlevel', size=6)
            self.basic_inf_ax.plot(x_temp, y_temp_true, label='Observed Waterlevel')
            self.basic_inf_ax.plot(x_temp, y_temp_pred, label='Predicted Waterlevel')
            
            for tl in self.basic_inf_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)

            self.basic_inf_ax.legend(loc='upper right', prop={'size': 8})
                
        QTimer.singleShot(100, lambda: self.finalize_plot(self.basic_inf_fig, self.basic_inf_canvas))

    # [Tab - Basic Model] : make_report_resultfile_performance_check
    def Make_Basic_PerformanceCheck(self):
                           
        self.cb_basic_pc_time.clear()

        # target_point_alarm_info
        target_waterlevel = pd.read_csv(os.path.join(self.obs_root_path, 'target_waterlevel.csv'), date_parser = True)
        target_value = target_waterlevel[target_waterlevel['target_point']==int(self.target_point)]        
        target_name = ''
        Watch_level = 0
        Warning_level = 0
        if not target_value.empty:
            target_name = target_value['target_name'].values[0]
            Watch_level = target_value['watch_level'].values[0]
            Warning_level = target_value['warning_level'].values[0]

        # set_inference_foldername
        inference_name = self.inferenceFolder[self.BASIC].format(self.target_point)   

        # 2022_to_2023_inference_file
        year_inf = '2023'
        if (self.cb_year.count() >= self.cb_year.currentIndex()+1):
            year_inf = self.cb_year.itemText(self.cb_year.currentIndex()+1)
                
        # 2022_to_2023_inference_file
        inference_path =  os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, inference_name, self.basic_inference_path)
        
        # 2023_model_dataset
        file_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], year_inf, self.riverRegion, self.target_point)
        dataset_filepath = os.path.join(file_path, 'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))

        if (os.path.isfile(inference_path) and os.path.isfile(dataset_filepath)):
            dataset = pd.read_csv(os.path.join(file_path, 'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point)), parse_dates=['Date'])
            
            modified_dataset = dataset[dataset['Date'].dt.year == 2023].drop_duplicates(subset='Date')
            modified_dataset = pd.concat([modified_dataset.iloc[:, 0], modified_dataset[modified_dataset.columns[modified_dataset.columns.str.startswith('WS_')].tolist()]], axis=1)

            result_load_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point, inference_name)

            load_result = pd.read_csv(os.path.join(result_load_path, self.basic_inference_path), parse_dates=['Date'])
            
            merged_result = pd.merge(modified_dataset,load_result, on="Date")
                            
            WS_columns = [col for col in merged_result.columns if col.startswith('WS_')]
                            
            WS_data = merged_result[merged_result.columns[merged_result.columns.str.startswith('WS_')].tolist()[len(WS_columns)-1]]
            
            merged_result = merged_result.drop(columns=WS_columns)
            merged_result['Rainfall'] = WS_data
            
            # make_report_result_file
            result_file_name = 'Results_'+ str(self.target_point) +'.csv'
            if not os.path.exists(os.path.join(self.model_root_path ,'report', self.modelFolder[self.BASIC], str(self.target_point))):
                os.makedirs(os.path.join(self.model_root_path ,'report', self.modelFolder[self.BASIC], str(self.target_point)))
            merged_result.to_csv(os.path.join(self.model_root_path ,'report', self.modelFolder[self.BASIC], str(self.target_point), result_file_name), index=False)

            # make_report_performance_check_graph_img
            save_path = os.path.join(self.model_root_path ,'report', self.modelFolder[self.BASIC], str(self.target_point), 'images_all')
            
            # Unless save_path folder exist, make the save_path folder
            if not os.path.exists(save_path):
                os.makedirs(save_path)
                
            # get_result_file
            results_data = pd.read_csv(os.path.join(self.model_root_path ,'report', self.modelFolder[self.BASIC], str(self.target_point), result_file_name), parse_dates=['Date'])
                      
            Obs_data = results_data.iloc[:,[0,1]]
            Obs_data.columns = ['Date','Obs']
            
            # make predict data
            predict_header = list(range(10,370,10))

        
            for j in range(len(predict_header)):
                txt_dateCol = '{}min'.format(str(predict_header[j]))
                txt_predCol = 'Y_pred_{}min'.format(str(predict_header[j]))                
                globals()['Pred_{}'.format(str(predict_header[j]))] = results_data.loc[:,[txt_dateCol,txt_predCol]]
                globals()['Pred_{}'.format(str(predict_header[j]))].columns = ['Date', 'Pred_{}'.format(str(predict_header[j]))]
                        
            Rainfall = results_data.loc[:,['Date','Rainfall']]
            Rainfall.columns = ['Date','Rainfall']
    
            for k in range(len(predict_header)):
                if k==0 :
                    Obs_data['Date'] = pd.to_datetime(Obs_data['Date'], errors='coerce')
                    eval('Pred_{}'.format(str(predict_header[k])))['Date'] = pd.to_datetime(
                        eval('Pred_{}'.format(str(predict_header[k])))['Date'], errors='coerce'
                    )

                    Graph_dataset = pd.merge(Obs_data, eval('Pred_{}'.format(str(predict_header[k]))), on="Date")
                else :
                    # 데이터 준비
                    Pred_df = eval('Pred_{}'.format(str(predict_header[k])))

                    # 날짜 타입 맞추기
                    Graph_dataset['Date'] = pd.to_datetime(Graph_dataset['Date'], errors='coerce')
                    Pred_df['Date'] = pd.to_datetime(Pred_df['Date'], errors='coerce')

                    Graph_dataset = pd.merge(Graph_dataset,eval('Pred_{}'.format(str(predict_header[k]))), on="Date")
                    
            
            Graph_dataset = pd.merge(Graph_dataset, Rainfall, on="Date")
        
            # peak index_graph_setting
            peak_index = Graph_dataset.Obs.index[Graph_dataset['Obs'] == max(Graph_dataset.Obs)].to_list()    

            end_tmp = Graph_dataset.Date[peak_index[0]]
            end_time =pd.to_datetime(end_tmp)
            
            std_tmp = Graph_dataset.Date[peak_index[0]-36]
            std_time = pd.to_datetime(std_tmp)
            
            self.dt_basic_pc_startTime.setDate(QtCore.QDate(std_time.year, std_time.month, std_time.day))           
            self.dt_basic_pc_startTime.setTime(QtCore.QTime(std_time.hour, std_time.minute, 0))     
            self.dt_basic_pc_endTime.setDate(QtCore.QDate(end_time.year, end_time.month, end_time.day))        
            self.dt_basic_pc_endTime.setTime(QtCore.QTime(end_time.hour, end_time.minute, 0))       

            # combobox
            interval_time = 0
            if (self.rb_basic_pd_interval1.isChecked()):    #30분간격
                interval_time = 30
            elif (self.rb_basic_pd_interval2.isChecked()):  #1시간간격
                interval_time = 60
            elif (self.rb_basic_pd_interval3.isChecked()):  #2시간간격
                interval_time = 120
            else:
                interval_time = 0

            # set_performance_check_time_combobox
            diff_date = end_time - std_time
            loof_cnt = int((diff_date.seconds/60) / interval_time)
            now_date = std_time

            while(now_date<=end_time):                
                self.cb_basic_pc_time.addItem(str(now_date)[:-3])
                now_date = now_date + timedelta(minutes=interval_time) 

            if (self.cb_basic_pc_time.count()>0):
                self.cb_basic_pc_time.setCurrentIndex(self.cb_basic_pc_time.count()-1)

            tick_interval = 18
            all_interval = int(math.ceil(len(Graph_dataset)/6/10)*10)            
            start = peak_index[0]-36
            
            # make img            
            for m in range(start,peak_index[0]+1,3):
                nowtime = m
                
                # make prediction Dataframe
                predict_data = pd.DataFrame()
                for q in range(len(predict_header)):
                    temp_predict_data = Graph_dataset.iloc[nowtime+q+1:nowtime+q+2,[q+2]]
                    temp_predict_data.columns = ['predict_data']
                    predict_data = pd.concat([predict_data,temp_predict_data],axis=0)
                                
                # make imagefile (for report)
                fig= plt.figure(figsize=(14,7))
                gs = gridspec.GridSpec(nrows=3,
                                ncols=1, 
                                height_ratios=[1,4,2])
                ax0 = plt.subplot(gs[0])
                ax0.bar(list(range(nowtime-54,nowtime+1)), Graph_dataset['Rainfall'][nowtime-54:nowtime+1], color = 'cyan', label = 'Observed Water Level')
                ax0.bar(list(range(nowtime+1,nowtime+55)), Graph_dataset['Rainfall'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
                ax0.set_title(self.target_point + '\n' + 'Current time : ' + Graph_dataset['Date'][nowtime].strftime('%Y-%m-%d %H:%M'))

                ax0.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[])
                ax0.set_ylabel('Rainfall(mm)')
                ax0.set_ylim([math.floor(min(Graph_dataset['Rainfall'][:])),math.ceil(max(Graph_dataset['Rainfall'][:]))])
                
                ax1 = plt.subplot(gs[1]) 
                ax1.plot([nowtime-54,nowtime+54],[Watch_level,Watch_level], color = 'yellow', label = 'Flood watch')
                ax1.text(nowtime-44, Watch_level + 0.1, 'Flood watch', ha='center', va='bottom', size = 12)
                ax1.plot([nowtime-54,nowtime+54],[Warning_level,Warning_level], color = 'red', label = 'Flood warning')
                ax1.text(nowtime-44, Warning_level + 0.1, 'Flood warning', ha='center', va='bottom', size = 12)
                ax1.plot(Graph_dataset['Obs'][nowtime-54:nowtime+1], color = 'black', label = 'Observed Water Level')
                ax1.plot(Graph_dataset['Obs'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
                ax1.plot(Graph_dataset['Obs'][nowtime:nowtime+1], color = 'blue', label = 'Observed Water Level', marker= 'o')
                ax1.plot(predict_data, color = 'salmon', label = 'Predicted  Water Level', marker= 'o' )
                
                ax1.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[Graph_dataset['Date'][nowtime-54].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*1].strftime('%m-%d %H:%M'),\
                                                                    Graph_dataset['Date'][nowtime-54+tick_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*3].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][nowtime-54+tick_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][nowtime-54+tick_interval*5].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][nowtime-54+tick_interval*6].strftime('%m-%d %H:%M')] )
                ax1.set_xlabel('Time')
                ax1.set_ylabel('Water Level')
                ax1.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),max(math.ceil(max(Graph_dataset['Obs'][:])),Warning_level+1)])
                
                ax2 = plt.subplot(gs[2]) 
                ax2.plot(Graph_dataset['Obs'][:nowtime+1], color = 'blue', label = 'Observed Water Level')
                ax2.plot(Graph_dataset['Obs'][nowtime+1:], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
                ax2.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),math.ceil(max(Graph_dataset['Obs'][:]))])
                ax2.set_xticks(range(0,all_interval*6+1,all_interval),[Graph_dataset['Date'][0].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*1].strftime('%m-%d %H:%M'),\
                                                                    Graph_dataset['Date'][all_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*3].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][all_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][all_interval*5].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][len(Graph_dataset)-1].strftime('%m-%d %H:%M')])
                ax2.set_ylabel('Water Level')

                date_str = Graph_dataset['Date'][nowtime].strftime('%Y%m%d%H%M%S')  # 원하는 형식으로 문자열 변환
                safe_date_str = re.sub(r"[^a-zA-Z0-9]", "", date_str)

                plt.savefig(save_path + r'\Prediction_graph_' + f"{0:05d}" + '(' + safe_date_str + ').png')
                
    # [Tab - Basic Model] : set_performance_check_combobox_event (search, change interval)
    def Set_Basic_Combobox_PerformanceCheck_Time(self):        
                        
        global data_dataset
        
        # initialize_control     
        self.cb_basic_pc_time.clear()   

        # get_result_file (rf_perfofrmance_check)
        result_file_name = 'Results_'+ str(self.target_point) +'.csv'
        report_path = os.path.join(self.model_root_path ,'report', self.modelFolder[self.BASIC], str(self.target_point), result_file_name)
        if os.path.exists(report_path):            
            results_data = pd.read_csv(report_path,parse_dates=['Date'])

            Obs_data = results_data.iloc[:,[0,1]]
            Obs_data.columns = ['Date','Obs']
            
            # make predict data
            predict_header = list(range(10,370,10))
        
            for j in range(len(predict_header)):
                txt_dateCol = '{}min'.format(predict_header[j])         
                txt_predCol = 'Y_pred_{}min'.format(predict_header[j])                                   
                globals()['Pred_{}'.format(str(predict_header[j]))] = results_data.loc[:,[txt_dateCol,txt_predCol]]
                globals()['Pred_{}'.format(str(predict_header[j]))].columns = ['Date', 'Pred_{}'.format(str(predict_header[j]))]
                        
            Rainfall = results_data.loc[:,['Date','Rainfall']]
            Rainfall.columns = ['Date','Rainfall']
        
            for k in range(len(predict_header)):
                if k==0 :
                    Obs_data['Date'] = pd.to_datetime(Obs_data['Date'])
                    eval('Pred_{}'.format(str(predict_header[k])))['Date'] = pd.to_datetime(eval('Pred_{}'.format(str(predict_header[k])))['Date'])

                    Graph_dataset = pd.merge(Obs_data, eval('Pred_{}'.format(str(predict_header[k]))), on='Date')
                else :
                    # 데이터 준비
                    Pred_df = eval('Pred_{}'.format(str(predict_header[k])))

                    # 날짜 타입 맞추기
                    Graph_dataset['Date'] = pd.to_datetime(Graph_dataset['Date'], errors='coerce')
                    Pred_df['Date'] = pd.to_datetime(Pred_df['Date'], errors='coerce')
                    
                    Graph_dataset = pd.merge(Graph_dataset,eval('Pred_{}'.format(str(predict_header[k]))), on="Date")
                    
            Graph_dataset = pd.merge(Graph_dataset, Rainfall, on="Date")

            end_tmp = '{}:00'.format(str(self.dt_basic_pc_endTime.text()))
            end_time = pd.to_datetime(end_tmp)
            std_tmp = '{}:00'.format(str(self.dt_basic_pc_startTime.text()))
            std_time = pd.to_datetime(std_tmp)

            if (std_time <= end_time):    
                # combobox
                interval_time = 0
                if (self.rb_basic_pd_interval1.isChecked()):    #30분간격
                    interval_time = 30
                elif (self.rb_basic_pd_interval2.isChecked()):  #1시간간격
                    interval_time = 60
                elif (self.rb_basic_pd_interval3.isChecked()):  #2시간간격
                    interval_time = 120
                else:
                    interval_time = 0
                
                loof_start = std_time
                loof_out = 0

                diff_date = end_time - std_time
                loof_cnt = int((diff_date.seconds/60) / interval_time)
                now_date = std_time
                
                while(now_date<=end_time):                    
                    wl_info = Graph_dataset[Graph_dataset['Date'] == str(now_date)]
                    if not wl_info.empty:
                        self.cb_basic_pc_time.addItem(str(now_date)[:-3])
                    now_date = now_date + timedelta(minutes=interval_time) 

                if (self.cb_basic_pc_time.count()>0):
                    self.cb_basic_pc_time.setCurrentIndex(self.cb_basic_pc_time.count()-1)

    # [Tab - Basic Model] : set_performance_check_prev_event
    def Draw_Basic_Graph_PerformanceCheck_Prev(self):
        item_cnt = self.cb_basic_pc_time.count()
        if (item_cnt>0):
            col_idx = self.cb_basic_pc_time.currentIndex()
            if (col_idx == 0): return    
            else:
                self.cb_basic_pc_time.setCurrentIndex(col_idx-1)

    # [Tab - Basic Model] : set_performance_check_next_event
    def Draw_Basic_Graph_PerformanceCheck_Next(self):
        item_cnt = self.cb_basic_pc_time.count()
        if (item_cnt>0):
            col_idx = self.cb_basic_pc_time.currentIndex()
            if (col_idx == item_cnt-1): return    
            else:
                self.cb_basic_pc_time.setCurrentIndex(col_idx+1)

    # [Tab - Basic Model] : draw_performance_check_graph
    def Draw_Basic_Graph_PerformanceCheck(self):        
                         
        if (self.cb_basic_pc_time.currentText()==''): 
            self.basic_pc_fig.clf()
            self.basic_pc_ax = self.basic_pc_fig.add_subplot(111)
            self.basic_pc_canvas.draw()
            return

        # initialize_control    
        self.basic_pc_fig.clf()

        # get_targetpoint_info
        target_waterlevel = pd.read_csv(os.path.join(self.obs_root_path, 'target_waterlevel.csv'), date_parser = True)
        target_value = target_waterlevel[target_waterlevel['target_point']==int(self.target_point)]        
        target_name = ''
        Watch_level = 0
        Warning_level = 0
        if not target_value.empty:
            target_name = target_value['target_name'].values[0]   
            Watch_level = target_value['watch_level'].values[0]
            Warning_level = target_value['warning_level'].values[0]

        # get_result_file 
        result_file_name = 'Results_'+ str(self.target_point) +'.csv'
        report_path = os.path.join(self.model_root_path ,'report', self.modelFolder[self.BASIC], str(self.target_point), result_file_name)
        if os.path.exists(report_path):            
            results_data = pd.read_csv(report_path, parse_dates=['Date'])

            Obs_data = results_data.iloc[:,[0,1]]
            Obs_data.columns = ['Date','Obs']

            # make predict data
            predict_header = list(range(10,370,10))
        
            for j in range(len(predict_header)):
                txt_dateCol = '{}min'.format(predict_header[j])         
                txt_predCol = 'Y_pred_{}min'.format(predict_header[j])                                           
                globals()['Pred_{}'.format(str(predict_header[j]))] = results_data.loc[:,[txt_dateCol,txt_predCol]]
                globals()['Pred_{}'.format(str(predict_header[j]))].columns = ['Date', 'Pred_{}'.format(str(predict_header[j]))]
                        
            Rainfall = results_data.loc[:,['Date','Rainfall']]
            Rainfall.columns = ['Date','Rainfall']
        
            for k in range(len(predict_header)):
                if k==0 :
                    Obs_data['Date'] = pd.to_datetime(Obs_data['Date'])
                    eval('Pred_{}'.format(str(predict_header[k])))['Date'] = pd.to_datetime(eval('Pred_{}'.format(str(predict_header[k])))['Date'])

                    Graph_dataset = pd.merge(Obs_data, eval('Pred_{}'.format(str(predict_header[k]))), on='Date')
                else :
                    # 데이터 준비
                    Pred_df = eval('Pred_{}'.format(str(predict_header[k])))

                    # 날짜 타입 맞추기
                    Graph_dataset['Date'] = pd.to_datetime(Graph_dataset['Date'], errors='coerce')
                    Pred_df['Date'] = pd.to_datetime(Pred_df['Date'], errors='coerce')
                    
                    Graph_dataset = pd.merge(Graph_dataset,eval('Pred_{}'.format(str(predict_header[k]))), on="Date")
                    
            Graph_dataset = pd.merge(Graph_dataset, Rainfall, on="Date")
         
            # set_combobox - peaktime(end_time)
            end_tmp = '{}:00'.format(str(self.cb_basic_pc_time.currentText()))            
            end_time = pd.to_datetime(end_tmp)

            # peak index
            peak_index = Graph_dataset.Date.index[Graph_dataset['Date'] == end_tmp].to_list()   
            
            tick_interval = 18
            all_interval = int(math.ceil(len(Graph_dataset)/6/10)*10)   
            nowtime = peak_index[0]
            
            # make prediction Dataframe
            predict_data = pd.DataFrame()
            for q in range(len(predict_header)):
                temp_predict_data = Graph_dataset.iloc[nowtime+q+1:nowtime+q+2,[q+2]]
                temp_predict_data.columns = ['predict_data']
                predict_data = pd.concat([predict_data,temp_predict_data],axis=0)            
            
            # draw performance_check graph
            gs = gridspec.GridSpec(nrows=3,
                            ncols=1,
                            height_ratios=[1,4,2])
            

            # draw - rainfall graph
            self.basic_pc_ax = self.basic_pc_fig.add_subplot(gs[0])
            self.basic_pc_ax.bar(list(range(nowtime-54,nowtime+1)), Graph_dataset['Rainfall'][nowtime-54:nowtime+1], color = 'cyan', label = 'Observed Water Level')
            self.basic_pc_ax.bar(list(range(nowtime+1,nowtime+55)), Graph_dataset['Rainfall'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
            self.basic_pc_ax.set_title('Current time : '+Graph_dataset['Date'][peak_index[0]].strftime('%Y-%m-%d %H:%M'), size=6)
            self.basic_pc_ax.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[])
            self.basic_pc_ax.set_ylabel('Rainfall(mm)', size=6)
            self.basic_pc_ax.set_ylim([math.floor(min(Graph_dataset['Rainfall'][:])),math.ceil(max(Graph_dataset['Rainfall'][:]))])
            for tl in self.basic_pc_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)
            
            # draw - predict
            self.basic_pc_ax = self.basic_pc_fig.add_subplot(gs[1])
            self.basic_pc_ax.plot([nowtime-54,nowtime+54],[Watch_level,Watch_level], color = 'yellow', label = 'Flood watch', linewidth=0.8)
            self.basic_pc_ax.text(nowtime-44, Watch_level + 0.1, 'Flood watch', ha='center', va='bottom', size = 6)
            self.basic_pc_ax.plot([nowtime-54,nowtime+54],[Warning_level,Warning_level], color = 'red', label = 'Flood warning', linewidth=0.8)
            self.basic_pc_ax.text(nowtime-44, Warning_level + 0.1, 'Flood warning', ha='center', va='bottom', size = 6)
            self.basic_pc_ax.plot(Graph_dataset['Obs'][nowtime-54:nowtime+1], color = 'black', label = 'Observed Water Level', linewidth=0.8)
            self.basic_pc_ax.plot(Graph_dataset['Obs'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--", linewidth=0.8)
            self.basic_pc_ax.plot(Graph_dataset['Obs'][nowtime:nowtime+1], color = 'blue', label = 'Observed Water Level', marker= 'o', markersize=1)
            self.basic_pc_ax.plot(predict_data, color = 'salmon', label = 'Predicted  Water Level', marker= 'o', markersize=1)
            self.basic_pc_ax.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[Graph_dataset['Date'][nowtime-54].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*1].strftime('%m-%d %H:%M'),\
                                                        Graph_dataset['Date'][nowtime-54+tick_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*3].strftime('%m-%d %H:%M')\
                                                        , Graph_dataset['Date'][nowtime-54+tick_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][nowtime-54+tick_interval*5].strftime('%m-%d %H:%M')\
                                                        , Graph_dataset['Date'][nowtime-54+tick_interval*6].strftime('%m-%d %H:%M')] )
            self.basic_pc_ax.set_xticklabels([Graph_dataset['Date'][nowtime-54].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*1].strftime('%m-%d %H:%M'),\
                                                        Graph_dataset['Date'][nowtime-54+tick_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*3].strftime('%m-%d %H:%M')\
                                                        , Graph_dataset['Date'][nowtime-54+tick_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][nowtime-54+tick_interval*5].strftime('%m-%d %H:%M')\
                                                        , Graph_dataset['Date'][nowtime-54+tick_interval*6].strftime('%m-%d %H:%M')] , fontsize=5)
            self.basic_pc_ax.set_ylabel('Water Level', size=6)
            self.basic_pc_ax.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),max(math.ceil(max(Graph_dataset['Obs'][:])),Warning_level+1)])
            for tl in self.basic_pc_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6) 
            
            # draw - waterlevel
            self.basic_pc_ax = self.basic_pc_fig.add_subplot(gs[2])
            self.basic_pc_ax.plot(Graph_dataset['Obs'][:nowtime+1], color = 'blue', label = 'Observed Water Level', linewidth=0.8)
            self.basic_pc_ax.plot(Graph_dataset['Obs'][nowtime+1:], color = 'lightgray', label = 'Observed Water Level', linestyle="--", linewidth=0.8)
            self.basic_pc_ax.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),math.ceil(max(Graph_dataset['Obs'][:]))])
            self.basic_pc_ax.set_xticks(range(0,all_interval*6+1,all_interval),[Graph_dataset['Date'][0].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*1].strftime('%m-%d %H:%M'),\
                                                        Graph_dataset['Date'][all_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*3].strftime('%m-%d %H:%M')\
                                                        , Graph_dataset['Date'][all_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][all_interval*5].strftime('%m-%d %H:%M')\
                                                        , Graph_dataset['Date'][len(Graph_dataset)-1].strftime('%m-%d %H:%M')])
            self.basic_pc_ax.set_xticklabels([Graph_dataset['Date'][0].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*1].strftime('%m-%d %H:%M'),\
                                                        Graph_dataset['Date'][all_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*3].strftime('%m-%d %H:%M')\
                                                        , Graph_dataset['Date'][all_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][all_interval*5].strftime('%m-%d %H:%M')\
                                                        , Graph_dataset['Date'][len(Graph_dataset)-1].strftime('%m-%d %H:%M')], fontsize=5)       
            self.basic_pc_ax.set_ylabel('Water Level', size=6)           
            for tl in self.basic_pc_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)    
                                
        QTimer.singleShot(100, lambda: self.finalize_plot(self.basic_pc_fig, self.basic_pc_canvas))  

    # [Tab - Basic Model] : save_validation_graph
    def Save_Basic_ImgValidation_SavePath(self):

        timeText = self.cb_basicValidation.currentText()
        saveFile = '{0}_{1}_{2}_{3}_validation_{4}.png'.format('Basic', self.year, self.riverRegion, self.target_point, timeText)

        file_path, _ = QFileDialog.getSaveFileName(
            self, 
            "[Dashboard] Save Basic Validation Image", 
            saveFile,
            "PNG(*.png);;JPEG(*.jpg);;All(*.*)"
        )

        if file_path:
            # save_img
            self.basic_val_fig.savefig(file_path, dpi=500)
    
    # [Tab - Basic Model] : save_inference_graph
    def Save_Basic_ImgInference_SavePath(self):      

        timeText = self.cb_basicInference.currentText()
        saveFile = '{0}_{1}_{2}_{3}_inference_{4}.png'.format('Basic', self.year, self.riverRegion, self.target_point, timeText)

        file_path, _ = QFileDialog.getSaveFileName(
            self, 
            "[Dashboard] Save Basic Inference Image", 
            saveFile,
            "PNG(*.png);;JPEG(*.jpg);;All(*.*)"
        )

        if file_path:
            # save_img
            self.basic_inf_fig.savefig(file_path, dpi=500)        

    # [Tab - Basic Model] : save_performancecheck_graph
    def Save_Basic_ImgPerformanceCheck_SavePath(self):

        timeText = self.cb_basic_pc_time.currentText()
        timeText = timeText.translate(str.maketrans('', '', '- :'))
        saveFile = '{0}_{1}_{2}_{3}_performanceCheck_{4}.png'.format('Basic', self.year, self.riverRegion, self.target_point, timeText)

        file_path, _ = QFileDialog.getSaveFileName(
            self, 
            "[Dashboard] Save Basic PerformanceCheck Image", 
            saveFile,
            "PNG(*.png);;JPEG(*.jpg);;All(*.*)"
        )

        if file_path:
            # save_img
            self.basic_pc_fig.savefig(file_path, dpi=500)     
  
    # [Tab - Scenario Model] : validation, inference, performance_check 정보 셋팅
    def Get_ScenarioModel(self):
  
        # get_model_name 
        model_name = self.validationFolder[self.SCENARIO].format(self.target_point)        
               
        # 1. validation(nse) info(nse table, nse시간콤보박스선택에 따라 graph표출)  
        self.cb_sceValidation.clear()
        self.tbl_sceValidation.clearContents()

        nse_name = 'nse_{}.csv'.format(self.target_point)
        nse_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, model_name, nse_name)
        validation_path = os.path.join(self.model_root_path , "Scenario", self.year, self.riverRegion, self.target_point, model_name, self.sce_validation_path)
        if (os.path.isfile(nse_path) and os.path.isfile(validation_path)):
            valid_data = pd.read_csv(validation_path, encoding='cp949', date_parser=True)
            nse_data = pd.read_csv(nse_path, encoding='cp949', date_parser=True)
            nse_list = pd.DataFrame(nse_data)  

            lst_col = valid_data.filter(regex='min').columns.tolist()
            nse_col = []
            for col in range(0, int(len(lst_col)/3), 1):
                nse_col.append(str(lst_col[col*3]))

            self.tbl_sceValidation.setRowCount(1)
            self.tbl_sceValidation.setColumnCount(len(nse_col))
            self.tbl_sceValidation.setHorizontalHeaderLabels(nse_col)
            for i in range(len(nse_col)):
                nse_val = nse_list.iat[i,0]
                item_val = round(nse_val, 3)
                item = QTableWidgetItem(str(item_val))
                item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                self.tbl_sceValidation.setItem(0, i, item)
                self.cb_sceValidation.addItem(nse_col[i])

            self.tbl_sceValidation.resizeColumnsToContents()            
            self.cb_sceValidation.setCurrentIndex(0)

        # 2. inference(nse) info(nse table, nse시간콤보박스선택에 따라 graph표출)   
        self.cb_sceInference.clear()        
        self.tbl_sceInference.clearContents()
            
        inference_name = self.inferenceFolder[self.SCENARIO].format(self.target_point)   
        nse_name = 'nse_{}.csv'.format(self.target_point)
        nse_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, inference_name, nse_name)
        inference_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, inference_name, self.sce_inference_path)
       
        if (os.path.isfile(nse_path) and os.path.isfile(inference_path)):      
            valid_data = pd.read_csv(inference_path, encoding='cp949', date_parser=True) 
            nse_data = pd.read_csv(nse_path, encoding='cp949', date_parser=True)
            nse_list = pd.DataFrame(nse_data)        

            lst_col = valid_data.filter(regex='min').columns.tolist()
            nse_col = []
            for col in range(0, int(len(lst_col)/3), 1):
                nse_col.append(str(lst_col[col*3]))

            self.tbl_sceInference.setRowCount(1)
            self.tbl_sceInference.setColumnCount(len(nse_col))
            self.tbl_sceInference.setHorizontalHeaderLabels(nse_col)

            for i in range(len(nse_col)):
                nse_val = nse_list.iat[i,0]
                item_val = round(nse_val, 3)
                item = QTableWidgetItem(str(item_val))
                item.setTextAlignment(Qt.AlignHCenter | Qt.AlignVCenter)
                self.tbl_sceInference.setItem(0, i, item)
                self.cb_sceInference.addItem(nse_col[i])

            self.tbl_sceInference.resizeColumnsToContents()
            self.cb_sceInference.setCurrentIndex(0)
                    
        # 3. performance_check (result 파일만들고 graph 표출)
        self.Make_Scenario_PerformanceCheck() 

    # [Tab - Scenario Model] : validation_graph_prev_event
    def Draw_Scenario_Graph_Validation_Prev(self):
        item_cnt = self.cb_sceValidation.count()
        if (item_cnt>0):
            col_idx = self.cb_sceValidation.currentIndex()
            if (col_idx == 0): return    
            else:
                self.cb_sceValidation.setCurrentIndex(col_idx-1)

    # [Tab - Scenario Model] : validation_graph_next_event
    def Draw_Scenario_Graph_Validation_Next(self):
        item_cnt = self.cb_sceValidation.count()
        if (item_cnt>0):
            col_idx = self.cb_sceValidation.currentIndex()
            if (col_idx == item_cnt-1): return    
            else:
                self.cb_sceValidation.setCurrentIndex(col_idx+1)

    # [Tab - Scenario Model] : draw_validation_graph
    def Draw_Scenario_Graph_Validation(self):

        global data_dataset

        # initialize_control
        self.sce_val_fig.clf()
        self.sce_val_ax = self.sce_val_fig.add_subplot(111)        

        if (self.cb_sceValidation.count()<=0):
            self.sce_val_fig.tight_layout()                
            self.sce_val_canvas.draw()   
            return

        col_name = self.cb_sceValidation.currentText().strip()

        # get_validation_file   
        model_name = self.validationFolder[self.SCENARIO].format(self.target_point)    
        validation_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, model_name, self.sce_validation_path)
        if os.path.isfile(validation_path):        
            valid_data = pd.read_csv(validation_path, encoding='cp949', date_parser=True)
            pd_valid = pd.DataFrame(valid_data)                       
            
            col_true = 'Y_true_{}'.format(col_name)
            col_pred = 'Y_pred_{}'.format(col_name)

            x_temp = list(range(len(pd_valid.loc[:,'Date'])))
            y_temp_true = pd_valid.loc[:,col_true]
            y_temp_pred = pd_valid.loc[:,col_pred]

            self.sce_val_ax.set_title(col_name)

            list_cnt = int(len(x_temp)/5)
            x_labels_cnt = []
            x_labels_name = []
            for i in range(5):
                x_labels_cnt.append(list_cnt*(i))
                x_labels_name.append(str(x_temp[list_cnt*(i)]))
            
            x_labels_cnt.append(len(x_temp)-1)
            x_labels_name.append(str(x_temp[len(x_temp)-1]))
            
            # get_nse_info
            nse_value = ''
            if (self.tbl_sceValidation.rowCount()>0):
                nse_value = str(self.tbl_sceValidation.item(0, self.cb_sceValidation.currentIndex()).text()).strip()  

            
            self.sce_val_ax.set_title('Water Level Prediction (NSE={})'.format(nse_value), size=6)
            self.sce_val_ax.set_xticks(x_labels_cnt)
            self.sce_val_ax.set_xticklabels(x_labels_name, size=6)        
            self.sce_val_ax.set_xlabel('Time', size=6)
            self.sce_val_ax.set_ylabel('Waterlevel', size=6)
            self.sce_val_ax.plot(x_temp, y_temp_true, label='Observed Waterlevel')
            self.sce_val_ax.plot(x_temp, y_temp_pred, label='Predicted Waterlevel')
            
            for tl in self.sce_val_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)

            self.sce_val_ax.legend(loc='upper right', prop={'size': 8})            
        
        QTimer.singleShot(100, lambda: self.finalize_plot(self.sce_val_fig, self.sce_val_canvas))
    
    # [Tab - Scenario Model] : inference_graph_prev_event
    def Draw_Scenario_Graph_Inference_Prev(self):
        item_cnt = self.cb_sceInference.count()
        if (item_cnt>0):
            col_idx = self.cb_sceInference.currentIndex()
            if (col_idx == 0): return    
            else:
                self.cb_sceInference.setCurrentIndex(col_idx-1)

    # [Tab - Scenario Model] : inference_graph_next_event
    def Draw_Scenario_Graph_Inference_Next(self):
        item_cnt = self.cb_sceInference.count()
        if (item_cnt>0):
            col_idx = self.cb_sceInference.currentIndex()
            if (col_idx == item_cnt-1): return    
            else:
                self.cb_sceInference.setCurrentIndex(col_idx+1)

    # [Tab - Scenario Model] : draw_inference_graph
    def Draw_Scenario_Graph_Inference(self):
                
        global data_dataset
  
        # initialize_control
        self.sce_inf_fig.clf()
        self.sce_inf_ax = self.sce_inf_fig.add_subplot(111)

        if (self.cb_sceInference.count()<=0): 
            self.sce_inf_fig.tight_layout()                
            self.sce_inf_canvas.draw()
            return

        col_name = self.cb_sceInference.currentText().strip()

        # get_model_info    
        model_name = self.inferenceFolder[self.SCENARIO].format(self.target_point)    
        inference_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, model_name, self.sce_inference_path)
        if os.path.isfile(inference_path):        
            valid_data = pd.read_csv(inference_path, encoding='cp949', date_parser=True)
            pd_valid = pd.DataFrame(valid_data)           
                    
            col_true = 'Y_true_{}'.format(col_name)
            col_pred = 'Y_pred_{}'.format(col_name)

            x_temp = list(range(len(pd_valid.loc[:,'Date'])))
            y_temp_true = pd_valid.loc[:,col_true]
            y_temp_pred = pd_valid.loc[:,col_pred]

            self.sce_inf_ax.set_xlabel('Time')
            self.sce_inf_ax.set_ylabel('Waterlevel')

            list_cnt = int(len(x_temp)/5)
            x_labels_cnt = []
            x_labels_name = []
            for i in range(5):
                x_labels_cnt.append(list_cnt*(i))
                x_labels_name.append(str(x_temp[list_cnt*(i)]))
            
            x_labels_cnt.append(len(x_temp)-1)
            x_labels_name.append(str(x_temp[len(x_temp)-1]))

            # get_nse_info
            nse_value = ''
            if (self.tbl_sceInference.rowCount()>0):
                nse_value = str(self.tbl_sceInference.item(0, self.cb_sceInference.currentIndex()).text()).strip()  

            self.sce_inf_ax.set_xticks(x_labels_cnt)
            self.sce_inf_ax.set_xticklabels(x_labels_name, size=6)                       
            self.sce_inf_ax.set_title('Water Level Prediction (NSE={})'.format(nse_value), size=6)
            self.sce_inf_ax.set_xlabel('Time', size=6)
            self.sce_inf_ax.set_ylabel('Waterlevel', size=6)
            self.sce_inf_ax.plot(x_temp, y_temp_true, label='Observed Waterlevel')
            self.sce_inf_ax.plot(x_temp, y_temp_pred, label='Predicted Waterlevel')          

            for tl in self.sce_inf_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)

            self.sce_inf_ax.legend(loc='upper right', prop={'size': 8})
        
        QTimer.singleShot(100, lambda: self.finalize_plot(self.sce_inf_fig, self.sce_inf_canvas))  

    # [Tab - Scenario Model] : make_report_resultfile_performance_check
    def Make_Scenario_PerformanceCheck(self):
  
        global data_dataset

        self.cb_sce_pc_time.clear()

        # target_point_alarm_info
        target_waterlevel = pd.read_csv(os.path.join(self.obs_root_path, 'target_waterlevel.csv'), date_parser = True)
        target_value = target_waterlevel[target_waterlevel['target_point']==int(self.target_point)]        
        target_name = ''
        Watch_level = 0
        Warning_level = 0
        if not target_value.empty:
            target_name = target_value['target_name'].values[0]
            Watch_level = target_value['watch_level'].values[0]
            Warning_level = target_value['warning_level'].values[0]

        # set_inference_foldername
        inference_name = self.inferenceFolder[self.SCENARIO].format(self.target_point)   

        # 2022_to_2023_inference_file
        year_inf = '2023'
        if (self.cb_year.count() >= self.cb_year.currentIndex()+1):
            year_inf = self.cb_year.itemText(self.cb_year.currentIndex()+1)

        # 2022_to_2023_inference_file
        inference_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, inference_name, self.sce_inference_path)
                
        # 2023_model_dataset
        file_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], year_inf, self.riverRegion, self.target_point)
        dataset_filepath = os.path.join(file_path, 'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point))

        if (os.path.isfile(inference_path) and os.path.isfile(dataset_filepath)):
            dataset = pd.read_csv(os.path.join(file_path, 'Dataset_Target_{}_filtered_delete_null.csv'.format(self.target_point)),parse_dates=['Date'])
            
            modified_dataset = dataset[dataset['Date'].dt.year == 2023].drop_duplicates(subset='Date')
            modified_dataset = pd.concat([modified_dataset.iloc[:, 0], modified_dataset[modified_dataset.columns[modified_dataset.columns.str.startswith('WS_')].tolist()]], axis=1)

            result_load_path = os.path.join(self.model_root_path , self.modelFolder[self.SCENARIO], self.year, self.riverRegion, self.target_point, inference_name)

            load_result = pd.read_csv(os.path.join(result_load_path, self.sce_inference_path), parse_dates=['Date'])
                                
            merged_result = pd.merge(modified_dataset,load_result, on="Date")
                            
            WS_columns = [col for col in merged_result.columns if col.startswith('WS_')]
                            
            WS_data = merged_result[merged_result.columns[merged_result.columns.str.startswith('WS_')].tolist()[len(WS_columns)-1]]

            merged_result = merged_result.drop(columns=WS_columns)
            merged_result['Rainfall'] = WS_data
            
            # make_report_result_file
            result_file_name = 'Results_'+ str(self.target_point) +'.csv'
            if not os.path.exists(os.path.join(self.model_root_path ,'report', self.modelFolder[self.SCENARIO], str(self.target_point))):
                os.makedirs(os.path.join(self.model_root_path ,'report', self.modelFolder[self.SCENARIO], str(self.target_point)))
            merged_result.to_csv(os.path.join(self.model_root_path ,'report', self.modelFolder[self.SCENARIO], str(self.target_point), result_file_name), index=False)

            # make_report_performance_check_graph_img
            save_path = os.path.join(self.model_root_path ,'report', self.modelFolder[self.SCENARIO], str(self.target_point), 'images_all')
            
            # Unless save_path folder exist, make the save_path folder
            if not os.path.exists(save_path):
                os.makedirs(save_path)
                
            # get_result_file
            results_data = pd.read_csv(os.path.join(self.model_root_path ,'report', self.modelFolder[self.SCENARIO], str(self.target_point), result_file_name),parse_dates=['Date'])
            Obs_data = results_data.iloc[:,[0,1]]
            Obs_data.columns = ['Date','Obs']
            
            # make predict data
            predict_header = list(range(10,370,10))
        
            for j in range(len(predict_header)):
                txt_dateCol = '{}min'.format(predict_header[j])         
                txt_predCol = 'Y_pred_{}min'.format(predict_header[j])                                   
                globals()['Pred_{}'.format(str(predict_header[j]))] = results_data.loc[:,[txt_dateCol,txt_predCol]]
                globals()['Pred_{}'.format(str(predict_header[j]))].columns = ['Date', 'Pred_{}'.format(str(predict_header[j]))]
                        
            Rainfall = results_data.loc[:,['Date','Rainfall']]
            Rainfall.columns = ['Date','Rainfall']
    
            for k in range(len(predict_header)):
                if k==0 :
                    Obs_data['Date'] = pd.to_datetime(Obs_data['Date'])
                    eval('Pred_{}'.format(str(predict_header[k])))['Date'] = pd.to_datetime(eval('Pred_{}'.format(str(predict_header[k])))['Date'])

                    Graph_dataset = pd.merge(Obs_data, eval('Pred_{}'.format(str(predict_header[k]))), on='Date')
                else :
                    # 데이터 준비
                    Pred_df = eval('Pred_{}'.format(str(predict_header[k])))

                    # 날짜 타입 맞추기
                    Graph_dataset['Date'] = pd.to_datetime(Graph_dataset['Date'], errors='coerce')
                    Pred_df['Date'] = pd.to_datetime(Pred_df['Date'], errors='coerce')
                    
                    Graph_dataset = pd.merge(Graph_dataset,eval('Pred_{}'.format(str(predict_header[k]))), on="Date")
                    
            Graph_dataset = pd.merge(Graph_dataset, Rainfall, on="Date")
        
            # peak index_graph_setting
            peak_index = Graph_dataset.Obs.index[Graph_dataset['Obs'] == max(Graph_dataset.Obs)].to_list()

            end_tmp = Graph_dataset.Date[peak_index[0]]
            end_time = pd.to_datetime(end_tmp)
            
            std_tmp = Graph_dataset.Date[peak_index[0]-36]
            std_time = pd.to_datetime(std_tmp)
                        
            self.dt_sce_pc_startTime.setDate(QtCore.QDate(std_time.year, std_time.month, std_time.day))           
            self.dt_sce_pc_startTime.setTime(QtCore.QTime(std_time.hour, std_time.minute, 0))     
            self.dt_sce_pc_endTime.setDate(QtCore.QDate(end_time.year, end_time.month, end_time.day))        
            self.dt_sce_pc_endTime.setTime(QtCore.QTime(end_time.hour, end_time.minute, 0))       

            # combobox
            interval_time = 0
            if (self.rb_sce_pd_interval1.isChecked()):    #30분간격
                interval_time = 30
            elif (self.rb_sce_pd_interval2.isChecked()):  #1시간간격
                interval_time = 60
            elif (self.rb_sce_pd_interval3.isChecked()):  #2시간간격
                interval_time = 120
            else:
                interval_time = 0
            
            # set_performance_check_time_combobox
            diff_date = end_time - std_time
            loof_cnt = int((diff_date.seconds/60) / interval_time)
            now_date = std_time

            while(now_date<=end_time):                
                self.cb_sce_pc_time.addItem(str(now_date)[:-3])
                now_date = now_date + timedelta(minutes=interval_time) 

            if (self.cb_sce_pc_time.count()>0):
                self.cb_sce_pc_time.setCurrentIndex(self.cb_sce_pc_time.count()-1)
                    
            tick_interval = 18
            all_interval = int(math.ceil(len(Graph_dataset)/6/10)*10)            
            start = peak_index[0]-36           
            
            # make img        
            for m in range(start,peak_index[0]+1,3):
                nowtime = m
                
                # make prediction Dataframe
                predict_data = pd.DataFrame()
                for q in range(len(predict_header)):
                    temp_predict_data = Graph_dataset.iloc[nowtime+q+1:nowtime+q+2,[q+2]]
                    temp_predict_data.columns = ['predict_data']
                    predict_data = pd.concat([predict_data,temp_predict_data],axis=0)
                
                # make imagefile (for report)                
                fig= plt.figure(figsize=(14,7))
                gs = gridspec.GridSpec(nrows=3, # row 몇 개 
                                ncols=1, # col 몇 개 
                                height_ratios=[1,4,2])
                ax0 = plt.subplot(gs[0])
                ax0.bar(list(range(nowtime-54,nowtime+1)), Graph_dataset['Rainfall'][nowtime-54:nowtime+1], color = 'cyan', label = 'Observed Water Level')
                ax0.bar(list(range(nowtime+1,nowtime+55)), Graph_dataset['Rainfall'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
                ax0.set_title(self.target_point + '\n' + 'Current time : ' + Graph_dataset['Date'][nowtime].strftime('%Y-%m-%d %H:%M:%S'))

                ax0.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[])
                ax0.set_ylabel('Rainfall(mm)')
                ax0.set_ylim([math.floor(min(Graph_dataset['Rainfall'][:])),math.ceil(max(Graph_dataset['Rainfall'][:]))])
                
                ax1 = plt.subplot(gs[1]) 
                ax1.plot([nowtime-54,nowtime+54],[Watch_level,Watch_level], color = 'yellow', label = 'Flood watch')
                ax1.text(nowtime-44, Watch_level + 0.1, 'Flood watch', ha='center', va='bottom', size = 12)
                ax1.plot([nowtime-54,nowtime+54],[Warning_level,Warning_level], color = 'red', label = 'Flood warning')
                ax1.text(nowtime-44, Warning_level + 0.1, 'Flood warning', ha='center', va='bottom', size = 12)
                ax1.plot(Graph_dataset['Obs'][nowtime-54:nowtime+1], color = 'black', label = 'Observed Water Level')
                ax1.plot(Graph_dataset['Obs'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
                ax1.plot(Graph_dataset['Obs'][nowtime:nowtime+1], color = 'blue', label = 'Observed Water Level', marker= 'o')
                ax1.plot(predict_data, color = 'salmon', label = 'Predicted  Water Level', marker= 'o' )
                
                ax1.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[Graph_dataset['Date'][nowtime-54].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*1].strftime('%m-%d %H:%M'),\
                                                                    Graph_dataset['Date'][nowtime-54+tick_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*3].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][nowtime-54+tick_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][nowtime-54+tick_interval*5].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][nowtime-54+tick_interval*6].strftime('%m-%d %H:%M')] )
                ax1.set_xlabel('Time')
                ax1.set_ylabel('Water Level')
                ax1.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),max(math.ceil(max(Graph_dataset['Obs'][:])),Warning_level+1)])
                
                ax2 = plt.subplot(gs[2]) 
                ax2.plot(Graph_dataset['Obs'][:nowtime+1], color = 'blue', label = 'Observed Water Level')
                ax2.plot(Graph_dataset['Obs'][nowtime+1:], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
                ax2.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),math.ceil(max(Graph_dataset['Obs'][:]))])
                ax2.set_xticks(range(0,all_interval*6+1,all_interval),[Graph_dataset['Date'][0].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*1].strftime('%m-%d %H:%M'),\
                                                                    Graph_dataset['Date'][all_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*3].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][all_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][all_interval*5].strftime('%m-%d %H:%M')\
                                                                    , Graph_dataset['Date'][len(Graph_dataset)-1].strftime('%m-%d %H:%M')])
                ax2.set_ylabel('Water Level')

                date_str = Graph_dataset['Date'][nowtime].strftime('%Y%m%d%H%M%S')  # 문자열 변환 + 원하는 포맷
                safe_date_str = re.sub(r"[^a-zA-Z0-9]", "", date_str)

                plt.savefig(save_path + r'\Prediction_graph_' + f"{0:05d}" + '(' + safe_date_str + ').png')
    
    # [Tab - Scenario Model] : set_performance_check_combobox_event (search, change interval)
    def Set_Scenario_Combobox_PerformanceCheck_Time(self):        
                
        # initialize_control           
        self.cb_sce_pc_time.clear()

        # get_result_file (rf_perfofrmance_check)
        result_file_name = 'Results_'+ str(self.target_point) +'.csv'
        report_path = os.path.join(self.model_root_path ,'report', self.modelFolder[self.SCENARIO], str(self.target_point), result_file_name)
        if os.path.exists(report_path):
            results_data = pd.read_csv(report_path, parse_dates=['Date'])

            Obs_data = results_data.iloc[:,[0,1]]
            Obs_data.columns = ['Date','Obs']

            # make predict data
            predict_header = list(range(10,370,10))
        
            for j in range(len(predict_header)):
                txt_dateCol = '{}min'.format(predict_header[j])         
                txt_predCol = 'Y_pred_{}min'.format(predict_header[j])                                      
                globals()['Pred_{}'.format(str(predict_header[j]))] = results_data.loc[:,[txt_dateCol,txt_predCol]]
                globals()['Pred_{}'.format(str(predict_header[j]))].columns = ['Date', 'Pred_{}'.format(str(predict_header[j]))]
                        
            Rainfall = results_data.loc[:,['Date','Rainfall']]
            Rainfall.columns = ['Date','Rainfall']
        
            for k in range(len(predict_header)):
                if k==0 :
                    Obs_data['Date'] = pd.to_datetime(Obs_data['Date'])
                    eval('Pred_{}'.format(str(predict_header[k])))['Date'] = pd.to_datetime(eval('Pred_{}'.format(str(predict_header[k])))['Date'])

                    Graph_dataset = pd.merge(Obs_data, eval('Pred_{}'.format(str(predict_header[k]))), on='Date')
                else :
                    # 데이터 준비
                    Pred_df = eval('Pred_{}'.format(str(predict_header[k])))

                    # 날짜 타입 맞추기
                    Graph_dataset['Date'] = pd.to_datetime(Graph_dataset['Date'], errors='coerce')
                    Pred_df['Date'] = pd.to_datetime(Pred_df['Date'], errors='coerce')                    
                    Graph_dataset = pd.merge(Graph_dataset,eval('Pred_{}'.format(str(predict_header[k]))), on="Date")
                    
            Graph_dataset = pd.merge(Graph_dataset, Rainfall, on="Date")

            end_tmp = '{}:00'.format(str(self.dt_sce_pc_endTime.text()))
            end_time = pd.to_datetime(end_tmp)
            std_tmp = '{}:00'.format(str(self.dt_sce_pc_startTime.text()))
            std_time = pd.to_datetime(std_tmp)

            if (std_time <= end_time):        

                # combobox
                interval_time = 0
                if (self.rb_sce_pd_interval1.isChecked()):    #30분간격
                    interval_time = 30
                elif (self.rb_sce_pd_interval2.isChecked()):  #1시간간격
                    interval_time = 60
                elif (self.rb_sce_pd_interval3.isChecked()):  #2시간간격
                    interval_time = 120
                else:
                    interval_time = 0
                
                loof_start = std_time
                loof_out = 0

                diff_date = end_time - std_time
                loof_cnt = int((diff_date.seconds/60) / interval_time)
                now_date = std_time
                
                while(now_date<=end_time):                    
                    wl_info = Graph_dataset[Graph_dataset['Date'] == str(now_date)]
                    if not wl_info.empty:
                        self.cb_sce_pc_time.addItem(str(now_date)[:-3])
                    now_date = now_date + timedelta(minutes=interval_time) 

                if (self.cb_sce_pc_time.count()>0):
                    self.cb_sce_pc_time.setCurrentIndex(self.cb_sce_pc_time.count()-1)

    # [Tab - Scenario Model] : set_performance_check_prev_event
    def Draw_Scenario_Graph_PerformanceCheck_Prev(self):
        item_cnt = self.cb_sce_pc_time.count()
        if (item_cnt>0):
            col_idx = self.cb_sce_pc_time.currentIndex()
            if (col_idx == 0): return    
            else:
                self.cb_sce_pc_time.setCurrentIndex(col_idx-1)

    # [Tab - Scenario Model] : set_performance_check_next_event
    def Draw_Scenario_Graph_PerformanceCheck_Next(self):
        item_cnt = self.cb_sce_pc_time.count()
        if (item_cnt>0):
            col_idx = self.cb_sce_pc_time.currentIndex()
            if (col_idx == item_cnt-1): return    
            else:
                self.cb_sce_pc_time.setCurrentIndex(col_idx+1)

    # [Tab - Scenario Model] : draw_performance_check_graph
    def Draw_Scenario_Graph_PerformanceCheck(self):        
                        
        if (self.cb_sce_pc_time.currentText()==''): 
            self.sce_pc_fig.clf()
            self.sce_pc_ax = self.sce_pc_fig.add_subplot(111)
            self.sce_pc_canvas.draw()
            return
        
        # initialize_control   
        self.sce_pc_fig.clf()
        
        # get_targetpoint_info
        target_waterlevel = pd.read_csv(os.path.join(self.obs_root_path, 'target_waterlevel.csv'), date_parser = True)
        target_value = target_waterlevel[target_waterlevel['target_point']==int(self.target_point)]        
        target_name = ''
        Watch_level = 0
        Warning_level = 0
        if not target_value.empty:
            target_name = target_value['target_name'].values[0]   
            Watch_level = target_value['watch_level'].values[0]
            Warning_level = target_value['warning_level'].values[0]

        # get_result_file 
        result_file_name = 'Results_'+ str(self.target_point) +'.csv'
        report_path = os.path.join(self.model_root_path ,'report', self.modelFolder[self.SCENARIO], str(self.target_point), result_file_name)
                
        if os.path.exists(report_path):            
            results_data = pd.read_csv(report_path, parse_dates=['Date'])

            Obs_data = results_data.iloc[:,[0,1]]
            Obs_data.columns = ['Date','Obs']
            
            # make predict data
            predict_header = list(range(10,370,10))
        
            for j in range(len(predict_header)):
                txt_dateCol = '{}min'.format(predict_header[j])         
                txt_predCol = 'Y_pred_{}min'.format(predict_header[j])                           
                globals()['Pred_{}'.format(str(predict_header[j]))] = results_data.loc[:,[txt_dateCol,txt_predCol]]
                globals()['Pred_{}'.format(str(predict_header[j]))].columns = ['Date', 'Pred_{}'.format(str(predict_header[j]))]
                        
            Rainfall = results_data.loc[:,['Date','Rainfall']]
            Rainfall.columns = ['Date','Rainfall']
        
            for k in range(len(predict_header)):
                if k==0 :
                    Obs_data['Date'] = pd.to_datetime(Obs_data['Date'])
                    eval('Pred_{}'.format(str(predict_header[k])))['Date'] = pd.to_datetime(eval('Pred_{}'.format(str(predict_header[k])))['Date'])

                    Graph_dataset = pd.merge(Obs_data, eval('Pred_{}'.format(str(predict_header[k]))), on='Date')
                else :
                    # 데이터 준비
                    Pred_df = eval('Pred_{}'.format(str(predict_header[k])))

                    # 날짜 타입 맞추기
                    Graph_dataset['Date'] = pd.to_datetime(Graph_dataset['Date'], errors='coerce')
                    Pred_df['Date'] = pd.to_datetime(Pred_df['Date'], errors='coerce')
                    
                    Graph_dataset = pd.merge(Graph_dataset,eval('Pred_{}'.format(str(predict_header[k]))), on="Date")
                    
            Graph_dataset = pd.merge(Graph_dataset, Rainfall, on="Date")
        
            # set_combobox - peaktime(end_time)
            end_tmp = '{}:00'.format(str(self.cb_sce_pc_time.currentText()))            
            end_time = pd.to_datetime(end_tmp)
            
            # peak index
            peak_index = Graph_dataset.Date.index[Graph_dataset['Date'] == end_tmp].to_list()

            tick_interval = 18
            all_interval = int(math.ceil(len(Graph_dataset)/6/10)*10)  
            nowtime = peak_index[0]
            
            # make prediction Dataframe
            predict_data = pd.DataFrame()
            for q in range(len(predict_header)):
                temp_predict_data = Graph_dataset.iloc[nowtime+q+1:nowtime+q+2,[q+2]]
                temp_predict_data.columns = ['predict_data']
                predict_data = pd.concat([predict_data,temp_predict_data],axis=0)

            # draw performance_check graph
            gs = gridspec.GridSpec(nrows=3,
                            ncols=1, 
                            height_ratios=[1,4,2])
                       
            # draw - rainfall graph
            self.sce_pc_ax = self.sce_pc_fig.add_subplot(gs[0])
            self.sce_pc_ax.bar(list(range(nowtime-54,nowtime+1)), Graph_dataset['Rainfall'][nowtime-54:nowtime+1], color = 'cyan', label = 'Observed Water Level')
            self.sce_pc_ax.bar(list(range(nowtime+1,nowtime+55)), Graph_dataset['Rainfall'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--")
            #self.sce_pc_ax.set_title('Current time : '+Graph_dataset['Date'][peak_index[0]], size = 6)
            self.sce_pc_ax.set_title('Current time : ' + Graph_dataset['Date'][peak_index[0]].strftime('%Y-%m-%d %H:%M'), size=6)
            self.sce_pc_ax.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[])
            self.sce_pc_ax.set_ylabel('Rainfall(mm)', size = 6)
            self.sce_pc_ax.set_ylim([math.floor(min(Graph_dataset['Rainfall'][:])),math.ceil(max(Graph_dataset['Rainfall'][:]))])
            for tl in self.sce_pc_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)
            
            # draw - predict
            self.sce_pc_ax = self.sce_pc_fig.add_subplot(gs[1])
            self.sce_pc_ax.plot([nowtime-54,nowtime+54],[Watch_level,Watch_level], color = 'yellow', label = 'Flood watch', linewidth=0.8)
            self.sce_pc_ax.text(nowtime-44, Watch_level + 0.1, 'Flood watch', ha='center', va='bottom', size = 6)
            self.sce_pc_ax.plot([nowtime-54,nowtime+54],[Warning_level,Warning_level], color = 'red', label = 'Flood warning', linewidth=0.8)
            self.sce_pc_ax.text(nowtime-44, Warning_level + 0.1, 'Flood warning', ha='center', va='bottom', size = 6)
            self.sce_pc_ax.plot(Graph_dataset['Obs'][nowtime-54:nowtime+1], color = 'black', label = 'Observed Water Level', linewidth=0.8)
            self.sce_pc_ax.plot(Graph_dataset['Obs'][nowtime+1:nowtime+55], color = 'lightgray', label = 'Observed Water Level', linestyle="--", linewidth=0.8)
            self.sce_pc_ax.plot(Graph_dataset['Obs'][nowtime:nowtime+1], color = 'blue', label = 'Observed Water Level', marker= 'o', markersize=1)
            self.sce_pc_ax.plot(predict_data, color = 'salmon', label = 'Predicted  Water Level', marker= 'o', markersize=1)
            self.sce_pc_ax.set_xticks(range(nowtime-54,nowtime+55,tick_interval),[Graph_dataset['Date'][nowtime-54].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*1].strftime('%m-%d %H:%M'),\
                                                Graph_dataset['Date'][nowtime-54+tick_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*3].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][nowtime-54+tick_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][nowtime-54+tick_interval*5].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][nowtime-54+tick_interval*6].strftime('%m-%d %H:%M')] )
            self.sce_pc_ax.set_xticklabels([Graph_dataset['Date'][nowtime-54].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*1].strftime('%m-%d %H:%M'),\
                                                Graph_dataset['Date'][nowtime-54+tick_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][nowtime-54+tick_interval*3].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][nowtime-54+tick_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][nowtime-54+tick_interval*5].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][nowtime-54+tick_interval*6].strftime('%m-%d %H:%M')] , fontsize=5)
            self.sce_pc_ax.set_ylabel('Water Level', size = 6)
            self.sce_pc_ax.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),max(math.ceil(max(Graph_dataset['Obs'][:])),Warning_level+1)])
            for tl in self.sce_pc_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)

            # draw - waterlevel
            self.sce_pc_ax = self.sce_pc_fig.add_subplot(gs[2])
            self.sce_pc_ax.plot(Graph_dataset['Obs'][:nowtime+1], color = 'blue', label = 'Observed Water Level', linewidth=0.8)
            self.sce_pc_ax.plot(Graph_dataset['Obs'][nowtime+1:], color = 'lightgray', label = 'Observed Water Level', linestyle="--", linewidth=0.8)
            self.sce_pc_ax.set_ylim([math.floor(min(Graph_dataset['Obs'][:])),math.ceil(max(Graph_dataset['Obs'][:]))])
            self.sce_pc_ax.set_xticks(range(0,all_interval*6+1,all_interval),[Graph_dataset['Date'][0].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*1].strftime('%m-%d %H:%M'),\
                                                Graph_dataset['Date'][all_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*3].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][all_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][all_interval*5].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][len(Graph_dataset)-1].strftime('%m-%d %H:%M')])
            self.sce_pc_ax.set_xticklabels([Graph_dataset['Date'][0].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*1].strftime('%m-%d %H:%M'),\
                                                Graph_dataset['Date'][all_interval*2].strftime('%m-%d %H:%M'),Graph_dataset['Date'][all_interval*3].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][all_interval*4].strftime('%m-%d %H:%M'), Graph_dataset['Date'][all_interval*5].strftime('%m-%d %H:%M')\
                                                , Graph_dataset['Date'][len(Graph_dataset)-1].strftime('%m-%d %H:%M')], fontsize=5)
            self.sce_pc_ax.set_ylabel('Water Level', size = 6)          
            for tl in self.sce_pc_ax.yaxis.get_majorticklabels():
                tl.set_fontsize(6)    
        
        QTimer.singleShot(100, lambda: self.finalize_plot(self.sce_pc_fig, self.sce_pc_canvas))  
        
    # [Tab - Scenario Model] : save_validation_graph
    def Save_Scenario_ImgValidation_SavePath(self):

        timeText = self.cb_sceValidation.currentText()
        saveFile = '{0}_{1}_{2}_{3}_validation_{4}.png'.format('Scenario', self.year, self.riverRegion, self.target_point, timeText)

        file_path, _ = QFileDialog.getSaveFileName(
            self, 
            "[Dashboard] Save Scenario Validation Image", 
            saveFile,
            "PNG(*.png);;JPEG(*.jpg);;All(*.*)"
        )

        if file_path:
            # save_img
            self.sce_val_fig.savefig(file_path, dpi=500)  
    
    # [Tab - Scenario Model] : save_inference_graph
    def Save_Scenario_ImgInference_SavePath(self):  

        timeText = self.cb_sceInference.currentText()
        saveFile = '{0}_{1}_{2}_{3}_inference_{4}.png'.format('Scenario', self.year, self.riverRegion, self.target_point, timeText)

        file_path, _ = QFileDialog.getSaveFileName(
            self, 
            "[Dashboard] Save Scenario Inference Image", 
            saveFile,
            "PNG(*.png);;JPEG(*.jpg);;All(*.*)"
        )

        if file_path:
            # save_img
            self.sce_inf_fig.savefig(file_path, dpi=500)  
    
    # [Tab - Scenario Model] : save_performancecheck_graph
    def Save_Scenario_ImgPerformanceCheck_SavePath(self):

        timeText = self.cb_sce_pc_time.currentText()
        timeText = timeText.translate(str.maketrans('', '', '- :'))
        saveFile = '{0}_{1}_{2}_{3}_performanceCheck_{4}.png'.format('Scenario', self.year, self.riverRegion, self.target_point, timeText)

        file_path, _ = QFileDialog.getSaveFileName(
            self, 
            "[Dashboard] Save Scenario PerformanceCheck Image", 
            saveFile,
            "PNG(*.png);;JPEG(*.jpg);;All(*.*)"
        )

        if file_path:
            # save_img
            self.sce_pc_fig.savefig(file_path, dpi=500)  

    def create_hwp_report(self, hwp_file_path):

        try:
            import win32com.client
            import pythoncom
            import genpy  # genpy 오류 체크용

            # win32com 캐시 재빌드
            try:
                win32com.client.gencache.is_readonly = False
                win32com.client.gencache.Rebuild()
            except Exception as e:
                print("[HWP] Failed to rebuild win32com cache. ", e)
                QMessageBox.warning(self, 'Dashboard Report', 
                                    "An error occurred while rebuilding the win32com cache. It may be related to a genpy cache issue.", 
                                    QMessageBox.Ok)

            # COM 객체 생성
            try:
                hwp = win32com.client.Dispatch("HWPFrame.HwpObject")
            except pythoncom.com_error as e:
                hr, msg, exc, arg = e.args
                print(f"[HWP] A COM error occurred. HRESULT={hr}, msg={msg}")
                
                if hr == -2147221005:
                    QMessageBox.critical(self, 'Dashboard Report', 
                                        "HWP is not installed, or the COM server is not registered.\n"
                                        "You need to run 'hwp.exe /regserver' with administrator privileges.")
                elif hr == -2147024770:
                    QMessageBox.critical(self, 'Dashboard Report', 
                                        "Python and HWP bit versions do not match. Please check 32/64-bit compatibility.")
                else:
                    QMessageBox.critical(self, 'Dashboard Report', f"An unknown COM error occurred. {msg}")
                return None
            except Exception as e:
                QMessageBox.critical(self, 'Dashboard Report', f"Failed to create HWP object. {e}")
                return None

            # HWP 파일 열기
            try:
                hwp.RegisterModule("FilePathCheckDLL", "FilePathCheckerModule")
                hwp.Open(hwp_file_path, "HWP", "forceopen:true")
                
                '''hwp.XHwpWindows.Item(0).Visible = True
                hwp.RegisterModule("FilePathCheckDLL", "FilePathCheckerModule")
                open_option = "forceopen:true;readonly:false;disablebackup:true"
                hwp.Open(hwp_file_path, "HWP", open_option)'''
                
            except Exception as e:
                QMessageBox.critical(self, 'Dashboard Report', f"Failed to open HWP file. {e}")
                return None
            return hwp

        except ImportError as e:
            QMessageBox.critical(self, 'Dashboard Report', f"The win32com or genpy module is not installed. {e}")
            return None
        except Exception as e:
            QMessageBox.critical(self, 'Dashboard Report', f"An unknown error occurred. {e}")
            return None
        
    def open_hwp(self, file_path, visible=True):
        try:
            # initialize_genpy
            win32.gencache.is_readonly = False
            win32.gencache.Rebuild()
            # 한글 COM 객체 불러오기
            hwp = win32.gencache.EnsureDispatch("HWPFrame.HwpObject")
            # 보안 모듈 등록 (필수)
            hwp.RegisterModule("FilePathCheckDLL", "FilePathCheckerModule")            
            # 파일 열기 (forceopen:true → 강제로 열기 옵션)
            hwp.Open(file_path, "HWP", "forceopen:true")            
            # 창 보이기 / 숨기기
            hwp.XHwpWindows.Item(0).Visible = bool(visible)
            return hwp

        except Exception as e:
            print(f"HWP 열기 실패: {e}")
            return None
    
    # [Export Report] export_report_button_event
    def ExportReport(self):        
                      
        # get_model_type (basic, predict_rainfall, scenario)
        modelIndex = self.tab_models.currentIndex()
        model = self.modelFolder[modelIndex]
        
        # set_report_format(file)_path
        pluginPath = os.path.dirname(__file__)
        report_format_path = pluginPath + "/report_format/result_format_test6.hwp"  
        file = report_format_path   
        if not os.path.isfile(file):
            QMessageBox.warning(self, 'Dashboard Report', "No format file found for report creation.", QMessageBox.Ok)
            return

        # check_hwp_module
        '''import win32com.client as win32
        hwp=win32.gencache.EnsureDispatch("HWPFrame.HwpObject")
        hwp.RegisterModule("FilePathCheckDLL", "FilePathCheckerModule")
        hwp.Open(file,"HWP","forceopen:true")
        hwp.XHwpWindows.Item(0).Visible = True  # True를 입력하면 숨김해제'''

        hwp = self.open_hwp(file, visible=True)
        if hwp is None:
            QMessageBox.warning(self, 'Dashboard Report', "Failed to open HWP. Please check whether Hancom Office HWP is installed or verify the file.", QMessageBox.Ok)
            return 
        
        X_data_training_column_list_index = 9999

        #print('*******************************************Making the result format is starting  : {}'.format(self.target_point))

        # get_model/inference_folder_name
        inference_name = self.inferenceFolder[modelIndex].format(self.target_point) 
        model_name = self.validationFolder[modelIndex].format(self.target_point) 

        # 2022년 기본 Dataset
        datasetFILE_name = 'Dataset_Target_{}_filtered_delete_null.csv'

        # 2022_to_2023_inference_file
        year_inf = '2023'
        if (self.cb_year.count() >= self.cb_year.currentIndex()+1):
            year_inf = self.cb_year.itemText(self.cb_year.currentIndex()+1)

        Dataset_path = os.path.join(self.model_root_path , model, self.year, self.riverRegion, self.target_point,datasetFILE_name.format(self.target_point))

        # 2022년 Model의 parameter.txt 정보
        modelParam_file_path = os.path.join(self.model_root_path , model, self.year, self.riverRegion, self.target_point, model_name,'modelParam.txt')

        # 2022년 관측소별 데이터셋그래프 정보폴더 (현재, basic_model에만 존재함.)
        data_graph_folder_path = os.path.join(self.model_root_path , self.modelFolder[self.BASIC], self.year, self.riverRegion, self.target_point,'graph')

        # 2022년 Model정보
        graph_2022_folder_path = os.path.join(self.model_root_path , model, self.year, self.riverRegion, self.target_point, model_name)
        # 2023년 Model정보
        graph_2023_folder_path = os.path.join(self.model_root_path , model, year_inf, self.riverRegion, self.target_point, model_name)
        # 2022_to_2023 Inference_Model 정보 (2022년 폴더에)
        graph_inference_folder_path = os.path.join(self.model_root_path , model, self.year, self.riverRegion, self.target_point, inference_name)
        # report_생성을위한 performance_check 이미지정보 - root>report>model>self.target_point>images_all folder
        graph_peaktime_folder_path = os.path.join(self.model_root_path , 'report', model, self.target_point, 'images_all')
        graph_leadtime = [60, 120, 180, 240, 300, 360]

        # read_target
        # target_point info (code, name, beginning_date, hydro_model, rating_curve)
        for i in range(0,self.tbl_targetInfo.rowCount(),1):
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "target_code" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = self.target_point 	
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            target_name = self.tbl_targetInfo.item(0, 0).text()
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "target_name" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = target_name
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            target_date = self.tbl_targetInfo.item(0, 1).text()
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "target_date" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = target_date
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            tar_h = self.tbl_targetInfo.item(0, 2).text()
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "tar_h" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = tar_h
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            tar_r = self.tbl_targetInfo.item(0, 3).text()
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "tar_r" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = tar_r
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

        # read modelParam file       
        post_list = [] 
        drop_out_rate = 0
        seq_length = 0
        if not os.path.isfile(modelParam_file_path):
            print ("[Dashboard] Unable to retrieve the parameter information for the model at " + self.target_point + ".")
        else:
            f = open(modelParam_file_path, 'r')
            modelParam_list=f.readlines()

            # search index included in X_data_training_column_list
            for i in range(len(modelParam_list)):  
                if 'X_data_training_column_list' in modelParam_list[i] :
                    X_data_training_column_list_index = i
                if 'Data_X_Column' in modelParam_list[i] :
                    Data_X_Column_index = i
                if 'drop_out_rate' in modelParam_list[i] :
                    drop_out_rate_index = i
                if 'learning_rate' in modelParam_list[i] :
                    learning_rate_index = i
                if 'hidden_layer_unit' in modelParam_list[i] :
                    hidden_layer_unit_index = i
                if 'seq_length' in modelParam_list[i] :
                    seq_length_index = i
                if 'iterations' in modelParam_list[i] :
                    iterations_index = i
                if 'activation_func' in modelParam_list[i] :
                    activation_func_index = i
                if 'hidden_dim' in modelParam_list[i] :
                    hidden_dim_index = i
                if 'validation_rate' in modelParam_list[i] :
                    validation_rate_index = i        
                if 'optimize_func' in modelParam_list[i] :
                    optimize_func_index = i

            f.close()

            Data_X_Column_header = modelParam_list[X_data_training_column_list_index].strip('\n')[modelParam_list[X_data_training_column_list_index].index(',')+1:]
            post_list = eval(Data_X_Column_header)
            Data_X_Column = modelParam_list[Data_X_Column_index].strip('\n')[modelParam_list[Data_X_Column_index].index(',')+1:]
            drop_out_rate = modelParam_list[drop_out_rate_index].strip('\n')[modelParam_list[drop_out_rate_index].index(',')+1:]
            learning_rate = modelParam_list[learning_rate_index].strip('\n')[modelParam_list[learning_rate_index].index(',')+1:]
            hidden_layer_unit = modelParam_list[hidden_layer_unit_index].strip('\n')[modelParam_list[hidden_layer_unit_index].index(',')+1:]
            seq_length = modelParam_list[seq_length_index].strip('\n')[modelParam_list[seq_length_index].index(',')+1:]
            iterations = modelParam_list[iterations_index].strip('\n')[modelParam_list[iterations_index].index(',')+1:]
            activation_func = modelParam_list[activation_func_index].strip('\n')[modelParam_list[activation_func_index].index(',')+1:]
            hidden_dim = modelParam_list[hidden_dim_index].strip('\n')[modelParam_list[hidden_dim_index].index(',')+1:]
            validation_rate = modelParam_list[validation_rate_index].strip('\n')[modelParam_list[validation_rate_index].index(',')+1:]
            optimize_func = modelParam_list[optimize_func_index].strip('\n')[modelParam_list[optimize_func_index].index(',')+1:]

            #print('******************************************* Target info : {}'.format(target_point))            

            ## AI 모형 파라메터 (2022_modelParam)
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "data_x_header" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = Data_X_Column_header
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "data_x_column" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = Data_X_Column
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "value_drop_out_rate" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = drop_out_rate
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "value_learning_rate" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = learning_rate
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "value_hidden_layer_unit" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = hidden_layer_unit
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "value_seq_length" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = seq_length
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "value_iterations" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = iterations
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "value_activation_func" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = activation_func
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "value_hidden_dim" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = hidden_dim
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "value_validation_rate" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = validation_rate
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = "value_optimize_func" 	
            hwp.HParameterSet.HFindReplace.ReplaceString = optimize_func
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

        #print('******************************************* Reference info : {}'.format(target_point))

        # reference_point (code, name, beginning_date, hydro_model, rating_curve)
        for i in range(0,self.tbl_referenceInfo.rowCount(),1):

            x_class_val = self.tbl_referenceInfo.item(i, 1).text()
            if (x_class_val.find('_') > 0):
                x_class_val = x_class_val[0:x_class_val.index('_')]
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = 'x{}_class'.format(i+1) 	
            hwp.HParameterSet.HFindReplace.ReplaceString = x_class_val
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet) 

            x_code_val = self.tbl_referenceInfo.item(i, 2).text() 
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = 'x{}_code'.format(i+1) 	
            hwp.HParameterSet.HFindReplace.ReplaceString = x_code_val
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            x_class_name_val = self.tbl_referenceInfo.item(i, 3).text() 
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = 'x{}_name'.format(i+1) 	
            hwp.HParameterSet.HFindReplace.ReplaceString = x_class_name_val
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            
            x_class_date_val = self.tbl_referenceInfo.item(i, 4).text() 
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = 'x{}_date'.format(i+1) 	
            hwp.HParameterSet.HFindReplace.ReplaceString = x_class_date_val
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            x_class_h_val = self.tbl_referenceInfo.item(i, 5).text() 
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = 'x{}_h'.format(i+1) 	
            hwp.HParameterSet.HFindReplace.ReplaceString = x_class_h_val
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            
            x_class_r_val = self.tbl_referenceInfo.item(i, 6).text() 
            hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            hwp.HParameterSet.HFindReplace.FindString = 'x{}_r'.format(i+1) 	
            hwp.HParameterSet.HFindReplace.ReplaceString = x_class_r_val
            hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
            hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

        # 학습데이터 그래프 : 그래프 이미지(data_graph_x1~data_graph_x18)
        #print('******************************************* Input data graph(2011-2022) : {}'.format(target_point))
        if (len(post_list)>0):
            for i in range(len(post_list)):   
                if not os.path.isfile(os.path.join(data_graph_folder_path,'{}.png'.format(post_list[i]))):
                    print ("[Dashboard] file not found - ", os.path.join(data_graph_folder_path,'{}.png'.format(post_list[i])))
                else:
                    hwp.MoveToField('x{}_data_graph'.format(i+1))
                    hwp.InsertPicture(os.path.join(data_graph_folder_path,'{}.png'.format(post_list[i])), Embedded=True, sizeoption=1) #, Width=90, Height=34)
                    hwp.FindCtrl() # 이미지 속성 처리
                    hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                    hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                    hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                    hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                    hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                    hwp.HParameterSet.HShapeObject.Height = 9496
                    hwp.HParameterSet.HShapeObject.Width = 23810
                    hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)  # 실행

        # NSE 값 
        for j in range(0,36):

            file_2022 = os.path.join(graph_2022_folder_path, 'nse_{}.csv'.format(self.target_point))
            if not os.path.isfile(file_2022):
                print ("[Dashboard] file not found - ", file_2022)
            else:
                hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
                hwp.HParameterSet.HFindReplace.FindString = 'nse_2022_{}0min'.format(j+1) 	
                hwp.HParameterSet.HFindReplace.ReplaceString = round(pd.read_csv(file_2022, date_parser = True).iloc[j,0],5)
                hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
                hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
            
            file_2023 = os.path.join(graph_2023_folder_path, 'nse_{}.csv'.format(self.target_point))
            if not os.path.isfile(file_2023):
                print ("[Dashboard] file not found - ", file_2023)
            else:
                hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
                hwp.HParameterSet.HFindReplace.FindString = 'nse_2023_{}0min'.format(j+1) 	
                hwp.HParameterSet.HFindReplace.ReplaceString = round(pd.read_csv(file_2023, date_parser = True).iloc[j,0],5)
                hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
                hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

            file_inference = os.path.join(graph_inference_folder_path, 'nse_{}.csv'.format(self.target_point))
            if not os.path.isfile(file_inference):
                print ("[Dashboard] file not found - ", file_inference)
            else:
                hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
                hwp.HParameterSet.HFindReplace.FindString = 'nse_inference_{}0min'.format(j+1) 	
                hwp.HParameterSet.HFindReplace.ReplaceString = round(pd.read_csv(file_inference, date_parser = True).iloc[j,0],5)
                hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
                hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

        # AI모형 검증 정확도(2022_model) : 2022모형(graph_2022_60min, 120min, 180min, 240min, 300min, 360min)
        for k in range(len(graph_leadtime)):               
            file_val = os.path.join(graph_2022_folder_path,'prediction_result_{}_after_{}min_drop-out_{}_seq_length_{}.png'.format(model_name,graph_leadtime[k],drop_out_rate,seq_length))
            if not os.path.isfile(file_val):
                print ("[Dashboard] file not found - ", file_val)
            else:   
                hwp.MoveToField('graph_2022_{}min'.format(graph_leadtime[k]))
                hwp.InsertPicture(file_val, Embedded=True, sizeoption=1) 
                hwp.FindCtrl() # 이미지 속성 처리
                hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                hwp.HParameterSet.HShapeObject.Height = 9496
                hwp.HParameterSet.HShapeObject.Width = 23810
                hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)  # 실행

        # AI모형 검증 정확도(2023_model) : 2023모형(graph_2023_60min, 120min, 180min, 240min, 300min, 360min)
        for k in range(len(graph_leadtime)):  
            file_val = os.path.join(graph_2023_folder_path,'prediction_result_{}_after_{}min_drop-out_{}_seq_length_{}.png'.format(model_name,graph_leadtime[k],drop_out_rate,seq_length))
            if not os.path.isfile(file_val):
                print ("[Dashboard] file not found - ", file_val)
            else:  
                hwp.MoveToField('graph_2023_{}min'.format(graph_leadtime[k]))
                hwp.InsertPicture(file_val, Embedded=True, sizeoption=1)
                hwp.FindCtrl() # 이미지 속성 처리
                hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                hwp.HParameterSet.HShapeObject.Height = 9496
                hwp.HParameterSet.HShapeObject.Width = 23810
                hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)  # 실행

        # AI모형 예측 정확도(2022_to_2023_inference) : 2022모형으로 2023년 예측(graph_inference_60min, 120min, 180min, 240min, 300min, 360min)
        for k in range(len(graph_leadtime)):  
            file_inf = os.path.join(graph_inference_folder_path,'predict_result_{}_after_{}min_seq_length_{}.png'.format(model_name,graph_leadtime[k],seq_length))
            if not os.path.isfile(file_inf):
                print ("[Dashboard] file not found - ", file_inf)
            else:  
                hwp.MoveToField('graph_inference_{}min'.format(graph_leadtime[k]))            
                hwp.InsertPicture(file_inf, Embedded=True, sizeoption=1)
                hwp.FindCtrl() # 이미지 속성 처리
                hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                hwp.HParameterSet.HShapeObject.Height = 9496
                hwp.HParameterSet.HShapeObject.Width = 23810
                hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)  # 실행   

        # AI모형 예측 정확도 : 최대홍수사상 peak_time_2023(graph_inference_60min, 120min, 180min, 240min, 300min, 360min)
        if not os.path.exists(graph_peaktime_folder_path):
                print ("[Dashboard] folder not found - ", graph_peaktime_folder_path)
        else:
            lst_peaktimefile = os.listdir(graph_peaktime_folder_path)
            if (len(lst_peaktimefile)>0):
                # peaktime_sort
                lst_peaktime = [file[-19:-5] for file in lst_peaktimefile if file.endswith(".png")]
                peak_text = str(lst_peaktime[len(lst_peaktime)-1])
                time_peak = pd.to_datetime(peak_text)
                time_peak2 = time_peak.strftime("%Y-%m-%d %H:%M")
                str_peaktime = "{0}-{1}-{2} {3}:{4}".format(peak_text[0:4], peak_text[4:2], peak_text[6:2], peak_text[8:2], peak_text[10:2])

                hwp.HAction.GetDefault("AllReplace", hwp.HParameterSet.HFindReplace.HSet)
                hwp.HParameterSet.HFindReplace.FindString = "peak_time_2023" 	
                hwp.HParameterSet.HFindReplace.ReplaceString = time_peak2
                hwp.HParameterSet.HFindReplace.IgnoreMessage = 1 
                hwp.HAction.Execute("AllReplace", hwp.HParameterSet.HFindReplace.HSet)

                for timedata in lst_peaktime:

                    nowtime = pd.to_datetime(timedata)
                    timeText =  timedata                

                    if (nowtime == (time_peak - timedelta(minutes=30)) ):
                        hwp.MoveToField('graph_inference_realtime_0.5hr')          
                        hwp.InsertPicture(os.path.join(graph_peaktime_folder_path,'Prediction_graph_00000({}).png'.format(timeText)), Embedded=True, sizeoption=1)
                        hwp.FindCtrl() # 이미지 속성 처리
                        hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                        hwp.HParameterSet.HShapeObject.Height = 9496
                        hwp.HParameterSet.HShapeObject.Width = 23810
                        hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)

                    elif (nowtime == (time_peak - timedelta(minutes=60)) ):
                        hwp.MoveToField('graph_inference_realtime_1hr')            
                        hwp.InsertPicture(os.path.join(graph_peaktime_folder_path,'Prediction_graph_00000({}).png'.format(timeText)), Embedded=True, sizeoption=1)
                        hwp.FindCtrl() # 이미지 속성 처리
                        hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                        hwp.HParameterSet.HShapeObject.Height = 9496
                        hwp.HParameterSet.HShapeObject.Width = 23810
                        hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)

                    elif (nowtime == (time_peak - timedelta(minutes=120)) ):
                        hwp.MoveToField('graph_inference_realtime_2hr')            
                        hwp.InsertPicture(os.path.join(graph_peaktime_folder_path,'Prediction_graph_00000({}).png'.format(timeText)), Embedded=True, sizeoption=1)
                        hwp.FindCtrl() # 이미지 속성 처리
                        hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                        hwp.HParameterSet.HShapeObject.Height = 9496
                        hwp.HParameterSet.HShapeObject.Width = 23810
                        hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)

                    elif (nowtime == (time_peak - timedelta(minutes=180)) ):
                        hwp.MoveToField('graph_inference_realtime_3hr')            
                        hwp.InsertPicture(os.path.join(graph_peaktime_folder_path,'Prediction_graph_00000({}).png'.format(timeText)), Embedded=True, sizeoption=1)
                        hwp.FindCtrl() # 이미지 속성 처리
                        hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                        hwp.HParameterSet.HShapeObject.Height = 9496
                        hwp.HParameterSet.HShapeObject.Width = 23810
                        hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)

                    elif (nowtime == (time_peak - timedelta(minutes=240)) ):
                        hwp.MoveToField('graph_inference_realtime_4hr')            
                        hwp.InsertPicture(os.path.join(graph_peaktime_folder_path,'Prediction_graph_00000({}).png'.format(timeText)), Embedded=True, sizeoption=1)
                        hwp.FindCtrl() # 이미지 속성 처리
                        hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                        hwp.HParameterSet.HShapeObject.Height = 9496
                        hwp.HParameterSet.HShapeObject.Width = 23810
                        hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)

                    elif (nowtime == (time_peak - timedelta(minutes=300)) ):
                        hwp.MoveToField('graph_inference_realtime_5hr')            
                        hwp.InsertPicture(os.path.join(graph_peaktime_folder_path,'Prediction_graph_00000({}).png'.format(timeText)), Embedded=True, sizeoption=1)
                        hwp.FindCtrl() # 이미지 속성 처리
                        hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                        hwp.HParameterSet.HShapeObject.Height = 9496
                        hwp.HParameterSet.HShapeObject.Width = 23810
                        hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)

                    elif (nowtime == (time_peak - timedelta(minutes=360)) ):
                        hwp.MoveToField('graph_inference_realtime_6hr')            
                        hwp.InsertPicture(os.path.join(graph_peaktime_folder_path,'Prediction_graph_00000({}).png'.format(timeText)), Embedded=True, sizeoption=1)
                        hwp.FindCtrl() # 이미지 속성 처리
                        hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                        hwp.HParameterSet.HShapeObject.Height = 9496
                        hwp.HParameterSet.HShapeObject.Width = 23810
                        hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)

                    elif (nowtime == time_peak ):
                        hwp.MoveToField('graph_inference_realtime_0hr')            
                        hwp.InsertPicture(os.path.join(graph_peaktime_folder_path,'Prediction_graph_00000({}).png'.format(timeText)), Embedded=True, sizeoption=1)
                        hwp.FindCtrl() # 이미지 속성 처리
                        hwp.HAction.GetDefault("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipLeft = 8590
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipRight = 9430
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipTop = 2428
                        hwp.HParameterSet.HShapeObject.ShapeDrawImageAttr.SkipBottom = 376
                        hwp.HParameterSet.HShapeObject.Height = 9496
                        hwp.HParameterSet.HShapeObject.Width = 23810
                        hwp.HAction.Execute("ShapeObjDialog", hwp.HParameterSet.HShapeObject.HSet)

                    else:
                        printdata = ''

        # 시스템 검증 : 시스템 검증 그래프(system_graph)                 
        #hwp.MoveToField('system_graph')
        #hwp.InsertPicture(os.path.join(system_graph_folder_path,'{}.png'.format(target_point)), Embedded=True, sizeoption=1, Height = 59, Width = 170) 

        # 저장 경로 설정
        name = 'result_'+ self.target_point +'.hwp' 
        saveFolderPath = os.path.join(self.model_root_path , 'AI_report', model)

        if not os.path.exists(saveFolderPath):
            os.makedirs(saveFolderPath)

        saveFilePath = os.path.join(saveFolderPath, name)
        hwp.SaveAs(saveFilePath)

# UserControl : Combobox_Search_and_List
class SearchableComboBox(QWidget):

    itemSelected = pyqtSignal(str)  

    def __init__(
        self,
        items,
        max_visible_items=5,
        popup_width=None,
        popup_height=None,
        popup_offset=QPoint(0, 0)  
    ):
        super().__init__()
        self.all_items = items
        self.max_visible_items = max_visible_items
        self.popup_width = popup_width
        self.popup_height = popup_height
        self.popup_offset = popup_offset

        self.button = QPushButton("Please select")        
        self.button.setFixedWidth(200) 
        self.button.clicked.connect(self.toggle_popup)
        self.button.setFixedHeight(31)
        self.button.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)         

        # 팝업 프레임
        self.popup = QFrame(self, Qt.Popup)
        self.popup.setWindowFlags(Qt.Popup)
        popup_layout = QVBoxLayout(self.popup)
        popup_layout.setContentsMargins(0, 0, 0, 0)

        self.search_bar = QLineEdit()
        font = QFont()
        font.setPointSize(9)  
        font.setFamily("돋움")
        self.search_bar.setFont(font)
        self.search_bar.setPlaceholderText("Search Field")
        self.search_bar.textChanged.connect(self.filter_items)
        self.search_bar.setFixedWidth(200) 
        self.search_bar.setFixedHeight(31) 

        self.view = QListView()
        self.model = QStringListModel(self.all_items)
        self.view.setModel(self.model)
        self.view.clicked.connect(self.select_item)

        popup_layout.addWidget(self.search_bar)
        popup_layout.addWidget(self.view)

        layout = QVBoxLayout(self)
        layout.addWidget(self.button)
        self.setLayout(layout)

    def toggle_popup(self):
        if self.popup.isVisible():
            self.popup.hide()
        else:
            self.search_bar.clear()
            self.filter_items("")

            button_pos = self.button.mapToGlobal(QPoint(0, self.button.height()))
            pos = button_pos + self.popup_offset

            item_height = self.view.sizeHintForRow(0) or 20
            search_height = self.search_bar.sizeHint().height()
            default_popup_height = item_height * self.max_visible_items + search_height

            popup_width = self.popup_width or self.button.width()
            popup_height = self.popup_height or default_popup_height

            self.popup.setGeometry(pos.x(), pos.y(), popup_width, popup_height)
            self.view.setMinimumHeight(popup_height - search_height)
            self.view.setMaximumHeight(popup_height - search_height)

            self.popup.show()
            self.search_bar.setFocus()

    def filter_items(self, text):
        filtered = [item for item in self.all_items if text.lower() in item.lower()]
        self.model.setStringList(filtered)

    def get_selected_text(self):
        return self.button.text()
    
    def select_item(self, index):
        selected_text = self.model.stringList()[index.row()]
        self.button.setText(selected_text)
        self.popup.hide()
        self.itemSelected.emit(selected_text)  # 시그널 발생
    
    def set_items(self, new_items):
        self.items = new_items
        self.filtered_items = new_items.copy()
        self.model.setStringList(new_items)
        self.search_box.clear()

    def set_selected_text(self, text):
        if text in self.all_items:
            self.button.setText(text)
            self.itemSelected.emit(text)  # 시그널 발신
        else:
            print(f"[Notice] '{text}' does not exist in the combo box.")

    def set_selected_obs_text(self, text):
        if text in self.all_items:
            self.button.setText(text)
            self.itemSelected.emit(text)  # 시그널 발신
        else:
            print(f"[Notice] '{text}' does not exist in the combo box.")

    def set_selected_sfm_scefolder_text(self, text):
        if text in self.all_items:
            self.button.setText(text)
            self.itemSelected.emit(text)  
        else:
            print(f"[Notice] '{text}' does not exist in the combo box.")

    def reset_items(self, new_items=None):
        if new_items is not None:
            self.all_items = new_items
            self.model.setStringList(new_items)
        else:
            self.all_items = []
            self.model.setStringList([])
        self.search_bar.clear()
        self.button.setText("Please select")

    def get_all_items(self):
        return self.all_items

# Dialog : Create_Database_Tablespace
class CreateTablespace(QDialog):

    def __init__(self, db_config):
        super().__init__()
        # set_plugin_path
        program_path = os.path.dirname(__file__)  
        # 아이콘 설정
        self.setWindowIcon(QIcon(os.path.join(program_path,'icon.png')))

        self.setWindowTitle("Create Database")
        self.setFixedSize(300, 200)
        self.setStyleSheet("background-color: white; font-family: '돋움'; font-size: 9pt;")
        self.db_config = db_config

        # 배경색 흰색
        palette = self.palette()
        palette.setColor(QPalette.Window, QColor("white"))
        self.setPalette(palette)
        self.setAutoFillBackground(True)

        # 라벨 및 입력창
        label = QLabel("Enter the database name.")
        label.setFixedHeight(31)
        self.name_input = QLineEdit()        
        self.name_input.setFixedHeight(31)
        hint_label = QLabel("(*Input must contain only letters, numbers, or underscores (_) without spaces.)")
        hint_label.setFixedHeight(31)

        # 체크박스 추가
        self.predict_checkbox = QCheckBox("Create Prediction Rainfall Table (predict_rain)")
        self.predict_checkbox.setFixedHeight(31)

        # 버튼
        create_btn = QPushButton("Create")
        cancel_btn = QPushButton("Cancel")
        create_btn.setFixedHeight(31)
        cancel_btn.setFixedHeight(31)
        create_btn.clicked.connect(self.create_tablespace)
        cancel_btn.clicked.connect(self.close)

        # 레이아웃
        btn_layout = QHBoxLayout()
        btn_layout.addWidget(create_btn)
        btn_layout.addWidget(cancel_btn)
        btn_layout.setContentsMargins(5, 5, 5, 5)

        main_layout = QVBoxLayout()
        main_layout.setContentsMargins(5, 5, 5, 5)  
        main_layout.addWidget(label)
        main_layout.addWidget(self.name_input)
        main_layout.addWidget(hint_label)
        main_layout.addWidget(self.predict_checkbox)
        main_layout.addLayout(btn_layout)
        self.setLayout(main_layout)

    def get_text(self):
        return self.name_input.text().strip()
    
    def check_database_exists(self, db_name):        
        try:
            import mariadb    
            conn = mariadb.connect(**self.db_config)
            with conn.cursor() as cur:
                cur.execute(f"SHOW DATABASES LIKE %s", (db_name,))
                result = cur.fetchone()
                return result is not None  
        finally:
            conn.close()

    def create_tablespace(self):
        name = self.get_text()

        # 유효성 검사
        if not name:
            QMessageBox.warning(self, "Create Database", "Please enter a name.")
            return
        if not re.fullmatch(r'[a-zA-Z0-9_]+', name):
            QMessageBox.warning(self, "Create Database", "Input can contain only letters, numbers, or underscores(_).")
            return
        
        if self.check_database_exists(name):
            QMessageBox.warning(self, "Create Database", f"'{name}' database already exists.")
            self.name_input.clear()
            return
        
        try:
            import mariadb
            conn = mariadb.connect(**self.db_config)
            cur = conn.cursor()

            # 데이터베이스 생성 
            sql = f"CREATE DATABASE IF NOT EXISTS `{name}`"
            cur.execute(sql)

            # 기본 테이블 생성
            tablenames = [
                'waterlevel', 'rainfall', 'discharge',
                'daminlet', 'damrelease', 'tidelevel', 'watershed'
            ]

            for tablename in tablenames:
                sql_create = f"""CREATE TABLE `{name}`.`{tablename}` (
                    `OBS_ID` VARCHAR(50) NOT NULL COLLATE 'latin1_swedish_ci',
                    `DT_DATE` DATETIME NOT NULL,
                    `DT_DATA` FLOAT NULL DEFAULT NULL,
                    `MI_DATA` FLOAT NULL DEFAULT NULL,
                    `OI_DATA` FLOAT NULL DEFAULT NULL,
                    PRIMARY KEY (`OBS_ID`, `DT_DATE`) USING BTREE
                )
                COLLATE='latin1_swedish_ci'
                ENGINE=InnoDB;"""
                cur.execute(sql_create)

             # 예측강우 테이블 생성 (체크박스 선택 시)
            if self.predict_checkbox.isChecked():
                # RF1 ~ RF36 컬럼 생성
                rf_columns = ",\n".join([f"`RF{i}` FLOAT NULL DEFAULT NULL" for i in range(1, 37)])

                sql_create_predict = f"""CREATE TABLE `{name}`.`predict_rain` (
                    `OBS_ID` VARCHAR(50) NOT NULL COLLATE 'latin1_swedish_ci',
                    `DT_DATE` DATETIME NOT NULL,
                    {rf_columns},
                    PRIMARY KEY (`OBS_ID`, `DT_DATE`) USING BTREE
                )
                COLLATE='latin1_swedish_ci'
                ENGINE=InnoDB;"""
                cur.execute(sql_create_predict)

            cur.close()
            conn.close()

            self.accept()

        except mariadb.Error as e:
            QMessageBox.critical(self, "Create Database", f"Error occurred.\n{e}")
            self.reject()

# Dialog : Select_Shapefile
class FileSelectDialog(QDialog):

    def __init__(self):
        super().__init__()
        # set_plugin_path
        program_path = os.path.dirname(__file__)  
        # 아이콘 설정
        self.setWindowIcon(QIcon(os.path.join(program_path,'icon.png')))

        self.setWindowTitle("Layer Settings")
        self.resize(600, 400)
       
        self.setStyleSheet("background-color: white; font-family: '돋움'; font-size: 9pt;")

        # 경로입력 + 파일선택
        self.path_edit = QLineEdit(self)
        self.path_edit.setFixedHeight(31)
        self.path_edit.setReadOnly(True)
        self.select_button = QPushButton("Select File")
        self.select_button.setFixedHeight(31)
        self.select_button.clicked.connect(self.select_file)

        path_layout = QHBoxLayout()
        path_layout.addWidget(QLabel("Layer Path : "))
        path_layout.addWidget(self.path_edit)
        path_layout.addWidget(self.select_button)

        # 콤보박스
        self.combo = QComboBox()
        self.combo.setFixedHeight(31)
        combo_layout = QHBoxLayout()
        self.combo.setStyleSheet("color: black; background-color: white; font-family: '돋움'; font-size: 9pt;")
        combo_layout.addWidget(QLabel("Station Code : "))
        combo_layout.addWidget(self.combo)

        # QTableWidget - 필드+타입+샘플값
        self.table_widget = QTableWidget()
        
        # 적용/취소
        self.ok_button = QPushButton("Apply")
        self.cancel_button = QPushButton("Cancel")
        self.ok_button.setFixedHeight(31)
        self.cancel_button.setFixedHeight(31)
        self.ok_button.clicked.connect(self.accept)
        self.cancel_button.clicked.connect(self.reject)

        btn_layout = QHBoxLayout()
        btn_layout.addStretch()
        btn_layout.addWidget(self.ok_button)
        btn_layout.addWidget(self.cancel_button)

        # 전체 레이아웃
        main_layout = QVBoxLayout()
        main_layout.addLayout(path_layout)
        main_layout.addLayout(combo_layout)
        main_layout.addWidget(self.table_widget)
        main_layout.addLayout(btn_layout)

        self.setLayout(main_layout)

    def select_file(self):

        file_path, _ = QFileDialog.getOpenFileName(self, "Select File", "", "ShapeFile(*.shp)")

        if file_path:
            self.path_edit.setText(file_path)
            self.combo.clear()
            self.table_widget.setColumnCount(3)
            self.table_widget.setHorizontalHeaderLabels(["Field Name", "Data Type", "Sample Data"])
            self.table_widget.setRowCount(0)

            layer = QgsVectorLayer(file_path, "MyLayer", "ogr")
            if not layer.isValid():
                self.table_widget.setRowCount(1)
                self.table_widget.setItem(0, 0, QTableWidgetItem("Failed to load layer"))
                self.table_widget.setItem(0, 1, QTableWidgetItem(""))
                self.table_widget.setItem(0, 2, QTableWidgetItem(""))
                return

            fields = layer.fields()
            features = layer.getFeatures()
            first_feature = next(features, None)

            self.table_widget.setRowCount(len(fields))
            for i, field in enumerate(fields):
                field_name = field.name()
                field_type = field.typeName()
                sample_val = str(first_feature[field.name()]) if first_feature else ""

                self.combo.addItem(field_name)

                # 1번째 컬럼 - 가운데 정렬
                item = QTableWidgetItem(field_name)
                item.setTextAlignment(Qt.AlignCenter)
                self.table_widget.setItem(i, 0, item)

                # 2번째 컬럼 - 가운데 정렬
                item = QTableWidgetItem(field_type)
                item.setTextAlignment(Qt.AlignCenter)
                self.table_widget.setItem(i, 1, item)

                # 3번째 컬럼 - 왼쪽 정렬 + 수직 가운데 정렬
                item = QTableWidgetItem(sample_val)
                item.setTextAlignment(Qt.AlignLeft | Qt.AlignVCenter)
                self.table_widget.setItem(i, 2, item)

            # 행 번호(Vertical Header) 숨기기
            self.table_widget.verticalHeader().setVisible(False)

            # 컬럼 너비 자동 조절 (Stretch)
            header = self.table_widget.horizontalHeader()
            header.setSectionResizeMode(QHeaderView.Stretch)

    def get_result(self):
        return self.path_edit.text(), self.combo.currentText()   

# Dialog : Set_Database_Connection_info
class MariaDBConfigDialog(QtWidgets.QDialog):
    def __init__(self, user, password, host, port, parent=None):
        super().__init__(parent)
        self.setWindowTitle("MariaDB Connection Settings")
        self.setFixedSize(350, 180)        
        self.setStyleSheet("background-color: white; font-family: '돋움'; font-size: 9pt;")

        # 폼 레이아웃
        form_layout = QtWidgets.QFormLayout()

        # 입력 필드 (외부에서 받은 값 세팅)
        self.user_edit = QtWidgets.QLineEdit(user)
        self.password_edit = QtWidgets.QLineEdit(password)
        self.host_edit = QtWidgets.QLineEdit(host)
        self.port_edit = QtWidgets.QLineEdit(str(port))

        # 폼에 추가
        form_layout.addRow("User :", self.user_edit)
        form_layout.addRow("Password :", self.password_edit)
        form_layout.addRow("Host/IP :", self.host_edit)
        form_layout.addRow("Port :", self.port_edit)

        # 버튼 박스 (확인 / 취소)
        button_box = QtWidgets.QDialogButtonBox(
            QtWidgets.QDialogButtonBox.Ok | QtWidgets.QDialogButtonBox.Cancel
        )
        button_box.accepted.connect(self.accept)
        button_box.rejected.connect(self.reject)

        # 메인 레이아웃
        main_layout = QtWidgets.QVBoxLayout()
        main_layout.addWidget(QtWidgets.QLabel("Configure the MariaDB connection information."))
        main_layout.addLayout(form_layout)
        main_layout.addWidget(button_box)
        self.setLayout(main_layout)

    def get_config(self):
        return {
            "user": self.user_edit.text(),
            "password": self.password_edit.text(),
            "host": self.host_edit.text(),
            "port": int(self.port_edit.text()) if self.port_edit.text().isdigit() else 3306
        }

# 데이터임포트
class DataImporter(QThread):

    fileProgressChanged = pyqtSignal(int)
    allProgressChanged = pyqtSignal(int)
    statusMessage = pyqtSignal(str)
    finishedSignal = pyqtSignal()
    
    fileChanged = pyqtSignal(str)           
    errorOccured = pyqtSignal(str)          

    def __init__(self, file_list, options, parent=None):
        super().__init__(parent)
        self.file_list = file_list
        self.options = options
        self._is_running = True

        self.strTableNm = options['table_nm']
        self.isUpdate = options['is_update']
        self.bRemoveOutlier = options['remove_outlier']
        self.bRemoveMissingVAL = options['fill_missing']
        self.bSaveFile = options['save_file']
        self.bSaveDbImport = options['save_db']
        self.db_config = options['db_config']
        self.db_tablespace = options['tablespace']
        self.dirPath = options['save_dir']    

    def stop(self):
        self._is_running = False        

    def run(self):

        total_files = len(self.file_list)
        error_messages = []  

        try:
            for idx, file_info in enumerate(self.file_list):
                
                self.fileProgressChanged.emit(0)

                if not self._is_running:
                    break

                file_path = file_info['path']
                strObsId = os.path.splitext(os.path.basename(file_path))[0]

                self.fileChanged.emit(f"Processing [{idx+1}/{total_files}] {strObsId}...")
                self.statusMessage.emit(f"Processing [{idx+1}/{total_files}] {strObsId}...")

                try:
                    # 테이블별 처리
                    # 강우와 유역평균강우의 자료는 이상치제거와 결측치보정없이 DB에 임포트(Import)한다.
                    # 강우는 원본파일에서 결측치보정한 파일을 저장한 후, 사용자가 수기로 이상치제거작업을 하여 임포트한다.
                    # 유역평균강우는 품질관리를 위한 전처리 작업에 대한 자료가 불명확하여 사용자가 수기로 작업하여 임포트한다.
                    # 유역실제강우도 원본그대로 임포트한다.
                    # Null값을 0으로 (수위제외, 유량/조위/댑유입량/댐방류량/강우)
                    if self.strTableNm == "rainfall":
                        df = pd.read_csv(file_path, header=None)

                        # check_file 
                        df_col = df.shape[1]

                        # 데이터가 모두 있을경우, (date, dt_data, mi_data, oi_data)
                        if (df_col==4):
                            target_cols = df.columns[1:4]
                            # 오류값 → NaN 치환
                            df[target_cols] = df[target_cols].replace(["", " ", "nan", "NaN", None], pd.NA)
                            # 숫자로 변환 (변환 불가한 값은 NaN 처리됨)
                            df[target_cols] = df[target_cols].apply(pd.to_numeric, errors="coerce")
                            # 최종적으로 NaN → None (DB NULL로 들어가게)
                            df[target_cols] = df[target_cols].where(pd.notna(df[target_cols]), None)        
                            pd_final = df.copy()
                        else: 
                            DATA_QM = DataQualityManagement(file_path)
                            pd_final = self._process_quality(DATA_QM, strObsId)

                        self.fileProgressChanged.emit(50)            
                        all_progress = int(((idx + 50 / 100.0) / total_files) * 100)
                        self.allProgressChanged.emit(all_progress)

                    elif self.strTableNm == "watershed":

                        df = pd.read_csv(file_path, header=None)

                        # check_file 
                        df_col = df.shape[1]

                        # 데이터가 모두 있을경우, (date, dt_data, mi_data, oi_data)
                        if (df_col==4):
                            target_cols = df.columns[1:4]
                            # 오류값 → NaN 치환
                            df[target_cols] = df[target_cols].replace(["", " ", "nan", "NaN", None], pd.NA)
                            # 숫자로 변환 (변환 불가한 값은 NaN 처리됨)
                            df[target_cols] = df[target_cols].apply(pd.to_numeric, errors="coerce")
                            # 최종적으로 NaN → None (DB NULL로 들어가게)
                            df[target_cols] = df[target_cols].where(pd.notna(df[target_cols]), None)
                            pd_final = df.copy()
                        else: 
                            DATA_QM = DataQualityManagement(file_path)
                            pd_final = self._process_quality(DATA_QM, strObsId)

                        self.fileProgressChanged.emit(50)            
                        all_progress = int(((idx + 50 / 100.0) / total_files) * 100)
                        self.allProgressChanged.emit(all_progress)

                    elif self.strTableNm == "predict_rain":
                        df = pd.read_csv(file_path, header=0, encoding="utf-8-sig")
                        pd_final = df.copy()
                        self.fileProgressChanged.emit(50)            
                        all_progress = int(((idx + 50 / 100.0) / total_files) * 100)
                        self.allProgressChanged.emit(all_progress)

                    else:
                        df = pd.read_csv(file_path, header=None)

                        # check_file 
                        df_col = df.shape[1]

                        # 데이터가 모두 있을경우, (date, dt_data, mi_data, oi_data)
                        if (df_col==4):
                            target_cols = df.columns[1:4]
                            # 오류값 → NaN 치환
                            df[target_cols] = df[target_cols].replace(["", " ", "nan", "NaN", None], pd.NA)
                            # 숫자로 변환 (변환 불가한 값은 NaN 처리됨)
                            df[target_cols] = df[target_cols].apply(pd.to_numeric, errors="coerce")
                            # 최종적으로 NaN → None (DB NULL로 들어가게)
                            df[target_cols] = df[target_cols].where(pd.notna(df[target_cols]), None)
                            pd_final = df.copy()

                        else: 
                            DATA_QM = DataQualityManagement(file_path)
                            pd_final = self._process_quality(DATA_QM, strObsId)
                        
                        self.fileProgressChanged.emit(50)                        
                        all_progress = int(((idx + 50 / 100.0) / total_files) * 100)
                        self.allProgressChanged.emit(all_progress)

                    # 파일 저장
                    if self.bSaveFile:
                        saveFilePath = os.path.join(self.dirPath, os.path.basename(file_path))
                        pd.DataFrame(pd_final).to_csv(saveFilePath, header=False, index=False)
                        self.statusMessage.emit(f"{strObsId} file saved successfully.")
                        self.fileProgressChanged.emit(60)                        
                        all_progress = int(((idx + 60 / 100.0) / total_files) * 100)
                        self.allProgressChanged.emit(all_progress)

                    # DB 저장
                    if self.bSaveDbImport:
                        db_err = self.saveToDatabase(pd_final, strObsId)
                        if db_err:
                            error_messages.append(db_err)  
                        self.fileProgressChanged.emit(95)
                        all_progress = int(((idx + 95 / 100.0) / total_files) * 100)
                        self.allProgressChanged.emit(all_progress)

                    
                    self.fileProgressChanged.emit(100)

                except Exception as e:
                    msg = f"Failed to process {strObsId}. {str(e)}"
                    self.statusMessage.emit(f"[ERROR] {msg}")
                    error_messages.append(msg)     
                    continue

                # 진행률 업데이트
                all_progress = int((idx + 1) / total_files * 100)
                self.allProgressChanged.emit(all_progress)

            # 모든 파일 처리 완료 후 메시지
            if error_messages:
                final_msg = "An error occurred during processing.\n\n" + "\n".join(error_messages)
                self.errorOccured.emit(final_msg)
            else:
                self.statusMessage.emit("All files processed successfully.")

            self.finishedSignal.emit()

        except Exception as e:
            msg = str(e)
            self.statusMessage.emit(f"[DataImport] {msg}")
            self.errorOccured.emit(msg)
            self.finishedSignal.emit()    

    def _process_quality(self, DATA_QM, strObsId):

        pd_step = None  # 원시데이터의 전처리 (DATE 시간표기변경:2400_to_0000, DATA콤마제거, 날짜누락보간, 중복DATA제거)
        pd_data = None  # 원시데이터
        pd_out = None   # 이상치데이터
        pd_null = None  # 결측치데이터

        try:
            # 1. 작업진행            
            try:
                # INITIALIZE_FILE 호출, 필요한 인자 전달
                pd_step = DATA_QM.INITIALIZE_FILE(time_step_minutes=10)
                self.fileProgressChanged.emit(20)            
            except Exception as e:
                raise RuntimeError(f"Error at {strObsId} stage INITIALIZE_FILE {str(e)}")

            # interpolation / outlier / null 처리
            try:
                # 강우데이터, 컬럼이 4개면 그대로 사용하고 그 이하일때는 기존방식대로 적용한다.
                # 기존방식 - 결측치체크시(원천/결측/결측), 결측치미체크시(원천/원천/원천)
                # 강우데이터는 이상치제거를 사용자가 진행하므로 옵션은 없다.
                if self.strTableNm == "rainfall":

                    # 결측치 체크
                    if self.bRemoveMissingVAL:

                        # 마이너스값 0으로 변경 (수위제외, 유량/조위/댑유입량/댐방류량) - 데이터컬럼상관없음(전체적용)
                        pd_minus = DATA_QM.MINUS_TO_ZERO(pd_step)

                        # 3시간 선형보간
                        pd_interp = pd_minus.copy()
                        pd_step_col = pd_step.shape[1]
                        if pd_step_col == 2:    # date, dt_data
                            col_data = pd_minus.iloc[:, [0, 1]]  # Series
                            pd_interp = DATA_QM.THREEHR_INTERPOLATION(col_data)
                        elif pd_step_col == 3:  # date, dt_data, mi_data
                            col_data = pd_minus.iloc[:, [0, 2]]  # Series
                            pd_interp = DATA_QM.THREEHR_INTERPOLATION(col_data)

                        # Null값을 0으로 (수위제외, 유량/조위/댑유입량/댐방류량)
                        pd_null = DATA_QM.NULL_TO_ZERO(pd_interp)                     
                        pd_out = pd_null.copy()
                    
                    # 결측치 체크안했을경우, 원천/원천/원천
                    else:
                        # 데이터정제할 컬럼 정리
                        pd_step_col = pd_step.shape[1]
                        if pd_step_col == 2:    # date, dt_data
                            pd_out, pd_null = pd_step.copy(), pd_step.copy()
                        elif pd_step_col == 3:  # date, dt_data, mi_data
                            col_data = pd_step.iloc[:, [0, 2]] 
                            pd_out, pd_null = col_data, col_data
                                          
                # 수위데이터, 컬럼이 4개면 그대로 사용하고 그 이하일때는 기존방식대로 적용한다.
                # 마이너스값과 Null값에 대한 처리는 하지 않는다.
                # Null값을 처리안함 (pd_3hrInterpolation = mi_data)
                elif self.strTableNm == "waterlevel":           

                    # 3시간 선형보간
                    pd_interp = pd_step.copy()  
                    pd_step_col = pd_step.shape[1]
                    if self.bRemoveMissingVAL or self.bRemoveOutlier:
                        if pd_step_col == 2:    # date, dt_data                            
                            col_data = pd_step.iloc[:, [0, 1]]  # Series
                            pd_interp = DATA_QM.THREEHR_INTERPOLATION(col_data)
                        elif pd_step_col == 3:  # date, dt_data, mi_data                      
                            col_data = pd_step.iloc[:, [0, 2]]  # Series                          
                            pd_interp = DATA_QM.THREEHR_INTERPOLATION(col_data)
                    else:
                        if pd_step_col == 2:    # date, dt_data      
                            col_data = pd_step.iloc[:, [0, 1]]                 
                            pd_interp = col_data
                        elif pd_step_col == 3:  # date, dt_data, mi_data        
                            col_data = pd_step.iloc[:, [0, 2]]                           
                            pd_interp = col_data

                    # 결측치체크
                    if not self.bRemoveMissingVAL:         
                        if pd_step_col == 2:    # date, dt_data      
                            col_data = pd_step.iloc[:, [0, 1]]                 
                            pd_interp = col_data
                        elif pd_step_col == 3:  # date, dt_data, mi_data        
                            col_data = pd_step.iloc[:, [0, 2]]                           
                            pd_interp = col_data

                    pd_null = pd_interp

                    # 이상치 보간
                    pd_out = pd_step.copy()  
                    if self.bRemoveOutlier:
                        pd_out = DATA_QM.REMOVE_OUTLIER(pd_interp)
                    else:                            
                        if pd_step_col == 2:    # date, dt_data      
                            col_data = pd_step.iloc[:, [0, 1]]                 
                            pd_out = col_data
                        elif pd_step_col == 3:  # date, dt_data, mi_data        
                            col_data = pd_step.iloc[:, [0, 2]]                           
                            pd_out = col_data

                # 그 외 데이터의 경우, 원래대로 적용한다.
                else:                                        
                    pd_interp = pd_step.copy()  
                    pd_step_col = pd_step.shape[1]
                    if self.bRemoveMissingVAL or self.bRemoveOutlier:

                        # 마이너스값 0으로 변경 (수위제외, 유량/조위/댑유입량/댐방류량) - 데이터컬럼상관없음(전체적용)
                        pd_minus = DATA_QM.MINUS_TO_ZERO(pd_step)

                        # 3시간 선형보간
                        if pd_step_col == 2:    # date, dt_data                            
                            col_data = pd_minus.iloc[:, [0, 1]]  # Series
                            pd_interp = DATA_QM.THREEHR_INTERPOLATION(col_data)
                        elif pd_step_col == 3:  # date, dt_data, mi_data                      
                            col_data = pd_minus.iloc[:, [0, 2]]  # Series                          
                            pd_interp = DATA_QM.THREEHR_INTERPOLATION(col_data)
                    else:
                        if pd_step_col == 2:    # date, dt_data      
                            col_data = pd_step.iloc[:, [0, 1]]                 
                            pd_interp = col_data
                        elif pd_step_col == 3:  # date, dt_data, mi_data        
                            col_data = pd_step.iloc[:, [0, 2]]                           
                            pd_interp = col_data

                    # 결측치체크
                    if self.bRemoveMissingVAL:  
                        pd_null = DATA_QM.NULL_TO_ZERO(pd_interp)                           
                    else:       
                        if pd_step_col == 2:    # date, dt_data      
                            col_data = pd_step.iloc[:, [0, 1]]                 
                            pd_interp = col_data
                        elif pd_step_col == 3:  # date, dt_data, mi_data        
                            col_data = pd_step.iloc[:, [0, 2]]                           
                            pd_interp = col_data
                        pd_null = pd_interp

                    # 이상치 보간
                    pd_out = pd_step.copy()  
                    if self.bRemoveOutlier:
                        pd_out = DATA_QM.REMOVE_OUTLIER(pd_interp)
                    else:                            
                        if pd_step_col == 2:    # date, dt_data      
                            col_data = pd_step.iloc[:, [0, 1]]                 
                            pd_out = col_data
                        elif pd_step_col == 3:  # date, dt_data, mi_data        
                            col_data = pd_step.iloc[:, [0, 2]]                           
                            pd_out = col_data                

            except Exception as e:
                raise RuntimeError(f"Error processing Outlier/Interpolation for {strObsId}. {str(e)}")

            self.fileProgressChanged.emit(40)

            # combine
            try:
                pd_data = pd_step.iloc[:, [0, 1]]   
                pd_final = DATA_QM.COMBINE_DATA(pd_data, pd_null, pd_out)
            except Exception as e:
                raise RuntimeError(f"Error merging data for {strObsId}. {str(e)}")

            self.fileProgressChanged.emit(45)
            return pd_final

        except Exception as e:
            self.statusMessage.emit(str(e))            
            return pd_step if pd_step is not None else pd.DataFrame()

    def saveToDatabase(self, pd_final, strObsId):
        
        import os
        import tempfile
        import mariadb
        import pandas as pd

        conn = None
        tmpfile_name = None
        error_msg = None
        try:
            conn = mariadb.connect(
                user=self.db_config['user'],
                password=self.db_config['password'],
                host=self.db_config['host'],
                port=self.db_config.get('port', 3306),
                database=self.db_config['database'],
                local_infile=True
            )
            cur = conn.cursor()

            # date_format 처리
            pd_final.iloc[:,0] = pd_final.iloc[:,0].astype(str)
            converted = []

            # 지원할 포맷 리스트 (필요시 추가 가능)
            formats = [
                '%Y-%m-%d %H:%M:%S',
                '%Y/%m/%d %H:%M:%S',
                '%Y%m%d%H%M',
                '%Y%m%d%H%M%S',
                '%Y-%m-%d %H:%M',
                '%Y/%m/%d %H:%M',
                '%Y-%m-%d',
                '%Y/%m/%d',
                '%Y-%m-%d  %I:%M:%S %p', # 2025-08-01 12:00:00 AM
                '%m/%d/%Y %I:%M %p',     # 08/01/2025 12:00 PM
                '%d-%b-%Y %H:%M',        # 01-Aug-2025 12:00
                '%d-%b-%Y %I:%M:%S %p',  # 01-Aug-2025 12:00:00 PM    
            ]

            invalid_rows = []

            for val in pd_final.iloc[:,0]:
                dt = pd.NaT
                # 1. 여러 포맷 순서대로 시도
                for fmt in formats:
                    try:
                        dt = pd.to_datetime(val, format=fmt, errors='raise')
                        break
                    except:
                        continue
                # 2. 모든 포맷 실패 시 parser.parse 사용
                if pd.isna(dt):
                    try:
                        dt = parser.parse(val)
                    except Exception:
                        dt = pd.NaT

                if pd.isna(dt):
                    invalid_rows.append(val)

                converted.append(dt)

            # Series로 변환 후 강제로 datetime 타입 지정
            converted = pd.to_datetime(pd.Series(converted), errors='coerce')

            # 변환 실패 체크
            if converted.isna().any():
                invalid_rows = pd_final.iloc[converted.isna(), 0].tolist()
                raise RuntimeError(f"Invalid date values found for {strObsId} → DB save aborted.\nInvalid rows: {invalid_rows}")

            # 최종 포맷 적용
            if self.strTableNm == "predict_rain":
                target_format = '%Y-%m-%d %H:%M:%S'
            else:
                target_format = '%Y%m%d%H%M'

            pd_final.iloc[:,0] = converted.dt.strftime(target_format)

            # predict_rain 처리
            if self.strTableNm == "predict_rain":
                df = pd_final.copy()
                columns = ["DT_DATE"] + [f"RF{i}" for i in range(1, 37)]
                n_expected = len(columns)
                n_actual = df.shape[1]

                # 컬럼 개수 불일치 시 처리 중단
                if n_actual != n_expected:
                    raise RuntimeError(
                        f"Column count mismatch in predict_rain for {strObsId} : "
                        f"Expected: {n_expected}, Actual: {n_actual}"
                    )

                # 정상일 때만 컬럼명 적용
                df.columns = columns
                df = df.replace(["", "nan", "NaN", None], pd.NA)

                tmpfile = tempfile.NamedTemporaryFile(delete=False, suffix=".csv", mode="w", encoding="utf-8")
                tmpfile_name = tmpfile.name
                df.to_csv(tmpfile.name, index=False, header=False, na_rep="\\N")
                tmpfile.close()
                file_path = tmpfile.name.replace("\\", "/")

                tmp_table = "predict_rain_tmp"
                try:
                    cur.execute(f"DROP TEMPORARY TABLE IF EXISTS {tmp_table}")
                    rf_columns_sql = ", ".join([f"RF{i} DOUBLE NULL" for i in range(1, 37)])
                    cur.execute(f"""
                        CREATE TEMPORARY TABLE {tmp_table} (
                            DT_DATE VARCHAR(20),
                            {rf_columns_sql}
                        )
                    """)
                    self.fileProgressChanged.emit(65)
                except Exception as e:
                    raise RuntimeError(f"Error creating temporary table for {strObsId} : {str(e)}")

                try:
                    load_sql = f"""
                    LOAD DATA LOCAL INFILE '{file_path}'
                    INTO TABLE {tmp_table}
                    FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
                    LINES TERMINATED BY '\n'
                    ({', '.join(columns)})
                    """
                    cur.execute(load_sql)
                    self.fileProgressChanged.emit(80)
                except Exception as e:
                    raise RuntimeError(f"LOAD DATA error for {strObsId} : {str(e)}")

                try:
                    rf_columns = ", ".join([f"RF{i}" for i in range(1, 37)])
                    rf_values = ", ".join([f"VALUES(RF{i})" for i in range(1, 37)])
                    if self.isUpdate:
                        merge_sql = f"""
                        INSERT INTO predict_rain (OBS_ID, DT_DATE, {rf_columns})
                        SELECT '{strObsId}', STR_TO_DATE(DT_DATE, '%Y-%m-%d %H:%i:%s'), {rf_columns}
                        FROM {tmp_table}
                        ON DUPLICATE KEY UPDATE
                            {', '.join([f"RF{i}={rf_values.split(', ')[i-1]}" for i in range(1, 37)])}
                        """
                    else:
                        merge_sql = f"""
                        INSERT IGNORE INTO predict_rain (OBS_ID, DT_DATE, {rf_columns})
                        SELECT '{strObsId}', STR_TO_DATE(DT_DATE, '%Y-%m-%d %H:%i:%s'), {rf_columns}
                        FROM {tmp_table}
                        """
                    cur.execute(merge_sql)
                    self.fileProgressChanged.emit(95)
                except Exception as e:
                    raise RuntimeError(f"Database merge error for {strObsId} : {str(e)}")

            # rainfall, watershed, waterlevel
            else:
                df = pd_final.copy()
                if df.shape[1] == 2:
                    df.columns = ["DT_DATE", "DT_DATA"]
                    df["MI_DATA"] = df["DT_DATA"]
                    df["OI_DATA"] = df["DT_DATA"]
                elif df.shape[1] == 4:
                    df.columns = ["DT_DATE", "DT_DATA", "MI_DATA", "OI_DATA"]
                    '''if not self.bRemoveOutlier:
                        df["OI_DATA"] = df["DT_DATA"]
                    if not self.bRemoveMissingVAL:
                        df["MI_DATA"] = df["DT_DATA"]'''
                else:
                    raise RuntimeError(f"Unsupported column count for {strObsId} : {df.shape[1]}")                

                df = df.replace(["", "nan", "NaN", None], pd.NA)
                tmpfile = tempfile.NamedTemporaryFile(delete=False, suffix=".csv", mode="w", encoding="utf-8")
                tmpfile_name = tmpfile.name
                df.to_csv(tmpfile.name, index=False, header=False, na_rep="\\N")
                df.to_csv('aa.csv', index=False, header=False, na_rep="\\N")
                tmpfile.close()
                file_path = tmpfile.name.replace("\\", "/")

                tmp_table = f"{self.strTableNm}_tmp"
                try:
                    cur.execute(f"DROP TEMPORARY TABLE IF EXISTS {tmp_table}")
                    cur.execute(f"""
                        CREATE TEMPORARY TABLE {tmp_table} (
                            DT_DATE VARCHAR(12),
                            DT_DATA DOUBLE NULL,
                            MI_DATA DOUBLE NULL,
                            OI_DATA DOUBLE NULL
                        )
                    """)
                    self.fileProgressChanged.emit(65)
                except Exception as e:
                    raise RuntimeError(f"Error creating temporary table for {strObsId} : {str(e)}")

                try:
                    load_sql = f"""
                    LOAD DATA LOCAL INFILE '{file_path}'
                    INTO TABLE {tmp_table}
                    FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
                    LINES TERMINATED BY '\n'
                    (DT_DATE, DT_DATA, MI_DATA, OI_DATA)
                    """
                    cur.execute(load_sql)
                    self.fileProgressChanged.emit(80)
                except Exception as e:
                    raise RuntimeError(f"LOAD DATA error for {strObsId}: {str(e)}")

                try:
                    if self.isUpdate:
                        merge_sql = f"""
                        INSERT INTO {self.strTableNm} (OBS_ID, DT_DATE, DT_DATA, MI_DATA, OI_DATA)
                        SELECT '{strObsId}', STR_TO_DATE(DT_DATE, '%Y%m%d%H%i'), DT_DATA, MI_DATA, OI_DATA
                        FROM {tmp_table}
                        ON DUPLICATE KEY UPDATE
                            DT_DATA=VALUES(DT_DATA),
                            MI_DATA=VALUES(MI_DATA),
                            OI_DATA=VALUES(OI_DATA)
                        """
                    else:
                        merge_sql = f"""
                        INSERT IGNORE INTO {self.strTableNm} (OBS_ID, DT_DATE, DT_DATA, MI_DATA, OI_DATA)
                        SELECT '{strObsId}', STR_TO_DATE(DT_DATE, '%Y%m%d%H%i'), DT_DATA, MI_DATA, OI_DATA
                        FROM {tmp_table}
                        """
                    cur.execute(merge_sql)
                    self.fileProgressChanged.emit(95)
                except Exception as e:
                    raise RuntimeError(f"Database merge error for {strObsId} : {str(e)}")

            conn.commit()
            self.statusMessage.emit(f"{strObsId} saved to DB successfully (LOAD DATA INFILE)")
            self.fileProgressChanged.emit(100)

        except Exception as e:
            error_msg = f"Database save error for {strObsId}: {str(e)}"
            self.statusMessage.emit(f"[DataImport] {error_msg}")
        finally:
            if tmpfile_name and os.path.exists(tmpfile_name):
                os.remove(tmpfile_name)
            if conn:
                conn.close()       

            return error_msg

# 품질관리
class DataQualityManagement():

    def __init__(self, datafile):
        self.origin_file = datafile

    def INITIALIZE_FILE(self, time_step_minutes=10):

        # 날짜포맷 다양하게 처리(일단 이걸로 사용)
        import pandas as pd
        import numpy as np
        from datetime import datetime, timedelta
        from dateutil.parser import parse

        file_path = self.origin_file
        time_step = timedelta(minutes=time_step_minutes)

        # CSV 읽기
        try:
            df = pd.read_csv(file_path, header=None, dtype=str)
        except Exception as e:
            print(f"[INITIALIZE_FILE] Failed to read file : {e}")
            return pd.DataFrame()

        n_cols = df.shape[1]
        if n_cols < 2:
            print("[INITIALIZE_FILE] CSV must contain at least 2 columns.")
            return pd.DataFrame()

        # 컬럼 콤마 제거 및 float 변환 
        for col in range(1, min(n_cols, 4)):
            try:
                df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce')
            except Exception:
                df[col] = pd.to_numeric(df[col], errors='coerce')

        # 2400 처리
        try:
            dates = df[0].astype(str).values
            prev_dates = np.roll(dates, 1)
            prev_dates[0] = dates[0]

            mask_2400 = np.char.find(dates, '2400') != -1
            if mask_2400.any():
                prev_dt = np.array([datetime.strptime(p, '%Y%m%d%H%M') for p in prev_dates[mask_2400]])
                new_dt = prev_dt + time_step
                dates[mask_2400] = np.array([dt.strftime('%Y%m%d%H%M') for dt in new_dt])
            df[0] = dates
        except Exception:
            pass

        # 초, AM/PM 포함 안전 파싱 
        def parse_datetime_safe(date_str):
            try:
                return parse(date_str)
            except Exception:
                return pd.NaT

        try:
            df[0] = df[0].apply(parse_datetime_safe)
        except Exception:
            df[0] = pd.NaT

        # 누락 시간 보간
        try:
            df_non_null = df.dropna(subset=[0]).copy()
            if not df_non_null.empty:
                start = df_non_null[0].iloc[0].replace(hour=0, minute=0, second=0)
                end = df_non_null[0].iloc[-1].replace(hour=23, minute=59, second=59)
                full_time_index = pd.date_range(start=start, end=end, freq=f'{time_step_minutes}T')
                full_time_df = pd.DataFrame({0: full_time_index})

                df = pd.merge(full_time_df, df, how='left', on=0)
        except Exception:
            pass

        # 중복 제거
        try:
            df = df.drop_duplicates(subset=[0])
        except Exception:
            pass
        
        # NaT는 None, 정상 datetime은 MySQL DATETIME 문자열로 변환
        if not df.empty:
            df[0] = df[0].apply(
                lambda x: x.strftime('%Y-%m-%d %H:%M:%S') if pd.notnull(x) else None
            )

            # datetime이 None인 행 제거 (DB NOT NULL 방지)
            df = df.dropna(subset=[0])   

        return df

    # 마이너스값을 0으로 변경 (수위제외, 유량/댐유입량/댐방류량/조위)
    def MINUS_TO_ZERO(self, pdData):

        # 데이터프레임에서 2~4개의 컬럼 중 숫자형 데이터에서 음수값을 0으로 변환한다.
        df = pdData.copy()  

        # 적용할 컬럼 범위: 2~4번째 컬럼 (인덱스 1~3)
        cols_to_check = df.columns[1:min(4, df.shape[1])]

        for col in cols_to_check:
            # 숫자로 변환 불가능한 값은 NaN 처리 후, 음수는 0으로 치환
            df[col] = pd.to_numeric(df[col], errors='coerce')  # 오류는 NaN
            df[col] = df[col].mask(df[col] < 0, 0)  # 음수 -> 0

        return df

    # 3시간 선형 보간
    def THREEHR_INTERPOLATION(self, pdData):
        
        # 3시간 선형 보간 

        import pandas as pd
        import numpy as np

        try:
            df = pdData.copy()

            # check_column
            col_count = df.shape[1]
            if col_count < 2:
                raise ValueError("Fewer than 2 columns detected.")
            elif col_count == 2:
                df.columns = ["timestamp", "values"]
            elif col_count == 3:
                df.columns = ["timestamp", "values", "extra1"]
            elif col_count == 4:
                df.columns = ["timestamp", "values", "extra1", "extra2"]

            # 보간할 컬럼 선택 (timestamp 제외)
            cols_to_interp = df.columns.drop("timestamp")

            # 문자열 → 숫자 변환, 변환 불가 시 NaN 처리
            for col in cols_to_interp:
                df[col] = pd.to_numeric(df[col], errors="coerce")

            # 3시간 단위로 보간
            window_size = 19
            for start_idx in range(0, len(df), window_size):
                end_idx = min(start_idx + window_size, len(df))
                window_slice = df.iloc[start_idx:end_idx]

                # 양쪽 값이 모두 존재해야 보간
                df.iloc[start_idx:end_idx, 1:] = window_slice.iloc[:, 1:].interpolate(
                    method="linear",
                    limit_direction="forward",
                    limit_area="inside"
                )

            return df

        except Exception as e:
            print(f"[THREEHR_INTERPOLATION] An error occurred. {e}")
            return pdData  

    # 이상치 제거
    def REMOVE_OUTLIER(self, pdData):

        try:
            pd_datafile = pdData.copy()
            n_rows, n_cols = pd_datafile.shape

            if n_cols < 2:
                raise ValueError("Data must have at least 2 columns.")

            dates = pd_datafile.iloc[:, 0].astype(str).str.strip()
            result_df = pd.DataFrame({'DATE': dates})

            window_size = 72  # 6시간 * 12

            # 2~4 컬럼 모두 적용
            for col_idx in range(1, min(n_cols, 4)):
                values = pd.to_numeric(pd_datafile.iloc[:, col_idx], errors='coerce')
                n = len(values)

                # Q1, Q3, IQR
                rolling_Q1 = values.rolling(window=window_size, min_periods=1).quantile(0.25)
                rolling_Q3 = values.rolling(window=window_size, min_periods=1).quantile(0.75)
                IQR = rolling_Q3 - rolling_Q1
                IQR[IQR < 0.01] = 0.01
                LOWER_BOUND = rolling_Q1 - 1.5 * IQR
                UPPER_BOUND = rolling_Q3 + 1.5 * IQR

                # slope 계산
                SLOPE = values.diff().abs().fillna(0)

                # 결과 컬럼 초기화
                WSE_remove_outlier = [np.nan] * n
                Outlier_final_prev = "Normal"
                WSE_prev = np.nan
                before_data = np.nan

                for i in range(n):
                    origin_data = values.iloc[i]

                    if i >= window_size - 1:
                        # 이상치 판단
                        Outlier1 = "Outlier" if (origin_data < LOWER_BOUND.iloc[i] or origin_data > UPPER_BOUND.iloc[i]) else "Normal"
                        Outlier2 = "Outlier" if SLOPE.iloc[i] > 0.2 else "Normal"

                        if (Outlier1 == "Outlier" and Outlier2 == "Outlier") or (Outlier_final_prev == "Outlier" and SLOPE.iloc[i] <= 0.01):
                            Outlier_final = "Outlier"
                        else:
                            Outlier_final = "Normal"

                        if Outlier_final == "Normal":
                            WSE_remove_outlier[i] = origin_data
                        else:
                            WSE_remove_outlier[i] = WSE_prev

                        Outlier_final_prev = Outlier_final
                        WSE_prev = WSE_remove_outlier[i]
                        before_data = origin_data

                    else:
                        # 초기 window 동안
                        WSE_remove_outlier[i] = origin_data
                        Outlier_final_prev = "Normal"
                        WSE_prev = origin_data
                        before_data = origin_data

                result_df[pd_datafile.columns[col_idx]] = WSE_remove_outlier

            # 나머지 컬럼이 4개 초과이면 그대로 추가
            if n_cols > 4:
                for c in range(4, n_cols):
                    result_df[pd_datafile.columns[c]] = pd_datafile.iloc[:, c]

            return result_df

        except Exception as e:
            RESULT_OUTLIER = pdData.copy()
            for col in pdData.columns[1:4]:
                if col not in RESULT_OUTLIER.columns:
                    RESULT_OUTLIER[col] = np.nan
            return RESULT_OUTLIER

    # NULL값 0으로 변경 (수위제외, 유량/댐유입량/댐방류량/조위)
    def NULL_TO_ZERO(self, pdData):
        
        try:
            df = pdData.copy()

            if df.shape[1] < 2 or df.shape[1] > 4:
                raise ValueError(f"Please check the number of columns. Current column count : {df.shape[1]}")

            cols_to_fill = [col for col in df.columns if col.lower() not in ['수위', 'water_level']]

            df[cols_to_fill] = df[cols_to_fill].fillna(0)

            return df

        except Exception as e:
            print(f"[NULL_TO_ZERO] An error occurred during processing. {e}")
            return pdData  

    # 최종데이터 결합 (DATE, DT_DATA, MI_DATA, OI_DATA)
    def COMBINE_DATA(self, pdData1, pdData2, pdData3):

        try:
            RAW_Data = pdData1.copy()
        except Exception as e:
            print(f"[COMBINE_DATA] Error occurred while processing RAW_Data. {e}")
            RAW_Data = pd.DataFrame()

        # INTER_Data 결합
        try:
            INTER_Data_VALUE = pdData2.iloc[:, 1].copy()
            RAW_Data = pd.concat([RAW_Data, INTER_Data_VALUE], axis=1)
        except Exception as e:
            print(f"[COMBINE_DATA] Error occurred while merging INTER_Data. {e}")

        # OUTLIER_Data 결합
        try:
            OUTLIER_Data_VALUE = pdData3.iloc[:, 1].copy()
            RAW_Data = pd.concat([RAW_Data, OUTLIER_Data_VALUE], axis=1)
        except Exception as e:
            print(f"[COMBINE_DATA] Error occurred while merging OUTLIER_Data. {e}")

        return RAW_Data
    
    
# UserControl : ObsList-focus
class OutsideClickFilter(QObject):
    def __init__(self, parent_combo):
        super().__init__()
        self.parent_combo = parent_combo

    def eventFilter(self, obj, event):
        if event.type() == QEvent.MouseButtonPress:
            if self.parent_combo.list_widget.isVisible():
                if (not self.parent_combo.list_widget.geometry().contains(event.globalPos()) and
                    not self.parent_combo.btn_current.geometry().contains(
                        self.parent_combo.btn_current.mapFromGlobal(event.globalPos())
                    )):
                    self.parent_combo.list_widget.hide()
                    self.parent_combo.btn_current.setChecked(False)
        return False
    
# UserControl : ObsList
class ButtonComboBox(QWidget):
    itemAdded = pyqtSignal(str)
    itemDeleted = pyqtSignal(str)

    def __init__(self, items=None, parent=None):
        super().__init__(parent)
        self.setLayout(QVBoxLayout())
        self.layout().setContentsMargins(0, 0, 0, 0)

        self.btn_current = QPushButton("Select")
        self.btn_current.setCheckable(True)
        self.btn_current.clicked.connect(self.toggleList)
        self.btn_current.setFixedWidth(141)
        self.btn_current.setFixedHeight(31)
        self.layout().addWidget(self.btn_current)

        self.list_widget = QListWidget()
        self.list_widget.setWindowFlags(Qt.Popup)
        self.list_widget.setFixedWidth(self.btn_current.width())
        self.list_widget.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        self.list_widget.setSizeAdjustPolicy(QListWidget.AdjustToContents)
        self.list_widget.setVerticalScrollBarPolicy(Qt.ScrollBarAsNeeded)
        self.list_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Fixed)
        self.list_widget.itemClicked.connect(self.onItemClicked)
        self.list_widget.hide()

        self.add_widget_container = QWidget()
        add_layout = QHBoxLayout(self.add_widget_container)
        self.add_line_edit = QLineEdit()
        self.add_line_edit.setPlaceholderText("Enter Station ID")
        self.add_button = QToolButton()
        self.add_button.setText("+")
        self.add_button.setStyleSheet("""
            QPushButton {
                color: #444444;            /* 진한 회색 */
                font-size: 12pt;
                border: none;
                background: transparent;
            }
            QPushButton:hover {
                color: black;              /* 마우스 오버시 검정 */
            }
        """)
        self.add_button.setFixedSize(20, 20)
        add_layout.addWidget(self.add_line_edit)
        add_layout.addWidget(self.add_button)
        add_layout.setContentsMargins(2, 2, 2, 2)
        add_layout.setSpacing(5)
        self.add_widget_item = QListWidgetItem()
        self.list_widget.addItem(self.add_widget_item)
        self.list_widget.setItemWidget(self.add_widget_item, self.add_widget_container)
        self.add_widget_item.setSizeHint(self.add_widget_container.sizeHint())
        self.add_button.clicked.connect(self.addItemFromInput)

        self.completer_model = QStringListModel()
        self.completer = QCompleter(self.completer_model, self)
        self.completer.setFilterMode(Qt.MatchContains)
        self.completer.setCaseSensitivity(Qt.CaseInsensitive)
        self.add_line_edit.setCompleter(self.completer)

        if items:
            for t in items:
                self.addItemWithDelete(t)
        self.updateButtonText()

        self._outside_filter = OutsideClickFilter(self)
        QApplication.instance().installEventFilter(self._outside_filter)

    # 외부 클릭 필터 해제
    def cleanupFilter(self):
        if hasattr(self, "_outside_filter") and self._outside_filter:
            QApplication.instance().removeEventFilter(self._outside_filter)
            self._outside_filter = None

    def toggleList(self):        
        if self.list_widget.isVisible():
            self.list_widget.hide()
            self.btn_current.setChecked(False)
        else:
            self.adjustListHeight(max_visible=8)
            pos = self.btn_current.mapToGlobal(QPoint(0, self.btn_current.height()))
            self.list_widget.setFixedWidth(self.btn_current.width())
            self.list_widget.move(pos)
            self.list_widget.show()
            self.list_widget.setFocus()
            self.btn_current.setChecked(True)

    
    def adjustListHeight(self, max_visible=8):
        total_items = self.list_widget.count()
        if total_items == 0:
            self.list_widget.setFixedHeight(24)
            return

        visible_rows = min(total_items, max_visible)

        total_h = 0
        for i in range(visible_rows):
            h = self.list_widget.sizeHintForRow(i)
            if not h or h <= 0:
                w_item = self.list_widget.item(i)
                w = self.list_widget.itemWidget(w_item)
                if w:
                    h = w.sizeHint().height()
                else:
                    h = 24
            total_h += h

        total_h += 2 * self.list_widget.frameWidth()
        total_h += 6

        self.list_widget.setFixedHeight(total_h)

    def addItems(self, items):
        for item in items:
            if item not in self.getAllItems():
                self.addItemWithDelete(item)
                self.itemAdded.emit(item)
        self.updateButtonText()

    def addItemFromInput(self):
        text = self.add_line_edit.text().strip()
        if text and text not in self.getAllItems():
            self.addItemWithDelete(text)
            self.itemAdded.emit(text)
            self.add_line_edit.clear()
            self.updateButtonText()

    def addItemWithDelete(self, text):
        item = QListWidgetItem(self.list_widget)
        widget = QWidget()
        layout = QHBoxLayout(widget)
        label = QLabel(text)
        btn_del = QToolButton()
        btn_del.setText("x")
        btn_del.setStyleSheet("""
            QToolButton {
                color: #444444;            /* 진한 회색 */
                font-size: 12pt;
                border: none;
                background: transparent;
            }
            QToolButton:hover {
                color: black;              /* 마우스 오버시 검정 */
            }
        """)
        btn_del.setFixedSize(20, 20)        
        btn_del.setSizePolicy(QSizePolicy.Fixed, QSizePolicy.Fixed)
        btn_del.clicked.connect(lambda _, i=item, t=text: self.removeItem(i, t))
        layout.addWidget(label)
        layout.addWidget(btn_del)
        layout.setContentsMargins(2, 2, 2, 2)
        layout.setSpacing(4)
        widget.setLayout(layout)
        widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Fixed)
        self.list_widget.addItem(item)
        self.list_widget.setItemWidget(item, widget)
        item.setSizeHint(widget.sizeHint())
        self.updateCompleter()
        self.updateButtonText()
        self.adjustListHeight(max_visible=8)

    def removeItem(self, item, text):
        row = self.list_widget.row(item)
        if row >= 0:
            self.list_widget.takeItem(row)
            self.itemDeleted.emit(text)
            self.updateCompleter()
            self.updateButtonText()
            self.adjustListHeight(max_visible=8)

    def onItemClicked(self, item):
        self.list_widget.hide()
        self.btn_current.setChecked(False)

    def getAllItems(self):
        texts = []
        for i in range(self.list_widget.count()):
            widget = self.list_widget.itemWidget(self.list_widget.item(i))
            if widget and widget != self.add_widget_container:
                label = widget.findChild(QLabel)
                if label:
                    texts.append(label.text())
        return texts

    def updateCompleter(self):
        self.completer_model.setStringList(self.getAllItems())

    def updateButtonText(self):
        items = self.getAllItems()
        if items:
            btn_text = self.shorten_full_text(items)
            self.btn_current.setText(btn_text)
        else:
            self.btn_current.setText("Please select")
        
    def getSelectedItem(self):
        return self.btn_current.text()
    
    def shorten_full_text(self, items):
        try:
            if not items:
                return "Please select"
            full_text = ",".join(str(x) for x in items)  
            idx = full_text.index(',')  
            return full_text[:idx] + "..."
        except ValueError:
            return full_text
        except Exception as e:
            print(f"[Dataset Creation] shorten_full_text error: {e}")
            return full_text
        
    def clearItems(self):
        for i in reversed(range(self.list_widget.count())):
            item = self.list_widget.item(i)
            widget = self.list_widget.itemWidget(item)
            if widget and widget != self.add_widget_container:
                text = widget.findChild(QLabel).text()
                self.list_widget.takeItem(i)
                self.itemDeleted.emit(text)
        self.updateCompleter()
        self.updateButtonText()
        self.adjustListHeight(max_visible=8)


from PyQt5.QtCore import QRunnable, QThreadPool, pyqtSlot, pyqtSignal, QObject, Qt
from PyQt5.QtWidgets import QMessageBox, QTableWidgetItem
import mariadb
import pandas as pd
from datetime import timedelta

# ------------------ 스레드 시그널 정의 ------------------
class WorkerSignals(QObject):
    finished = pyqtSignal()
    error = pyqtSignal(str)
    progress = pyqtSignal(object)  # 테이블 데이터 전송용

# ------------------ 스레드 작업 클래스 ------------------

class RunnableTask(QRunnable):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn
        self.signals = WorkerSignals()

    @pyqtSlot()
    def run(self):
        try:
            result_data = self.fn()  # DB 조회 + 데이터 처리
            self.signals.progress.emit(result_data)  # UI 업데이트
        except Exception as e:
            self.signals.error.emit(str(e))
        finally:
            self.signals.finished.emit()